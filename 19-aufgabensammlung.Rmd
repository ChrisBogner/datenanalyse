# Aufgabensammlung

Diese Aufgabensammlung enthält zusätzlich Aufgaben, die z.B. im Seminar bearbeitet werden. Aufgaben zu den einzelnen Kapiteln finden Sie am Ende des jeweiligen Kapitels.

## Tutorial Zusammenhangsmaße {#werdeschlau}


**Begleitend zu diesem Tutorial sind die Kapitel 2 und 3 in Mittag (2017) "Statistik" zu lesen.**

## Befragung der Studierenden der Uni Werdeschlau {-}

Wir beschäftigen uns mit einem fiktiven Beispiel.

An der (kleinen) Universität Werdeschlau möchte die Studierendenvertretung wissen, ob sich eine Station zum Ausleihen von Fahrrädern lohnen würde. Dazu befragen sie die Studierenden, wie lange sie zur Uni fahren. Zudem wollen Sie wissen, ob die Anreisezeit und die Zeit, die die Studierenden pro Woche in der Bibliothek verbringen, zusammen hängen.


### Grundgesamtheit generieren

Unsere **Grundgesamtheit** sind alle 12000 Studierende von der Uni Werdeschlau. Wir erstellen uns in diesem Beispiel selbst unsere Grundgesamtheit aus der Gleichverteilung. Die Regeln dazu sind absolut frei erfunden. Die meisten Studierenden sind zwischen 5 und 40 Minuten unterwegs; 20% jedoch haben eine längere Anreise zwischen 60 und 120 Minuten.

*Lassen Sie den Code laufen.*
```{r, results = 'hide', fig.show='hide'}
library(tidyverse)
set.seed(123)
anreise <- c(runif(n = 12000 * 0.8, min = 5, max = 40),
                     runif(n = 12000 * 0.2, min = 60, max = 120))

geschlecht <- sample(c('m', 'w'), size = 12000, replace = TRUE)
wohnort <- sapply(anreise, function(x) {
  if(x < 30) 'stadt'
  else 'land'
})
verkehrsmittel <- sapply(anreise, function(x) {
  if(x <= 10) 'zu_fuss'
  else if(x > 10 & x <= 15) sample(c('zu_fuss', 'fahrrad'), size = 1)
  else if(x > 15 & x <= 45) sample(c('bus', 'fahrrad', 'auto'), size = 1)
  else sample(c('bus', 'auto'), size = 1)
})

zeit_bib <- 5 * 60 - 0.7 * anreise + rnorm(length(anreise), 0, 20)

```

Wir setzen `geschlecht`, `wohnort`, `verkehrsmittel`, `anreise` und `zeit_bib` zu einer Datenmatrix (`tibble`) zusammen und nennen das Objekt `grundgesamtheit`.

*Lassen Sie den folgenden Code laufen.*

```{r, results = 'hide', fig.show='hide'}
grundgesamtheit <- tibble(geschlecht, wohnort, verkehrsmittel, anreise, zeit_bib)
```


### Befragung simulieren

In der Realität werden natürlich nicht alle 12000 Studierende befragt (wer hat schon so viele Kapazitäten?), sondern eine zufällige **Stichprobe** erhoben, also eine Teilmenge der Grundgesamtheit.

**Frage**: Wie nennt man die Studierenden

  - Merkmalsträger
  - Befragte oder
  - Modalwerte?

Falls Sie nicht sicher sind: Lesen Sie Kapitel 2 in Mittag (2017) "Statistik"!


<br>

Um unsere Stichprobe zu erstellen, ziehen wir ohne Zurücklegen aus unserer Grundgesamtheit. Sagen wir mal, die Kapazitäten der Befragenden reichen für 200 Befragungen.

*Lassen Sie den folgenden Code laufen.*

```{r, results = 'hide', fig.show='hide'}
befragung <- grundgesamtheit[sample(1:dim(grundgesamtheit)[1], size = 200, replace = FALSE), ]
```

### Kurze explorative Datenanalyse

Von hier an arbeiten wir mit unserer Stichprobe `befragung`. Sehen wir uns mal die empirische Verteilung, d.h. die Verteilung in der Stichprobe an.

Plotten Sie ein Histogramm der Anreisezeiten in unserer Stichprobe. *Lassen Sie den Code laufen und passen Sie die bins sinnvoll an.*

```{r, results = 'hide', fig.show='hide'}
ggplot(data = befragung, aes(x = anreise)) +
  geom_histogram(bins = 5) +
  xlab('Tagliche Anreise (min)') +
  ylab('Häufigkeit')
```


### Lage- und Streuungsmaße

Erstellen Sie die Fünf-Punkte-Zusammenfassung der Stichprobe. *Lassen Sie den Code laufen.*

```{r, results = 'hide', fig.show='hide'}
summary(befragung)
```

Wie Sie sehen können, behandelt R die kategorischen Daten anders als numerische. Kategorische Variablen werden als absolute Häufigkeiten pro Kategorie dargestellt (d.h. ausgezählt).


Wir vergleichen nun gewöhnliche und robuste Lage- und Streuungsmaße. Zu gewöhnlichen gehören der Mittelwert (genauer arithmetisches Mittel) und die Standardabwechung.

*Berechnen Sie den Mittelwert und die Standardabweichung der Anreise.*

Zu den robusten Maßen gehören der Median, der Interquartilabstand und die mittlere absolute Abweichung vom Median (MAD). MAD beschreibt die durchschnittlich Abweichung der Stichprobe von ihrem Median.

*Berechnen Sie den Median der Stichprobe.*

Den Interquartilabstand bekommt man mit Hilfe der Funtion `quantile`, die die Quantile berechnet. 

*Lassen Sie den folgenden Code laufen.*

```{r, results = 'hide', fig.show='hide'}
quantile(x = befragung$anreise, probs = 0.75) - quantile(x = befragung$anreise, probs = 0.25)
```

Der Interquartilabstand kann auch direkt mit der Funktion `IQR()` berechnet werden und MAD mit `mad()`.

*Berechnen Sie den Interquartilabstand und MAD der Stichprobe.*


Vergleichen Sie die gewöhnlichen und die robusten Maße. Es gilt: je größer die außergewöhnlichen Datenpunkte, d.h. je höher die höchsten Anfahrtszeiten, desto stärker reagieren der Mittelwert und die Standardabweichung. Die robusten Maße bleiben (solange der Anteil der hohen Anfahrtszeiten nicht zu groß ist) relativ konstant.

Abgesehen vom Aspekt der Robustheit, ist das arithmetische Mittel nicht immer ein geeigneter Durchschnittswert. Für Wachstumsfaktoren (Preissteigerung, Zinsen) ist das geometrische Mittel die korrekte Mittelung und für die Berechnung von Durchschnittsgeschwindigkeiten das harmonische Mittel (Details z.B. bei Fahrmeir et al. (2016). Statistik. Der Weg zur Datenanalyse).

### Zufall in der Befragung

Wir haben unsere Befragten rein zufällig ausgewählt. D.h. die Kenngrößen hängen von dieser zufälligen Auswahl ab. Wie würden sie sich verändern, wenn wir eine andere Stichprobe ausgesucht hätten?

Wir simulieren eine wiederholte Befragung und sehen uns an, wie sich der Mittelwert und der Median entwickeln. *Lassen Sie den Code laufen.*

```{r, results = 'hide', fig.show='hide'}
anzahl_der_befragungen <- 100

# Leere Vektoren erstellen, in die später die Ergebnisse geschrieben werden.
mean_all <- vector()
median_all <- vector()


for (i in 1:anzahl_der_befragungen){
  dat <- grundgesamtheit[sample(1:dim(grundgesamtheit)[1], size = 200, replace = FALSE), ]
  mean_all[i] <- mean(dat$anreise)
  median_all[i] <- median(dat$anreise)
}

kennzahlen <- tibble(mean_all, median_all)

```


Stellen Sie die Mittelwerte `mean_all` als Histogramm dar. *Lassen Sie den Code laufen und passen Sie die bins sinnvoll an.*

```{r, results = 'hide', fig.show='hide'}
ggplot(data = kennzahlen, aes(x = mean_all)) +
  geom_histogram(bins = 5) +
  xlab('Mittelwerte der taglichen Anreise (min)') +
  ylab('Häufigkeit')
```


Stellen Sie die Mediane `median_all` als Histogramm dar. *Lassen Sie den Code laufen und passen Sie die bins sinnvoll an.*

```{r, results = 'hide', fig.show='hide'}
ggplot(data = kennzahlen, aes(x = median_all)) +
  geom_histogram(bins = 5) +
  xlab('Mediane der taglichen Anreise (min)') +
  ylab('Häufigkeit')
```

### Zusammenhangsmaße für nominalskalierte Merkmale
Gibt es Präferenzen für bestimmte Verkehrsmittel je nach Geschlecht?
Wir sehen uns die Kontingenztabelle dazu an.

*Lassen Sie den folgenden Code laufen.*

```{r, results = 'hide', fig.show='hide'}
table(befragung$geschlecht, befragung$verkehrsmittel)
```
Nun berechnen wir die Zusammenhangsmaße auf dieser Tabelle. Dazu nutzen wir die Bibliothek vcd (Visualizing Categorical Data), sehr empfehlenswert, wenn Sie kategorische Daten analysieren wollen.

*Lassen Sie den folgenden Code laufen.*

```{r, results = 'hide', fig.show='hide', message=F}
library(vcd)
assocstats(table(befragung$geschlecht, befragung$verkehrsmittel))
```

Der Phi-Koeffizient ist NA, weil er nur auf $2 \times 2$-Tabellen definiert ist. Die beiden anderen, Contingency Coeff. (Pearson Koeffizient K) und Cramer's V zeigen unterschiedliche Werte an, je nachdem, wie unsere zufällige Stichprobe ausfällt. Aber der Zusammenhang sollte eher klein sein.

Allgemein gilt: Contingency Coeff. (Pearson Koeffizient K) und Cramer's V schwanken zwischen 0 (kein Zusammenhang) und 1 (perfekter Zusammenhang). Wichtig: Sie zeigen keine Richtung an. D.h. wir wissen nicht, ob der Zusammenhang positiv - "je mehr desto mehr" oder negativ "je mehr desto weniger" ist.

Die ersten beiden Zeilen, die `assocstats` liefert, gehören zum Thema Hypothsentests. Das besprechen wir später.

Gibt es einen Zusammenhang zwischen dem Wohnort und dem ausgesuchten Verkehrsmittel?

*Berechnen Sie die Kontingenztabelle. Nutzen Sie die Funktion `table()` auf den Spalten `wohnort` und `verkehrsmittel` im Datensatz `befragung`.*


Berechnen Sie die Zusammenhangsmaße. *Lassen Sie den Code laufen.*

```{r, results = 'hide', fig.show='hide'}
assocstats(table(befragung$wohnort, befragung$verkehrsmittel))
```


Gibt es eine Präferenz für den Wohnort je Geschlecht? *Lassen Sie den Code laufen.*

```{r, results = 'hide', fig.show='hide'}
assocstats(table(befragung$wohnort, befragung$geschlecht))

```

Da Sie ja genau wissen, wie die Daten erstellt wurden, sollten Ihnen die Antworten nicht zu schwer fallen.


### Zusammenhangsmaße für metrische Merkmale

Zum Schluss wenden wir uns den beiden numerischen Variablen, `anreise` und `zeit_bib`. Besteht hier eine Korrelation?

Zuerst stellen wir die Daten dar.

*Lassen Sie den folgenden Code laufen.*

```{r, results = 'hide', fig.show='hide'}
ggplot(data = befragung, aes(x = anreise, y = zeit_bib)) +
  geom_point() +
  xlab('Tägliche Anreise (min)') +
  ylab('Zeit in der Bibliothek pro Woche (min)')
```

Der Zusammenhang zwischen den beiden Variablen ist (ziemlich) linear und negativ.

Wir berechnen beide Korrelationsmaße, den Pearson Korrelationskoeffizienten für lineare Zusammenhänge und den Spearman Korrelationskoeffizient für monotone Zusammenhänge.

*Lassen Sie den Code laufen.*

```{r, results = 'hide', fig.show='hide'}
# Pearson Korrelationskoeffizient
cor(befragung$anreise, befragung$zeit_bib, method = 'pearson')

# Spearman Korrelationskoeffizient
cor(befragung$anreise, befragung$zeit_bib, method = 'spearman')
```

Beide Koeffizienten sind nah dran an dem Faktor 0.7, den wir zum Simulieren unserer Daten verwendet haben. Man darf hier beide verwenden. Wichtig ist es zu berichten, welchen Sie verwenden. D.h. es ist nicht genug, zu schreiben, dass Sie eine Korrelation berechnet haben. 

**Gut gemacht! Lassen Sie den Code laufen.**
```{r "emoji", results = 'hide', fig.show='hide'}

library(ggplot2)
library(emojifont)
ggplot() + geom_fontawesome("fa-coffee", color='lightblue', size = 80) + theme_void() + ggtitle("It's time for coffee")

```

### Aufgabe einreichen
- Speichern Sie Ihr Notebook und laden Sie es vom Server herunter.
- Laden Sie Ihr Notebook in ILIAS hoch. Sie bekommen eine Musterlösung
- Vergleichen Sie Ihre Lösung mit der Musterlösung.

**Fertig!**



## Der explorative Workflow mit tidyverse

### R-Hausaufgaben

An dem Kurs "Einführung in R" nehmen 49 Studierende teil. Der Leistungsnachweis besteht aus Hausaufgaben, die insgesamt mit 100 Punkten bewertet werden. Ab 50 Punkten gilt der Kurs als bestanden.

1. Lesen Sie den Datensatz `r file.name("R-HAs.txt")`, der die Endpunkte enthält, ein.
2. Ermitteln Sie, wie viele Teilnehmer bestanden und wie viele nicht bestanden haben. Nutzen Sie dazu die Funktion `mutate()` und die Funktion `ifelse()`.


### Unfaire Klausur? {#klausur}

Ar belegt im 4. Semester die Veranstaltung "Spaß mit R". Bei der Klausur gibt es 2 Aufgabengruppen mit jeweils 60 Punkten. Aufgabengruppe 1 wird an Studierende auf ungeraden Sitzplätzen und  Aufgabengruppe 2 an Studierende auf geraden Sitzplätzen ausgegeben.

1. Lesen Sie den Datensatz `r file.name("Klausurpunkte.txt")` ein.
1. Überprüfen Sie Ars Vermutung, dass die Aufgabengruppe 1 im Schnitt leichter war als Aufgabengruppe 2 (d.h. in der Gruppe 1 im Schnitt mehr Punkte erzielt wurden). Nutzen Sie die Funktionen `mutate()`, um eine Spalte mit der Gruppenzugehörigkeit zu ermitteln und `summarize()`, um den Mittelwert zu berechnen. Tipp: mit dem Operator `%%` können Sie überprüfen, ob eine Zahl z.B. durch 2 teilbar ist.


### Fledermäuse
Ar Stat untersucht im Rahmen eines ökologischen Praktikums Fledermäuse in Ecuador. Er misst die Größe der Tiere und bestimmt ihr Geschlecht.

- Laden Sie den Datensatz `r file.name('Fledermaus.txt')`. Dieser enthält die Größe der Tiere in cm.
- Die ersten 20 untersuchten Tiere sind Männchen. Erstellen Sie einen `factor` "geschlecht", der das Geschlecht der Tiere enthält. Benutzen Sie dazu die Funktionen `rep()`.
- Fügen Sie die Informationen über die Größe und das Geschlecht in einem `tibble` zusammen und bennen Sie die Spalten entsprechend.
- Bei dem 3. Individuum hat sich Ar vertippt. Die Größe des Tieres lautet in Wirklichkeit 5,37 cm. Korrigieren Sie den Fehler.
- Speichern Sie den korrigierten Datensatz ab.
- Berechnen Sie die Mittelwerte und die Standardabweichungen der Größen der Tiere je Geschlecht.
- Plotten Sie die Größen je Geschlecht in einem Boxplot und speichern Sie diesen ab.

### Fledermäuse, revisited
Wir gehen davon aus, dass das Alter der Fledermäuse mit ihrer Größe zusammenhängt. Pauschal legen wir fest, dass ein Tier, das kleiner als 5 cm groß ist, ein Jungtier ist.

- Klassifizieren Sie die Tiere in J (Jungtier) und E (Erwachsen). Erstellen Sie dazu mit `mutate()` ein eigene Spalte.
- Wie viele Jungtiere gibt es im Datensatz?
- Sind die Jungtiere weiblich oder männlich?

### Zeitreihen aus dem Lehstenbacheinzugsgebiet (NE Bayern)
Im Lehstenbacheinzugsgebiet wurden über eine längere Zeit Niederschlag, Abfluss und Temperatur gemessen. Die Messeinheiten sind für Temperatur °C, für Niederschlag und Abfluss mm.

1. Laden Sie den Datensatz `r file.name("Data.dat")`.
1. Wandeln Sie die Spalte `Date` in ein richtiges Datum um.
2. Plotten Sie die Temperatur, den Niederschlag und den Abfluss (in verschiedene Grafiken) untereinander. Beschriften Sie alles korrekt und fügen Sie Titel hinzu. Überlegen Sie, welche Darstellungsart (geom) für den Niederschlag am besten ist.
4. Speichern Sie die Grafik als pdf ab.


### Umweltdaten entlang der dänischen Küste

Die Datei `r file.name("Temperatur.csv")` aus @Zuur2009a enthält Messungen von Temperatur, Salinität und Chlorophyl a an 31 Orten entlang der dänischen Küste. Der Datensatz kann [hier](https://highstat.com/index.php/a-beginner-s-guide-to-r) heruntergeladen werden. Die Daten stammen vom dänischen Institut RIKZ (Monitoringprogramm MWTL: Monitoring Waterstaatkundige Toestand des Lands). Die Messungen wurden zwischen 1990 und 2005 durchgeführt mit einer Häufigkeit von 0--4 mal pro Monat je nach Jahreszeit.

1. Lesen Sie den Datensatz `r file.name("Temperatur.csv")` ein.
1. Konvertieren Sie die Spalte Date in ein richtiges Datumsformat und plotten Sie die Temperaturen pro Station (`facet_wrap()`) als Zeitreihen.
1. Berechnen Sie die Anzahl der Messwerte, Monatsmittelwerte der Temperatur für alle Stationen, sowie die Standardabweichungen.
1. Stellen Sie die Monatsmittel der Temperatur als Linien dar.
1. Beschriften Sie die Grafik sinnvoll.
1. Fügen Sie die Standardabweichungen als Band hinzu.
1. Speichern Sie die Grafik als pdf ab.

### Umweltdaten entlang der dänischen Küste, revisited
1. Berechnen Sie die Monatsmittelwerte und Standardabweichungen je Station. Tipp: `group_by(Station, Month)`.
1. Stellen Sie die Daten mit einem Fehlerband dar (in verschiedenen Plots mit `facet_wrap()`) und speichern Sie sie ab.

## Bootstrapping, Konfidenzintervalle und Hypothesentests

### Unfaire Klausur, revisited
Wir kommen zurück auf die Klausurpunkte aus der Aufgabe \@ref(klausur). Waren die Aufgaben in Gruppe 1 leichter? Nutzen Sie das Framework in `infer`.


### Artenvielfalt in Grasländern
Sie erhalten Daten aus dem Grasland-Monitoring im Yellowstone Nationalpark und dem National Bison Range (USA) aus @Zuur2009a. Der Datensatz kann [hier](https://highstat.com/index.php/a-beginner-s-guide-to-r) heruntergeladen werden. Das Ziel des Monitorings ist die Untersuchung möglicher Änderungen der Biodiversität und deren Zusammenhang mit Umweltfaktoren. Biodiversität wurde durch die Anzahl unterschiedlicher Arten quantifiziert (Spalte `R`). Insgesamt haben die Forscher ca. 90 Arten in 8 Transekten kartiert. Die Aufnahmen wurden alle 4 bis 10 Jahre wiederholt. Insgesamt liegen 58 Beobachtungen vor. Die Daten sind in der Datei `r file.name("Vegetation2.xls")` gespeichert.

1. Laden Sie den Datensatz in R und sehen Sie sich seine Struktur an. Von welchem Typ sind die einzelnen Variablen? Entspricht das Ihren Erwartungen? Diese Aufgabe dient dazu, das Einlesen von Excel-Dateien mit `tidyverse` zu erarbeiten. Tipp: nutzen Sie die Funktion `read_xls()` in der Bibliothek `readxl`. Lesen Sie in der Hilfe nach, wie Sie *ein bestimmtes* Tabellenblatt aus Excel einlesen können.

1. Kurze explorative Analyse: Berechnen Sie die Anzahl der Messungen, den Mittelwert und die Standardabweichung der Artenzahl `R` pro Transekt.

1. Plotten Sie die Artenzahl gegen die Variable `BARESOIL` (Anteil von unbewachsenem Boden). Färben Sie die Punkte je nach Transekt unterschiedlich ein. Tipp: Transekt als `as_factor()` konvertieren.

1. Fügen Sie eine glättende Linie ohne Konfidenzband hinzu, die alle Punkte unabhängig vom Transekt berücksichtigt ([Abschnitt 4.2](https://ggplot2-book.org/collective-geoms.html) im Buch ggplot2 [@Wickham2020]). Damit eine einzige glättende Linie für alle Transekte hinzugefügt wird, müssen Sie die aes für Farbe statt in `ggplot()` in `geom_point()` angeben.

1. Beschriften Sie die Grafik (auch die Legende!) sinnvoll und speichern Sie sie als pdf ab.

1. Stellen Sie die Artenzahl je Transekt als Zeitreihe dar. Die Symbole sollen sowohl Punkte als auch Linien sein. Skalieren Sie die Größe der Punkte je nach Anteil des unbewachsenen Bodens ([Abschnitt 12.1](https://ggplot2-book.org/scale-other.html?q=size#size) im Buch ggplot2 [@Wickham2020]). Denken Sie nach, an welcher Stelle die aes `size` stehen muss, damit *nur* die Punkte skaliert werden.

1. Beschriften Sie die Grafik (auch die Legenden!) sinnvoll und speichern Sie sie als pdf ab.

1. Setzen Sie nun beide Grafiken untereinander, platzieren Sie die Legenden (ja nach gewähltem Layout) sinnvoll und speichern Sie die Grafiken ab.

1. Berechnen Sie den linearen Korrelationskoeffizienten zwischen der Biodiversität und dem Anteil von unbewachsenem Boden und ermitteln Sie das 95%-Bootstrap-Konfidenzintervall.

1. Wenn Sie statt eines 95%-Konfidenzintervalls, das 90%-Konfidenzintervall berechnen, wird das Intervall breiter oder schmaler? Warum? 

### Bodenverdichtung {#verdichtung}
Schwere landwirtschaftliche Maschinen können beim Bearbeiten des Bodens zu Bodenverdichtung führen. In einem randomisierten Design wurden zufällig Parzellen (Spalte `plots`) auf einem sonst homogenen Feld entweder mit einer schweren Maschine bearbeitet (`compacted`) oder nicht (`control`). Auf allen Parzellen wurde die Lagerungsdichte bestimmt. Die Lagerungsdichte (auch Trockenrohdichte) ist ein Maß für Bodenstruktur und gibt das Verhältnis der Trockenmasse eines Bodens zu seinem Volumen. Sie wird häufig in [g/cm³] gemessen und kann als ein Indikator für Bodenverdichtung genutzt werden. Der Datensatz  ist in der Date `r file.name("bd_compaction.csv")` gespeichert.

1. Lesen Sie den Datensatz ein und führen Sie eine kurze explorative Datenanalyse durch.
2. Überprüfen Sie, ob sich die Lagerungsdichte auf den bearbeiteten Feldern erhöht hat. 


### Anteil von beschäftigten Frauen im privaten und öffentlichen Sektor {#world-bank}
Diese Übung ist inspiriert von Anrew Heiss Blog: https://www.andrewheiss.com/blog/2018/12/05/test-any-hypothesis/

Wir nutzen den Datensatz Worldwide Bureaucracy Indicators (WWBI). Diesen kann man bei der [Weltbank](https://datacatalog.worldbank.org/dataset/worldwide-bureaucracy-indicators) herunter laden.

1. Laden Sie den Datensatz als *csv file* herunter, speichern Sie Ihn auf Ihrer Festplatte ab. Der Datensatz wird als zip-Datei heruntergeladen. Laden Sie diese zip-Datei direkt auf den R-Server in den Ordner Data hoch. De Server entpackte die Datei automatisch.
2. Die Daten sind in der Datei `r file.name('WWBIData.csv')` gespeichert. Sehen Sie sich die beiden anderen csv-Dateien an. Was steht drin?
1. Lesen Sie den Datensatz `r file.name('WWBIData.csv')` ein.
3. Gemeinsame Übung: Wir bereinigen den Datensatz und machen ihn *tidy*.
3. Filtern Sie Daten für das Jahr 2012 und die Indikatoren "BI.PWK.PRVS.FE.ZS" und "BI.PWK.PUBS.FE.ZS". Enfernen Sie NAs. Was bedeuten diese Indikatoren?
4. Stellen Sie die Histogramme dieser Indikatoren dar.
4. Gibt es Unterschied zwischen den Anteilen der beschäftigen Frauen im privaten und öffentlichen Sektor?

<!-- ### Wasserentnahme mit Datenquelle EUROSTAT direkt -->

<!-- Wir können die Datenbank EUROSTAT direkt über ihr API (Application Programming Interface) ansprechen. Leider ist das herunter geladene Datenformat sehr umständlich. Um uns Programmierarbeit zu sparen, nutzen wir das Paket eurostat, das die Daten aus der Datenbank herunterlädt und gleich ordentlich formatiert. -->

<!-- 1. Installieren Sie das Paket eurostat und sehen Sie sich das Tutorial für das Paket an (https://ropengov.github.io/eurostat/articles/website/eurostat_tutorial.html) -->
<!-- 2. Durchsuchen Sie die Datenbank nach allen Datensätzen, die das Wort "water" enthalten und darin das Wort "abstraction". -->
<!-- 3. Laden Sie den entsprechenden Datensatz herunter (env_wat_abs). -->
<!-- 4. Das Paket skimr bietet Zusammenfassungsfunktionen für Datensätze, die man auch in der Pipe benutzen kann. Installieren Sie das Paket und wenden Sie die Funktion `skim()` auf den heruntergeladenen Datensatz an. -->
<!-- 4. Welche Wasserquellen und Nutzer sind im Datensatz enthalten (https://appsso.eurostat.ec.europa.eu/nui/show.do?dataset=env_wat_abs&lang=en)? -->
<!-- 4. Stellen Sie die Wasserentnahme pro Einwohner dar (Gesamtentnahme aus allen Quellen: wat_proc == 'ABST' & wat_src == 'FRW'). -->
<!-- 4. Berechnen Sie die Gesamtmenge des entnommenen Wassers für alle Länder je Quelle (Fresh surface water und Fresh ground water). -->
<!-- 4. Stellen Sie diese Daten als Punktdiagramm, als Balkendiagramm und als Flächendiagramm dar. Was ist das Problem mit dem Flächendiagramm? -->


