[{"path":"index.html","id":"vorwort","chapter":"Vorwort","heading":"Vorwort","text":"‚Äúhoney, ‚Äôre gonna style‚Äù","code":""},{"path":"index.html","id":"organisatorisches","chapter":"Vorwort","heading":"Organisatorisches","text":"\nDie Coronaviruspandemie ver√§ndert unser Leben und unser Lernen. Die UzK bittet Lehrende, das SoSe 2021 als Hybridsemester zu gestalten. Wir werden unseren Kurs komplett online durchf√ºhren. Bitte seien Sie nachsichtig, wenn nicht alles klappt wie Pr√§senzveranstaltungen. Wir m√ºssen aktuell alle sehr viel dazu lernen Sachen digitale Lehre. Sie k√∂nnen sicher sein, dass das Geographische Institut bem√ºht ist, die Lehre effizient wie m√∂glich weiter laufen zu lassen, damit Sie Ihrem Studium fortfahren k√∂nnen.\ndieser Veranstaltung werden wir folgende Werkzeuge verwenden:ILIAS: die Online-Lernplattform der UzK. Entweder sind Sie bereits automatisch dem Kurs registriert oder werden von mir per Hand angemeldet.Campuswire: die Chatplattform dient der allgemeinen Kommunikation und der Selbstorganisation des Lernens. Verwenden Sie diese, um Fragen mit Ihren Kommilitonen*innen und mir zu diskutieren. Sie sollten eine Einladungsmail zu Campuswire erhalten haben.Zoom: die Videokonferenz-Software werden wir f√ºr Liveveranstaltungen nutzen. Die Anmeldemodalit√§ten sind auf den Kursseiten ILIAS erkl√§rt.RStudio Server Pro: der Server bietet die M√∂glichkeit, online R und RStudio zu arbeiten.","code":""},{"path":"index.html","id":"verwendete-literatur","chapter":"Vorwort","heading":"Verwendete Literatur","text":"Wir werden diesem Kurs haupts√§chlich das freie, englischsprachige Buch ModernDive: Statistical Inference via Data Science benutzen (Ismay Kim 2021). Bitte lassen Sie sich nicht davon abschrecken, dass das Buch englischsprachig ist. Es ist sehr gut verst√§ndlich und bietet einen modernen Zugang zur Datenanalyse. Als ein weiteres Buch werden wir Sauer (2019) nutzen.Ab und werde ich Ihnen auch andere Literatur empfehlen. F√ºr Ihren Abschlussbericht werden Sie auch selbst√§ndig weitere Literatur recherchieren.","code":""},{"path":"index.html","id":"sinn-und-unsinn-dieses-skripts","chapter":"Vorwort","heading":"Sinn und Unsinn dieses Skripts","text":"Dieses Skript ist ein lebendiges Begleitdokument des Kurses. Es wird laufend angepasst und aktualisiert.Ich nutze verschiedenfarbige Bl√∂cke, um wichtige Stellen hervorzuheben:\nInfoblock\n\nAchtung, wichtig!\n\nBeispielblock\n\nLernziele\n","code":""},{"path":"index.html","id":"inspiration-quellen-und-danksagung","chapter":"Vorwort","heading":"Inspiration, Quellen und Danksagung","text":"Dieses Skript baut stark auf folgenden freien Quellen auf:r4ds: Wickham Grolemund (2021)ggplot2: Wickham (2020)ModernDive: Ismay Kim (2021)Den Autoren dieser B√ºcher gilt ein gro√üer Dank f√ºr Ihren Beitrag zur -Community !","code":""},{"path":"index.html","id":"reproduzierbarkeit","chapter":"Vorwort","heading":"Reproduzierbarkeit","text":"Dieses Buch wurde RStudio mit Bookdown geschrieben und R version 4.1.0 (2021-05-18) gebaut. Folgende Pakete werden f√ºr die Beispiele und √úbungen ben√∂tigt:Die komplette Information zur Session lautet:Diese Skript ist lizensiert unter Creative Commons Namensnennung - Nicht-kommerziell - Weitergabe unter gleichen Bedingungen 4.0 International.","code":"## R version 4.1.0 (2021-05-18)\n## Platform: x86_64-pc-linux-gnu (64-bit)\n## Running under: Ubuntu 20.10\n## \n## Matrix products: default\n## BLAS:   /usr/lib/x86_64-linux-gnu/atlas/libblas.so.3.10.3\n## LAPACK: /usr/lib/x86_64-linux-gnu/atlas/liblapack.so.3.10.3\n## \n## locale:\n##  [1] LC_CTYPE=de_DE.UTF-8       LC_NUMERIC=C              \n##  [3] LC_TIME=de_DE.UTF-8        LC_COLLATE=de_DE.UTF-8    \n##  [5] LC_MONETARY=de_DE.UTF-8    LC_MESSAGES=de_DE.UTF-8   \n##  [7] LC_PAPER=de_DE.UTF-8       LC_NAME=C                 \n##  [9] LC_ADDRESS=C               LC_TELEPHONE=C            \n## [11] LC_MEASUREMENT=de_DE.UTF-8 LC_IDENTIFICATION=C       \n## \n## attached base packages:\n## [1] stats     graphics  grDevices utils     datasets  methods   base     \n## \n## other attached packages:\n##  [1] forcats_0.5.1     stringr_1.4.0     dplyr_1.0.6       purrr_0.3.4      \n##  [5] readr_1.4.0       tidyr_1.1.3       tibble_3.1.2      ggplot2_3.3.3    \n##  [9] tidyverse_1.3.1   kableExtra_1.3.4  fontawesome_0.2.1\n## \n## loaded via a namespace (and not attached):\n##  [1] Rcpp_1.0.6        svglite_2.0.0     lubridate_1.7.10  tufte_0.10       \n##  [5] assertthat_0.2.1  rprojroot_2.0.2   digest_0.6.27     utf8_1.2.1       \n##  [9] R6_2.5.0          cellranger_1.1.0  backports_1.2.1   reprex_2.0.0     \n## [13] evaluate_0.14     highr_0.9         httr_1.4.2        pillar_1.6.1     \n## [17] rlang_0.4.11      readxl_1.3.1      rstudioapi_0.13   jquerylib_0.1.4  \n## [21] rmarkdown_2.8     desc_1.3.0        webshot_0.5.2     munsell_0.5.0    \n## [25] broom_0.7.6       compiler_4.1.0    modelr_0.1.8      xfun_0.23        \n## [29] pkgconfig_2.0.3   systemfonts_1.0.2 htmltools_0.5.1.1 downlit_0.2.1    \n## [33] tidyselect_1.1.1  bookdown_0.22.3   fansi_0.5.0       viridisLite_0.4.0\n## [37] crayon_1.4.1      dbplyr_2.1.1      withr_2.4.2       grid_4.1.0       \n## [41] jsonlite_1.7.2    gtable_0.3.0      lifecycle_1.0.0   DBI_1.1.1        \n## [45] magrittr_2.0.1    scales_1.1.1      cli_2.5.0         stringi_1.6.2    \n## [49] fs_1.5.0          xml2_1.3.2        bslib_0.2.5.1     ellipsis_0.3.2   \n## [53] generics_0.1.0    vctrs_0.3.8       tools_4.1.0       glue_1.4.2       \n## [57] hms_1.1.0         yaml_2.2.1        colorspace_2.0-1  sessioninfo_1.1.1\n## [61] rvest_1.0.0       knitr_1.33        haven_2.4.1       sass_0.4.0"},{"path":"einfuehrung.html","id":"einfuehrung","chapter":"Kapitel 1 Der Kurs","heading":"Kapitel 1 Der Kurs","text":"","code":""},{"path":"einfuehrung.html","id":"zuordnung-zum-modul-und-leistungsnachweis","chapter":"Kapitel 1 Der Kurs","heading":"1.1 Zuordnung zum Modul und Leistungsnachweis","text":"Dieser Kurs geh√∂rt zum Modul Fachmethodik oder Fachmethodik II und ist aus 4 SWS Praktikum und 2 SWS Seminar aufgebaut. Das wichtigste Ziel besteht darin, Ihnen einen sicheren Umgang mit R beizubringen.Den Leistungsnachweis bildet ein benoteter Praktikumsbericht.","code":""},{"path":"einfuehrung.html","id":"lernziele-des-kurses","chapter":"Kapitel 1 Der Kurs","heading":"1.2 Lernziele des Kurses","text":"\nDaten f√ºr Analysen vorbereiten\n\neigene wiederverwendbare Skripte schreiben\n\neigene Funktionen schreiben\n\neinfache Datenanalysen durchf√ºhren\n\nDaten visualisieren\n\nErgebnisse reproduzierbar im Praktikumsbericht darstellen\n","code":""},{"path":"einfuehrung.html","id":"was-mir-im-umgang-miteinander-wichtig-ist","chapter":"Kapitel 1 Der Kurs","heading":"1.3 Was mir im Umgang miteinander wichtig ist","text":"P√ºnktlichkeit bei LivesitzungenGute Vorbereitung durch erledigen der HausaufgabenRespektieren anderer MeinungenOffenheit gegen√ºber neuen Sichtweisen, Themen und MethodenGeduld mit sich selbst und den anderen üòÑ","code":""},{"path":"erste-schritte.html","id":"erste-schritte","chapter":"Kapitel 2 Erste Schritte in R","heading":"Kapitel 2 Erste Schritte in R","text":"\nLayout und Bedeutung einzelner Fenster RStudio kennen\n\nAnweisungen aus dem Skript die Konsole schicken\n\nR als Taschenrechner benutzen\n\nerste Funktionen aufrufen\n\nObjekte mit eckigen Klammern [ ] ansprechen\n\nR-Hilfeseiten aufrufen\n\nIhren ersten Olot erstellen\n","code":""},{"path":"erste-schritte.html","id":"was-ist","chapter":"Kapitel 2 Erste Schritte in R","heading":"2.1 Was ist ?","text":"R ist eine Programmiersprache f√ºr Datenanalyse und statistische Modellierung. Es ist frei verf√ºgbar (open source software) und neben Python einer der meisten benutzten Programmiersprachen zur Datenanalyse und -visualisierung. R wurde von Ross Ihaka und Robert Gentleman 1996 ver√∂ffentlicht (Ihaka Gentleman 1996). Es gibt f√ºr R eine Vielzahl von Zusatzpaketen, die die Funktionalit√§t und die Einsatzm√∂glichkeiten enorm erweitern.Sie k√∂nnen R f√ºr Ihren Computer auf der offiziellen R-Seite https://www.r-project.org/ herunter laden und installieren. Auch die Pakete finden Sie dort unter CRAN (Comprehensive R Archive Network). Auf den CRAN-Seiten finden Sie sogen. CRAN Task Views, eine √úbersicht √ºber Pakete verschiedenen Themenbereichen. F√ºr den Umweltbereich sind folgende Paketsammlungen besonders relevant:Environmetrics: Analyse von UmweltdatenMultivariate: Multivariate StatistikSpatial: Analyse von r√§umlichen DatenTimeSeries: ZeitreihenanalyseZu Beginn des Kurses, werden wir jedoch nicht auf Ihren lokalen Rechnern arbeiten, sondern auf der RStudio Server Pro, der extra f√ºr die digitale Lehre mit R der UzK eingef√ºhrt wurde. Das erm√∂glicht einen schnelleren Einstieg R und bietet eine fast-live Unterst√ºtzung durch den Dozenten beim Programmieren. Daher biete ich zu diesem fr√ºhen Zeitpunkt im Kurs keine Unterst√ºtzung bei der Installation von R auf Ihren Privatrechnern. F√ºr die ganz Ungeduldigen, gibt es hier eine kurze Einleitung zur Installation.","code":""},{"path":"erste-schritte.html","id":"was-ist-rstudio","chapter":"Kapitel 2 Erste Schritte in R","heading":"2.2 Was ist RStudio?","text":"RStudio Desktop ist eine Entwicklungsumgebung f√ºr R. Sie k√∂nnen die open source Version kostenlos f√ºr Ihren Rechner hier herunterladen.Es gibt eine live Einf√ºhrung RStudio im Kurs. Zus√§tzlich k√∂nnen Sie hier ein Video dazu ansehen.","code":""},{"path":"erste-schritte.html","id":"rstudio-server-pro","chapter":"Kapitel 2 Erste Schritte in R","heading":"2.3 RStudio Server Pro","text":"","code":""},{"path":"erste-schritte.html","id":"einloggen-und-eine-session-starten","chapter":"Kapitel 2 Erste Schritte in R","heading":"2.3.1 Einloggen und eine Session starten","text":"Zu Beginn des Kurses werden wir auf dem RStudio Server Pro (RSSP) arbeiten. Jede(r) von Ihnen wird ein pers√∂nliches Login f√ºr den Server erhalten. Dieses Login darf nicht weiter gegeben werden. Damit ich mich im Falle von Programmierfehlern Ihre Konto einloggen darf, m√ºssen Sie eine Einwilligung unterschreiben und per Email mich.Bevor Sie sich auf dem RSSP einloggen k√∂nnen, m√ºssen Sie Ihre VPN-Verbindung aktivieren (aus dem Uni-Netz geht es auch ohne). Auf den Seiten der Rechenzentrums finden Sie eine Anleitung zur Einrichtung des VPN-Zugangs.Anschlie√üend k√∂nnen Sie sich hier einloggen. Alternativ k√∂nnen Sie die Adresse des Servers https://cheops-rstudio-edu.rrz.uni-koeln.de:8787/auth-sign-.htm Ihren Browser kopieren. Nach dem Einloggen sehen Sie die Home-Oberfl√§che, aus der Sie eine neue Sitzung starten k√∂nnen (Abbildung 2.1).\nAbbildung 2.1: RStudio Server Pro Home\nUm eine neue Sitzung zu starten, klicken Sie auf den blauen Button + New Session oder auf New Session neben dem R-Symbol und stellen Sie Folgendes ein (Sie d√ºrfen der Session einen anderen Namen geben, wenn Sie m√∂chten):\nAbbildung 2.2: Einstellungen f√ºr neue Session\nAnschlie√üend sehen Sie die neue Sitzung, auf die Sie nur noch klicken m√ºssen, damit es los geht:\nAbbildung 2.3: Neue Sitzung erstellt\nDer gro√üe Vorteil des RSSPs ist, dass ich direkt Ihre Projekte eingreifen kann, wenn es mal zu Fehlern kommt. W√§hrend ich Ihrem Projekt arbeite, werden Sie kurz aus der R-Sitzung ausgeloggt. Ihnen stehen auf dem Server unbegrenzt Arbeitsstunden zur Verf√ºgung.Sowohl auf dem RSSP als auch einer lokalen Installation, ist Ihr RStudio aufgebaut wie Abbildung 2.4.\nAbbildung 2.4: Aufbau von RStudio\n","code":""},{"path":"erste-schritte.html","id":"dateimanagement","chapter":"Kapitel 2 Erste Schritte in R","heading":"2.3.2 Dateimanagement","text":"Sie werden regelm√§√üig Dateien die Sitzungen auf den RSSP hoch laden und auch herunter laden m√ºssen. F√ºr eine √ºbersichtliche Organisation bietet es sich , einen Ordner f√ºr Dateien anzulegen. Klicken Sie daf√ºr auf New Folder auf dem Reiter Files rechts unten und geben Sie dem Ordnder den Namen data.Um Dateien hoch zu laden, klicken Sie auf den Button Upload auf dem Reiter Files rechts unten (Abbildung 2.5).\nAbbildung 2.5: Dateien hoch laden\nAnschlie√üend klicken Sie auf den Button Browse unter der √úberschrift ‚ÄúFile upload‚Äù und navigieren zu der Datei, die Sie hoch laden m√∂chten (Abbildung 2.6).\nAbbildung 2.6: Dateien zum Hochladen ausw√§hlen\nUm Dateien herunter zu laden, markieren Sie zun√§chst die Datei oder die Dateien, die Sie herunterladen m√∂chten. Dann klicken Sie auf den Button im Reiter Files und dann auf Export und anschlie√üend auf Download (Abbildungen 2.7 und 2.8). Speichern Sie die Datei(en) auf Ihrem Rechner.\nAbbildung 2.7: Dateien zum herunter laden ausw√§hlen und herunter laden\n\nAbbildung 2.8: Dateien zum Herunterladen speichern\nSie sollten auch auf Ihrem eigenen Rechner einen Ordner f√ºr die Veranstaltung anlegen und darin jeweils einen Ordner f√ºr Daten und Skripte.","code":""},{"path":"erste-schritte.html","id":"lesestoff","chapter":"Kapitel 2 Erste Schritte in R","heading":"2.4 Lesestoff","text":"Kapitel 1.1 und 1.2 Ismay Kim (2021).","code":""},{"path":"erste-schritte.html","id":"aufgaben","chapter":"Kapitel 2 Erste Schritte in R","heading":"2.5 Aufgaben","text":"","code":""},{"path":"erste-schritte.html","id":"ars-haushaltsbuch","chapter":"Kapitel 2 Erste Schritte in R","heading":"2.5.1 Ars Haushaltsbuch","text":"Der angehende Datenanalyst Ar Stat m√∂chte dem Rat seiner Mutter folgen und ein Haushaltsbuch anlegen. Als erstes m√∂chte er sich einen √úberblick √ºber seine Ausgaben der Uni-Mensa verschaffen und erstellt die folgende Tabelle:\nTabelle 2.1: Ars Mensaausgaben\nWie viel hat Ar insgesamt der Woche ausgegeben?Wie viel hat er im Schnitt pro Tag ausgegeben?Wie stark schwanken seine Ausgaben?Leider hat Ar sich beim √ºbertragen der Daten vertippt. Er hat Dienstag seine Freundin zum Essen eingeladen und 7,95 ‚Ç¨ statt 2,90 ‚Ç¨ ausgegeben.Korrigieren Sie Ars Fehler.Wie ver√§ndern sich die Ergebnisse aus den Teilaufgaben 1 bis 3 Warum?","code":""},{"path":"erste-schritte.html","id":"rob2","chapter":"Kapitel 2 Erste Schritte in R","heading":"2.5.2 Fehlende Werte","text":"R kodiert fehlende Werte mit NA. Ar Stat hat Montag der darauffolgenden Woche der Mensa gegessen, aber vergessen die Ausgaben zu notieren.\nTabelle 2.2: Ars Mensaausgaben, cont.\nWie √§ndert der fehlende Wert die Berechnung der Summe?Lesen Sie passiert, wenn der Datenvektor bei der Berechnung der Summe fehlende Werte enth√§lt. Rufen Sie dazu die Hilfe auf, .e.¬†?sum.Korrigieren Sie die Berechnung der Summe entsprechend.","code":""},{"path":"erste-schritte.html","id":"firstplot","chapter":"Kapitel 2 Erste Schritte in R","heading":"2.5.3 Ihr erster Plot","text":"Vor allem Anfang kann die Lernkurve R recht flach verlaufen. Daher sollten Sie nicht vergessen, warum Sie R lernen, n√§mlich um echte Datens√§tze zu analysieren.Auch wenn Sie den Code unten noch nicht (ganz) verstehen, kopieren Sie ihn Ihr R und lassen Sie ihn laufen.Welche Daten sind diesem Datensatz enthalten? Nutzen Sie die Hilfe, .e.¬†?gapminder.stellen die Farben der Abbildung dar?wird durch die Symbolgr√∂√üe dargestellt?Wie w√ºrden Sie den Zusammenhang zwischen den Variablen GDP per capita und Life expectancy beschreiben?","code":"\nlibrary(tidyverse)\nlibrary(gapminder)\n\ngapminder2007 <- gapminder %>% \n  filter(year == 2007)\n\nggplot(gapminder2007, aes(x = gdpPercap, y = lifeExp, color = continent, size = pop)) +\n  geom_point() +\n  scale_x_log10() +\n  xlab('GDP per capita') +\n  ylab('Life expectancy') +\n  labs(title = 'Gapminder data for the year 2007')"},{"path":"erste-schritte.html","id":"r-als-taschenrechner","chapter":"Kapitel 2 Erste Schritte in R","heading":"2.5.4 R als Taschenrechner","text":"R ist ein gro√üer Taschenrechner mit vielen voreingebauten Funktionen. Es gelten die √ºblichen Rechenregeln wie z.B. Punkt-vor-Strich und die Klammern.Schreiben Sie den Code, der 2 und 10 addiertDas korrekte Multiplikationszeichen R ist *.Geben Sie den folgenden Befehl korrekt R ein: (2 + 10) \\(\\times\\) 27Bei Dezimalzahlen wird der Dezimalpunkt und nicht das Komma verwendet. Das ist wichtig zu beachten, wenn Sie sp√§ter Daten R einlesen m√∂chten.Berechnen Sie die Summe von 2,34 und 4,98.","code":""},{"path":"erste-schritte.html","id":"zuweisungen","chapter":"Kapitel 2 Erste Schritte in R","heading":"2.5.5 Zuweisungen","text":"R arbeitet man mit Objekten. Ein Objekt kann alles M√∂gliche sein: eine Variable, Daten, Vektoren etc. Wenn also das Ergebnis einer Berechnung oder ein Datenobjekt im R-Arbeitsbereich (workspace) zur Verf√ºgung stehen soll, muss daraus ein Objekt erstellt werden.Objekte erstellt man, indem man ihnen Namen gibt. Diesen Vorgang nennt man Zuweisung (assignment). Im Beispiel unten wird ein Objekt, diesem Fall ein Skalar, namens x erzeugt mit dem Wert 42. Um den Wert von x anzuzeigen, tippen Sie x ein.Zuweisungen k√∂nnen R entweder mit dem = erfolgen oder mit <-. Beide Varianten sind gleichwertig. Dabei ist allerdings Pfeilrichtung entscheidend! x <- 42 bedeutet: die linke Seite (Zahl 42) wird dem Objekt x zugeordnet. Wenn man die Pfeilrichtung umdreht, macht die Zuweisung keinen Sinn und man erh√§lt eine Fehlermeldung.Objektnamen k√∂nnen (fast) frei gew√§hlt werden. Sie m√ºssen mit einem Buchstaben beginnen und d√ºrfen keine Sonderzeichen enthalten. Bei l√§ngeren Namen empfiehlt sich ein _. Streng verboten sind Namen von vordefinierten Funktionen!Erstellen Sie ein Objekt namens mein_objekt und weisen Sie ihm das Ergebnis der Berechnung \\(23^{2}\\) zu. Eine Potenz berechnen Sie mit ^.Eine Zuweisung kann auch kompliziertere Anweisungen enthalten. Hier erstellen wir z.B. einen Vektor mit Hilfe der Funktion c (concatenate) und weisen das Ergebnis dem Objekt my_a zu.","code":"\nx <- 42\n\n# Zeige den Wert von x\nx\n# Sinnvolle Zuweisung\nx <- 42\n# Gleichwertige sinnvolle Zuweisung\nx = 42\n# Sinnloser Ausdruck. Fehlermeldung!\nx -> 42## Error in 42 <- x: ung√ºltige (do_set) linke Seite in Zuweisung\nmy_a <- c(32, 54, 1.2, 398)"},{"path":"erste-schritte.html","id":"funktionsaufruf","chapter":"Kapitel 2 Erste Schritte in R","heading":"2.5.6 Funktionsaufruf","text":"R gibt es eine Vielzahl von vordefinierten Funktionen. Ein Funktionsaufruf hat immer die gleiche Form: mach_das(damit) oder mach_das(damit, und_mit_dieser_einstellung). Z.B. wird die Summe auf einem Objekt mein_objekt mit sum(mein_objekt) berechnet.Erstellen Sie einen Vektor mit den Zahlen 32, 54, 1,2 und 398 und weisen Sie ihn der Variablen my_a zu.Berechnen Sie die summe von my_a.Sie k√∂nnen im √úbrigen auch Vektoren sinnvoll addieren.Erstellen Sie einen Vektor my_b mit der passenden L√§nge und addieren Sie ihn zum Vektor my_a. Die Addition erfolgt elementeweise.H√§ufig wollen wir f√ºr unsere Daten den Mittelwert berechnen.Berechnen Sie den Mittelwerts von my_aBerechnen Sie die Standardabweichung von my_a.","code":""},{"path":"erste-schritte.html","id":"objekte-ansprechen","chapter":"Kapitel 2 Erste Schritte in R","heading":"2.5.7 Objekte ansprechen","text":"Um das ‚ÄúInnenleben‚Äù der Objekte R anzusprechen, gibt es verschieden M√∂glichkeiten. diesem Tutorial konzentrieren wir uns auf Vektoren. Um die einzelnen Komponenten im Vektor anzusprechen, benutzt man eckige Klammern [ ]. Um eine bestimmte Komponente zu adressieren (anzusprechen), schreibt man die Platznummer der Komponente die Klammer. Wenn man im Vektor my_c, z.B. die dritte Komponente extrahieren m√∂chte, dann schreibt man my_c[3]Wir k√∂nnen auch Vektoren erstellen, bei denen einzelne Elemente benannt sind.Elemente solchen Vektoren kann man mit Namen eckigen Klammern ansprechen. Die Namen m√ºssen Anf√ºhrungszeichen geschrieben werden. Es spielt keine Rolle, ob Sie einfache oder doppelte Anf√ºhrungszeichen benutzen.Fragen Sie nach dem Element Koeln im Vektor benannt.","code":"\nmy_c <- c(2, 45.7, pi, sqrt(23), 2^6)\nmy_c[3]## [1] 3.141593\nbenannt <- c('Koeln' = 50667, 'Berlin' = 10965, \"Stuttgart\" = 70173)"},{"path":"erste-schritte.html","id":"ihre-arbeit-einreichen","chapter":"Kapitel 2 Erste Schritte in R","heading":"2.6 Ihre Arbeit einreichen","text":"Speichern Sie Ihre .R Datei auf dem Server ab.Laden Sie diese Datei herunter und speichern Sie sie auf Ihrem Computer ab.Laden Sie die Datei auf ILIAS der dazugeh√∂rigen √úbung hoch.Nach der Abgabe erhalten Sie die Musterl√∂sung.Vergelichen Sie Ihre L√∂sung sebstst√§ndig mit der Musterl√∂sung.Stellen Sie entweder Campuswire (im class-chat) oder der n√§chsten live Sitzung Fragen, falls Sie bei den Aufgaben etwas nicht verstanden haben und die Musterl√∂sung es nicht aufkl√§ren konnte.","code":""},{"path":"reproduzieren.html","id":"reproduzieren","chapter":"Kapitel 3 R Markdown","heading":"Kapitel 3 R Markdown","text":"\nWichtigkeit der Reproduzierbarkeit erkl√§ren\n\nBegriff literate programming definieren\n\nAufbau einer RMarkdown-Datei erkl√§ren\n\nEinen einfachen ersten reproduzierbaren Bericht schreiben\n","code":""},{"path":"reproduzieren.html","id":"warum-reproduzierbarkeit-in-der-forschung-wichtig-ist","chapter":"Kapitel 3 R Markdown","heading":"3.1 Warum Reproduzierbarkeit in der Forschung wichtig ist","text":"","code":""},{"path":"reproduzieren.html","id":"literate-programming-idee-von-donald-knuth","chapter":"Kapitel 3 R Markdown","heading":"3.2 Literate Programming Idee von Donald Knuth","text":"Die Idee, dass man den Code und die dazugeh√∂rige Interpretation (Text, Bericht etc.) nicht von einander trennen sollte, geht auf Knuth (1984) zur√ºck. Mit Literate Programming meinte Knuth, dass Programme auch nichts anderes wie literarische Werke sind. Er setzte den Fokus darauf, mit Programmen menschlichen Benutzern zu erkl√§ren, man den Computer machen lassen m√∂chte. Also weg vom computer- hin zum mensch-zentrierten Zugang. wird Programmieren und unserem Fall die Datenanalyse verst√§ndlich und vor allem reproduzierbar.Leider ist es unserer modernen Forschungslandschaft immer noch nicht Standard. Das Trennen von Analyseergebnissen und Berichten (Forschungsartikeln) sorgt f√ºr viele (unentdeckte und unn√∂tige) Fehler und Frust.","code":""},{"path":"reproduzieren.html","id":"reproduzierbare-berichte-mit-r-markdown","chapter":"Kapitel 3 R Markdown","heading":"3.3 Reproduzierbare Berichte mit R Markdown","text":"R hat sein eigenes System von reproduzierbaren Berichten, genannt R Markdown (Xie, Allaire, Grolemund 2021). Es ist benutzerfreundlich und erm√∂glicht unterschiedliche Formate von Berichten, wie HTML-Dokumente, PDF-Dateien, Pr√§sentationsfolien usw.Es wird Sie vielleicht √ºberraschen, aber das Skript, das Sie gerade lesen ist nichts anderes als ein ‚Äúliterarisch‚Äù programmiertes Buch R Bookdown (Xie, Allaire, Grolemund 2021), einem R-Paket speziell f√ºr lange R Markdown-Dokumente.Wir werden vor allem mit R Notebooks arbeiten, die eine gute Interaktion zwischen dem geschriebenen Text und dem R-Code erm√∂glichen. Das Notebook kann sowohl ein HTML-Dokument als auch PDF oder Word als endg√ºltiges Dokument umgewandelt werden. Diesen Prozess nennt man knit.","code":""},{"path":"reproduzieren.html","id":"ein-neues-r-notebook-erstellen","chapter":"Kapitel 3 R Markdown","heading":"3.4 Ein neues R Notebook erstellen","text":"Um ein neues R Notebook zu erstellen, klicken Sie das leine gr√ºne Plus oben links und w√§hlen Sie R Notebook aus. Sie k√∂nnen es erst einmal bei untitled belassen (Abbildung 3.1).\nAbbildung 3.1: Neues R Notebook anlegen\nWenn Sie ein neues Notebook erstellen, enth√§lt das Template etwas Code. Lesen Sie sich das ruhig noch einmal durch, da es ein paar hilfreiche Tastenk√ºrzel und Tipps. Danach k√∂nnen Sie den Text unterhalb des Headers l√∂schen.","code":""},{"path":"reproduzieren.html","id":"header","chapter":"Kapitel 3 R Markdown","heading":"3.5 Der Header eines Notebooks","text":"Ein R Notebook (und jedes andere R Markdown Dokument) besteht aus einem Header (Kopf) und dem eigentlichen Text und Code. Der Header hat dabei ein bestimmtes Layout, auf das Sie unbedingt achten m√ºssen (Rechtschreibung!). Der Header ist immer zwischen drei Minuszeichen --- eingeschlossen. Bei komplizierteren Headern gibt es auch Einr√ºckungen (mit der Tab-Taste), die auch Bedeutung haben (s. weiterf√ºhrende Literatur). Wir bleiben bei einem einfachen Header ohne Einr√ºckungen (Abbildung 3.2).\nAbbildung 3.2: Einen neuen Chunk hinzuf√ºgen\nText kann einfach unterhalb des Headers und au√üerhalb der Chunks getippt werden. Die wichtigsten Layoutelemente f√ºr den Text finden Sie hier. R Markdown unterst√ºtzt mathematische Notation Latex-Stil. Eine Einf√ºhrung Latex w√ºrde dieser Stelle aber zu weit f√ºhren.Das R Notebook hat den Vorteil, dass man √ºber den Button Preview oben der Leiste sofort die Ergebnisse anzeigen lassen kann. Sie m√ºssen also nicht knitten. Falls Sie es doch m√∂chten, klicken Sie auf das kleine Dreieck neben dem Preview und suchen Sie sich ein Output-Format aus. Ein einmal ‚Äúgeknittetes‚Äù Notebook ist kein Notebook mehr (kein Preview). Damit es wierder zum Nobebook wird, m√ºssen Sie im Header output: html_notebbok einstellen (Abbildung 3.2).","code":""},{"path":"reproduzieren.html","id":"wichtigste-regeln-f√ºr-reproduzierbarkeit","chapter":"Kapitel 3 R Markdown","heading":"3.6 Wichtigste Regeln f√ºr Reproduzierbarkeit","text":"","code":""},{"path":"reproduzieren.html","id":"lesestoff-1","chapter":"Kapitel 3 R Markdown","heading":"3.7 Lesestoff","text":"Intro zu Kapitel 2 (Basics), Kapitel 3.2.1 und 3.2.2 Xie, Allaire, Grolemund (2021)","code":""},{"path":"reproduzieren.html","id":"weiterf√ºhrende-literatur","chapter":"Kapitel 3 R Markdown","heading":"3.8 Weiterf√ºhrende Literatur","text":"r4ds, Kapitel 27 (Wickham Grolemund 2021)","code":""},{"path":"reproduzieren.html","id":"aufgaben-1","chapter":"Kapitel 3 R Markdown","heading":"3.9 Aufgaben","text":"","code":""},{"path":"reproduzieren.html","id":"erstes-notebook","chapter":"Kapitel 3 R Markdown","heading":"3.9.1 Erstes Notebook","text":"Erstellen Sie ein R Notebook.F√ºgen Sie Layoutelemente hinzu:\n√úberschrift\nUnter√ºberschrift\nkursiver Text\nein Exponent: R2\nein Mathematikelement: \\(x^2\\)\neine Liste\n√úberschriftUnter√ºberschriftkursiver Textein Exponent: R2ein Mathematikelement: \\(x^2\\)eine ListeNutzen Sie die unter 3.5 verlinkte Liste der Layoutelemente.","code":""},{"path":"reproduzieren.html","id":"erste-schritte-als-notebook","chapter":"Kapitel 3 R Markdown","heading":"3.9.2 Erste Schritte als Notebook","text":"Wandeln Sie beide R-Skripte der ersten Sessions R Notebooks um.F√ºgen Sie mehr Erkl√§rungstext zu den einzelnen Schritten hinzuGliedern Sie Ihre Notebooks mit passenden Layoutelementen.","code":""},{"path":"reproduzieren.html","id":"exploration-eines-datensatzes","chapter":"Kapitel 3 R Markdown","heading":"3.9.3 Exploration eines Datensatzes","text":"Arbeiten Sie das Kapitel 1.4 Explore first datasets Ismay Kim (2021) durch.","code":""},{"path":"ggplot.html","id":"ggplot","chapter":"Kapitel 4 Einf√ºhrung in ggplot2","heading":"Kapitel 4 Einf√ºhrung in ggplot2","text":"\nAufbau des Aufrufs der Funktion ggplot() kennen\n\n5 wichtigste Grafiktypen kennen und einsetzten\n","code":""},{"path":"ggplot.html","id":"aufbau-eines-visualisierungsbefehls","chapter":"Kapitel 4 Einf√ºhrung in ggplot2","heading":"4.1 Aufbau eines Visualisierungsbefehls","text":"Das Paket ggplot2 ist ein sehr m√§chtiges Visualisierungswerkzeug. Der Name steht f√ºr ‚Äúgrammar graphics.‚Äù Das Bedeutet, dass man mit Hilfe von verschiedenen Funktion ggplot2 seine Grafik Schritt f√ºr Schritt aufbaut, wie einen (grammatikalisch korrekten) Satz. aller K√ºrze bedeutet das:Eine statistische Grafik ist eine Zuordnung (mapping) von Variablen einem Datensatz (data) zu (√§sthetischen) Attributen (aes) von geometrischen Objekten (geom).Wir m√ºssen also f√ºr das Visualisieren Folgendes festlegen:data: der Datensatz, der die Variablen enth√§lt, die wir darstellen m√∂chten.data: der Datensatz, der die Variablen enth√§lt, die wir darstellen m√∂chten.aes: (√§sthetische) Attribute f√ºr die geometrischen Objekte, die dargestellt werden sollen. Diese Attribute sind, z.B. die x und y Koordinaten, Farbe, Form und Gr√∂√üe der geometrischen Obekteaes: (√§sthetische) Attribute f√ºr die geometrischen Objekte, die dargestellt werden sollen. Diese Attribute sind, z.B. die x und y Koordinaten, Farbe, Form und Gr√∂√üe der geometrischen Obektegeom: geometrische Objekte, die dargestellt werden sollen, z.B. Punkte, Linien, Boxen, S√§ulen etc.geom: geometrische Objekte, die dargestellt werden sollen, z.B. Punkte, Linien, Boxen, S√§ulen etc.Wir laden zun√§chst die n√∂tigen Bibliotheken und filtern den Datensatz gapminder, um nur die Daten aus dem Jahr 2007 zu visualisieren. Die Bibliothek ggplot2 ist tidyverse enthalten und wird mitgeladen.","code":"\nlibrary(tidyverse)\nlibrary(gapminder)\n\ngapminder2007 <- gapminder %>% \n  filter(year == 2007)"},{"path":"ggplot.html","id":"punktdiagramm","chapter":"Kapitel 4 Einf√ºhrung in ggplot2","heading":"4.2 Punktdiagramm","text":"Ein typischer Befehl zur Visualisierung w√ºrde also aussehen:Worten k√∂nnte man es vielleicht wie folgt umschreiben:Nimm den Datensatz (data) gapminder undNimm den Datensatz (data) gapminder undordne folgende Attribute zu:\nauf die x-Achse die Variable gdpPercap\nauf die y-Achse die Variable lifeExp\nf√§rbe ein mit Hilfe der Variablen continent\nbestimme die Gr√∂√üe der Symbole mit Hilfe der Variablen pop\nordne folgende Attribute zu:auf die x-Achse die Variable gdpPercapauf die y-Achse die Variable lifeExpf√§rbe ein mit Hilfe der Variablen continentbestimme die Gr√∂√üe der Symbole mit Hilfe der Variablen popStelle das Ganze als geometrisches Objekte Punkte dar (geom_point())Stelle das Ganze als geometrisches Objekte Punkte dar (geom_point())Sie sehen, dass diese Zuordnungen klar nach einer Legende verlangen, die dann auch automatisch sowohl f√ºr die Farbe als auch f√ºr die Gr√∂√üe der Symbole, erstellt wird.Die Anweisungen zur Visualisierung ggplot2 werden mit einem + verbunden. Man kann (und diesem Fall soll) weitere Anweisungen geben. Z.B. sind die Beschriftungen der beiden Achsen nichtssagend und m√ºssen verbessert werden. Wir h√§ngen mit eine +-Zeichen weitere Befehle hinzu:","code":"\nggplot(data = gapminder2007, mapping = aes(x = gdpPercap, y = lifeExp, color = continent, size = pop)) +\n  geom_point()\nggplot(data = gapminder2007, mapping = aes(x = gdpPercap, y = lifeExp, color = continent, size = pop)) +\n  geom_point() + \n  labs(x = 'Bruttoinlandsprodukt pro Kopf (US$)', y = 'Lebenserwartung (Jahre)',\n       color = 'Kontinent', size = 'Bev√∂lkerung')"},{"path":"ggplot.html","id":"weitere-geoms","chapter":"Kapitel 4 Einf√ºhrung in ggplot2","heading":"4.3 Weitere geoms","text":"Das geom_point() produziert eine xy-Grafik (scatter plot). Weiter wichtige Grafiktypen sindgeom_line(): Liniengeom_histogram(): Histogrammgeom_boxplot(): Boxplotgeom_bar(): S√§ulen","code":""},{"path":"ggplot.html","id":"scatter","chapter":"Kapitel 4 Einf√ºhrung in ggplot2","heading":"4.4 Liniendiagramm","text":"Es macht wenig Sinn, die obere Grafik mit Linien darzustellen. Allerdings eignen sich Linien sehr gut, um einen zeitlichen Verlauf zu visualisieren. Daher filtern wir aus dem Datensatz gapminder die Zeitreihen f√ºr Frankreich und Deutschland heraus. Weil wir jetzt zwei L√§nder haben m√∂chten, muss beim Filtern ein Vektor mit L√§ndernamen angegeben werden und statt == der Operator %%. Wir werden sp√§ter noch ausf√ºhrlich auf diese Operatoren zur√ºck kommen.","code":"\nfrance_germany <- gapminder %>% \n  filter(country %in% c('France', 'Germany'))\nggplot(data = france_germany, mapping = aes(x = year, y = gdpPercap, color = country)) +\n  geom_line()"},{"path":"ggplot.html","id":"histogramm","chapter":"Kapitel 4 Einf√ºhrung in ggplot2","heading":"4.5 Histogramm","text":"Wie ist das GDP im Jahre 2007 Afrika und Europa verteilt? Dazu nutzen wir das Histogramm und filtern die Daten vorher entsprechend. Als √Ñsthetik eignet sich hier fill besser als color.","code":"\nafrica_europe <- gapminder2007 %>% \n  filter(continent %in% c('Africa', 'Europe'))\n\nggplot(africa_europe, mapping = aes(x = gdpPercap, fill = continent)) +\n  geom_histogram(bins = 20)"},{"path":"ggplot.html","id":"boxplot","chapter":"Kapitel 4 Einf√ºhrung in ggplot2","heading":"4.6 Boxplot","text":"Wie ist das GDP im Jahre 2007 auf verschiedenen Kontinenten verteilt? Ein Histogramm mit allen Kontinenten w√ºrde schnell sehr un√ºbersichtlich werden. Das geht mit einem Boxplot besser.","code":"\nggplot(gapminder2007, mapping = aes(x = continent, y = gdpPercap)) +\n  geom_boxplot()"},{"path":"ggplot.html","id":"s√§ulendiagramm","chapter":"Kapitel 4 Einf√ºhrung in ggplot2","heading":"4.7 S√§ulendiagramm","text":"Wie viele Eintr√§ge gibt es pro Kontinent? Das S√§ulendiagramm z√§hlt f√ºr uns die Eintr√§ge im Datensatz zusammen","code":"\nggplot(data = gapminder, mapping = aes(x = continent)) +\n  geom_bar()"},{"path":"ggplot.html","id":"lesestoff-2","chapter":"Kapitel 4 Einf√ºhrung in ggplot2","heading":"4.8 Lesestoff","text":"Kapitel 2.1 Ismay Kim (2021)","code":""},{"path":"ggplot.html","id":"aufgaben-2","chapter":"Kapitel 4 Einf√ºhrung in ggplot2","heading":"4.9 Aufgaben","text":"","code":""},{"path":"ggplot.html","id":"grafiken-richtig-beschriften","chapter":"Kapitel 4 Einf√ºhrung in ggplot2","heading":"4.9.1 Grafiken richtig beschriften","text":"Bis auf die Grafik 4.4 fehlen bei den Grafiken oben ordentliche Achsenbeschriftungen und Titel f√ºr die Legenden. Erg√§nzen Sie den Code entsprechend.","code":""},{"path":"ggplot.html","id":"zeitreihen","chapter":"Kapitel 4 Einf√ºhrung in ggplot2","heading":"4.9.2 Zeitreihen","text":"Stellen Sie den zeitlichen Verlauf der Lebenserwartung f√ºnf europ√§ischen L√§ndern Ihrer Wahl dar. F√§rben Sie die Linien nach L√§ndern.","code":""},{"path":"ggplot.html","id":"boxplots","chapter":"Kapitel 4 Einf√ºhrung in ggplot2","heading":"4.9.3 Boxplots","text":"Stellen Sie die Lebenserwartung im Jahr 1952 und im Jahr 2007 pro Kontinent dar. Das sind zwei verschiedene Boxplots.","code":""},{"path":"ggplot.html","id":"ihre-arbeit-einreichen-1","chapter":"Kapitel 4 Einf√ºhrung in ggplot2","heading":"4.10 Ihre Arbeit einreichen","text":"Speichern Sie Ihr Notebook ab und laden Sie nur die .Rmd Datei vom Server.Laden Sie Ihre .Rmd Datei ILIAS hoch. Beachten Sie die Deadline!Sie erhalten die Musterl√∂sung nach dem Hochladen.","code":""},{"path":"daten-einlesen-und-visualisieren.html","id":"daten-einlesen-und-visualisieren","chapter":"Kapitel 5 Daten einlesen und visualisieren","heading":"Kapitel 5 Daten einlesen und visualisieren","text":"\nDaten aus Textdateien R einlesen\n\ndata.frame speichern\n\nGrafiken anpassen (nebeneinander, Facetten, Transparenz)\n\nGrafiken speichern\n","code":""},{"path":"daten-einlesen-und-visualisieren.html","id":"daten-aus-textdateien-in-r-einlesen","chapter":"Kapitel 5 Daten einlesen und visualisieren","heading":"5.1 Daten aus Textdateien in R einlesen","text":"Um Daten aus Textdateien (z.B. aus .csv, .txt, .dat) R zu importieren (.e.¬†einzulesen) werden wir die Bibliothek readr aus tidyverse benutzen. Wir laden erst einmal tidyverse.Wir gehen davon aus, dass die Daten im Ordner data gespeichert sind. Falls Ihre Daten einem anderen Ort abgelegt sind, m√ºssen Sie den Pfad beim Einlesen entsprechend anpassen.Um die Daten zu laden, gibt es der Bibliothek readr verschiedene Funktionen, die alle mit read_ beginnen. Die allgemeinste davon ist read_delim. Darin kann man explizit einstellen, mit welchem Zeichen (z.B. Komma, Strichpunkt etc.) die einzlenen Spalten der zu importierenden Datei getrennt sind.Ein kurzer Blick auf den Datensatz. Hierbei handelt es sich um Daten zu Treibhausgasemissionen auf der EU-Ebene, die ich bei eurostat 30.4.2021 heruntergeladen und vorgefiltert habe. Die Datenbank bietet sehr viele Datens√§zte und ist als Quelle f√ºr Berichte hervorragend geeignet üòÑ.Das Ergebnis des Einlesens mit read_ Funktionen ist immer ein tibble. Kategorische Variablen werden als Text (character) eingelesen und nicht factor umgewandelt. Wenn man factor m√∂chte, muss man die Variablen per Hand umwandeln.Wir verschaffen uns einen kurzen √úberblick √ºber die Daten.Um die Anzahl der einzelnen L√§nder zu ermitteln, sehen wir uns die L√§nge der Ausgabe der Funktion unique() , die die einzelnen verschiedenen Eintr√§ge ermitteln kann. Es sind Eintr√§ge f√ºr 33 verschiedene L√§nder vorhanden.","code":"\nlibrary(tidyverse)\nemissions <- read_delim(file = 'data/emissions.csv', delim = ';')## \n## ‚îÄ‚îÄ Column specification ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n## cols(\n##   unit = col_character(),\n##   airpol = col_character(),\n##   vehicle = col_character(),\n##   geo = col_character(),\n##   time = col_date(format = \"\"),\n##   values = col_double()\n## )\nemissions## # A tibble: 2,871 x 6\n##    unit     airpol                  vehicle    geo             time       values\n##    <chr>    <chr>                   <chr>      <chr>           <date>      <dbl>\n##  1 Million‚Ä¶ Greenhouse gases (CO2,‚Ä¶ Fuel comb‚Ä¶ Austria         2018-01-01  14.4 \n##  2 Million‚Ä¶ Greenhouse gases (CO2,‚Ä¶ Fuel comb‚Ä¶ Belgium         2018-01-01  14.4 \n##  3 Million‚Ä¶ Greenhouse gases (CO2,‚Ä¶ Fuel comb‚Ä¶ Bulgaria        2018-01-01   5.78\n##  4 Million‚Ä¶ Greenhouse gases (CO2,‚Ä¶ Fuel comb‚Ä¶ Switzerland     2018-01-01  11.0 \n##  5 Million‚Ä¶ Greenhouse gases (CO2,‚Ä¶ Fuel comb‚Ä¶ Cyprus          2018-01-01   1.38\n##  6 Million‚Ä¶ Greenhouse gases (CO2,‚Ä¶ Fuel comb‚Ä¶ Czechia         2018-01-01  11.9 \n##  7 Million‚Ä¶ Greenhouse gases (CO2,‚Ä¶ Fuel comb‚Ä¶ Germany (until‚Ä¶ 2018-01-01  97.8 \n##  8 Million‚Ä¶ Greenhouse gases (CO2,‚Ä¶ Fuel comb‚Ä¶ Denmark         2018-01-01   6.85\n##  9 Million‚Ä¶ Greenhouse gases (CO2,‚Ä¶ Fuel comb‚Ä¶ Estonia         2018-01-01   1.52\n## 10 Million‚Ä¶ Greenhouse gases (CO2,‚Ä¶ Fuel comb‚Ä¶ Greece          2018-01-01   7.61\n## # ‚Ä¶ with 2,861 more rows\nsummary(emissions)##      unit              airpol            vehicle              geo           \n##  Length:2871        Length:2871        Length:2871        Length:2871       \n##  Class :character   Class :character   Class :character   Class :character  \n##  Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n##                                                                             \n##                                                                             \n##                                                                             \n##                                                                             \n##       time                values         \n##  Min.   :1990-01-01   Min.   :  0.00609  \n##  1st Qu.:1997-01-01   1st Qu.:  0.25564  \n##  Median :2004-01-01   Median :  1.92403  \n##  Mean   :2004-01-01   Mean   :  8.52836  \n##  3rd Qu.:2011-01-01   3rd Qu.:  6.93899  \n##  Max.   :2018-01-01   Max.   :119.77824  \n##                       NA's   :232\nlength(unique(emissions$geo))## [1] 33"},{"path":"daten-einlesen-und-visualisieren.html","id":"legende-verschieben-und-facetten","chapter":"Kapitel 5 Daten einlesen und visualisieren","heading":"5.2 Legende verschieben und Facetten","text":"Wir stellen die Zeitreihen der Emissionen eingef√§rbt nach Land dar. Die L√§nder stehen der Variablen geo.Als erstes f√§llt auf, dass die Legende sehr umfangreich ist (wir haben ja 33 L√§nder im Datensatz). Daher w√§re es g√ºnstig, die Legende unterhalb der Grafik zu positionieren und den Titel der Legende oberhalb der Legende zu belassen. Das geht mit Hilfe der Funktionen theme() und guides(). Wie immer, werden sie im Plotaufbau (denken Sie grammer graphics) mit + angeh√§ngt.Die Zeitreihen sehen echt seltsam aus. Wenn wir uns die Variable vehicle ansehen, wird auch klar, warum. Wir stellen gerade Emissionen f√ºr verschiedene Fahrzeuge dar, d.h. wir mischen mehrere Zeitreihen zusammen.Die einfachste L√∂sung ist, drei verschiedene Grafiken pro Verkehrsmittel zu erstellen. Dies gelingt sehr leicht mit der Funktion facet_wrap(), die den Namen der Variablen erwartet, mit Hilfe derer die Grafiken gesplittet werden sollen. Vor der Variablen muss eine Tilde (~) stehen. unserem Fall wollen wir nach Verkehrsmittel splitten, d.h. mit Hilfe der Varialben vehicle.Da die Emissionen sehr unterschiedlich sind, macht es Sinn, die Skalierungen der y-Achsen anzupassen. Aber Achtung: Das sollten Sie Ihren Berichten unbedingt ansprechen (z.B. der Bildunterschrift), da man unterschiedliche Skalierunge sehr leicht √ºbersieht und dann die Interpretation der Daten leicht die falsche Richtung gehen kann. Der Funktionsparameter labeller = label_wrap_gen() sorgt f√ºr geschickte Zeilenumbr√ºche bei zu langen Labels. Zum Vergleich k√∂nnen Sie ihn mal weglassen und sehen, dann passiert.","code":"\nggplot(data = emissions, mapping = aes(x = time, y = values, colour = geo)) +\n  geom_line()## Warning: Removed 7 row(s) containing missing values (geom_path).\nggplot(data = emissions, mapping = aes(x = time, y = values, colour = geo)) +\n  geom_line() +\n  theme(legend.position = \"bottom\") +\n  guides(colour = guide_legend(title.position = \"top\"))## Warning: Removed 7 row(s) containing missing values (geom_path).\nunique(emissions$vehicle)## [1] \"Fuel combustion in cars\"                       \n## [2] \"Fuel combustion in heavy duty trucks and buses\"\n## [3] \"Fuel combustion in railways\"\nggplot(data = emissions, mapping = aes(x = time, y = values, colour = geo)) +\n  geom_line() +\n  facet_wrap(~vehicle) +\n  theme(legend.position = \"bottom\") +\n  guides(colour = guide_legend(title.position = \"top\"))## Warning: Removed 203 row(s) containing missing values (geom_path).\nggplot(data = emissions, mapping = aes(x = time, y = values, colour = geo)) +\n  geom_line() +\n  facet_wrap(~vehicle, scales = 'free_y', labeller = label_wrap_gen()) +\n  theme(legend.position = \"bottom\") +\n  guides(colour = guide_legend(title.position = \"top\"))## Warning: Removed 203 row(s) containing missing values (geom_path)."},{"path":"daten-einlesen-und-visualisieren.html","id":"fehlerbalken-und-co.","chapter":"Kapitel 5 Daten einlesen und visualisieren","heading":"5.3 Fehlerbalken und Co.","text":"Um die Variabilit√§t der Daten grafisch darzustellen, bieten sich Fehlerbalken, Bereiche etc. . Daf√ºr hat ggplot2 spezielle geoms. Hier ein Beispiel aus dem ggplot2 Buch Wickham (2020).Sie sehen, dass man ggplot Objekte wie andere Objekte R zuweisen kann, um mit ihnen sp√§ter zu arbeiten. diesem Fall ist base ein ggplot Objekt.","code":"\ny <- c(18, 11, 16)\ndf <- tibble(x = 1:3, y = y, se = c(1.2, 0.5, 1.0))\n\nbase <- ggplot(df, aes(x, y, ymin = y - se, ymax = y + se))\nbase + geom_pointrange()\nbase + geom_errorbar()\nclass(base)## [1] \"gg\"     \"ggplot\""},{"path":"daten-einlesen-und-visualisieren.html","id":"mehrere-grafiken-nebeneinander","chapter":"Kapitel 5 Daten einlesen und visualisieren","heading":"5.4 Mehrere Grafiken nebeneinander","text":"Um mehrere Grafiken nebeneinander zu plotten, nutzen wir die Funktion grid.arrange() aus der Bibliothek gridExtra. Um sie zu nutzen, m√ºssen wir die ggplot Objekte abspeichern und dann mit Hilfe der Funktion grid.arrange, wie der Name schon sagt, ‚Äúarrangieren.‚Äù diesem Fall wollen wir der Gesamtgrafik eine Zeile (nrow = 1), sodass die Grafiken nebeneinander stehen.Um die Grafiken untereinander abzubilden, bestellen wir entsprechend zwei Zeilen.","code":"\nlibrary(gridExtra)\n\np1 <- base + geom_pointrange()\np2 <- base + geom_errorbar()\n\nalles <- grid.arrange(p1, p2, nrow = 1)\nalles <- grid.arrange(p1, p2, nrow = 2)"},{"path":"daten-einlesen-und-visualisieren.html","id":"grafiken-abspeichern","chapter":"Kapitel 5 Daten einlesen und visualisieren","heading":"5.5 Grafiken abspeichern","text":"","code":"\nggsave(filename = 'Fehlerbalken.pdf', plot = alles, device = 'pdf', width = 7, height = 5)"},{"path":"daten-einlesen-und-visualisieren.html","id":"weitere-statistsiche-zusammenfassungen-in-grafiken","chapter":"Kapitel 5 Daten einlesen und visualisieren","heading":"5.6 Weitere statistsiche Zusammenfassungen in Grafiken","text":"Arbeiten Sie selbst√§ndig das Kapitel 5: Statistical summaries Wickham (2020) (https://ggplot2-book.org/statistical-summaries.html).","code":""},{"path":"daten-einlesen-und-visualisieren.html","id":"lesestoff-3","chapter":"Kapitel 5 Daten einlesen und visualisieren","heading":"5.7 Lesestoff","text":"Kapitel 2.2 bis 2.9 Ismay Kim (2021)","code":""},{"path":"daten-einlesen-und-visualisieren.html","id":"aufgaben-3","chapter":"Kapitel 5 Daten einlesen und visualisieren","heading":"5.8 Aufgaben","text":"","code":""},{"path":"daten-einlesen-und-visualisieren.html","id":"grafiken-richtig-beschriften-1","chapter":"Kapitel 5 Daten einlesen und visualisieren","heading":"5.8.1 Grafiken richtig beschriften","text":"Beschriften Sie die finale Grafik der Zeitreihen (Achsen, Titel, Legende).","code":""},{"path":"daten-einlesen-und-visualisieren.html","id":"bestandesaufnahme","chapter":"Kapitel 5 Daten einlesen und visualisieren","heading":"5.8.2 Bestandesaufnahme im Wald","text":"Ar Stat arbeitet als HiWi der AG √ñkosystemforschung und soll im Nationalpark Eifel eine Bestandsaufnahme durchf√ºhren (d.h. Baumh√∂hen und -durchmesser vermessen). Er notiert den BHD (Brusth√∂hendurchmesser) und die Art der B√§ume.Lesen Sie den Datensatz BHD.txt ein und ordnen Sie ihn der Variable BHD zu.Erstellen Sie einen Vektor Nr mit durchlaufenden Baumnummern. Von welcher Art sind die Elemente des Vektors ?F√ºgen Sie die Datens√§tze BHD und Nr zu einem tibble zusammen und benennen Sie die Spalten sinnvoll.L√∂schen Sie den Vektor Nr.Lesen Sie den Datensatz Art.txt ein und ordnen Sie ihn der Variablen art zu.F√ºgen Sie die Art das tibble ein.Erstellen Sie eine Tabelle mit der Anzahl der jeweiligen Arten. Nutzen Sie die Funktion table().Speichern Sie die Tabelle mit write_delim() ab. Schlagen Sie der Hilfe nach, wie diese Funktion arbeitet!","code":""},{"path":"daten-einlesen-und-visualisieren.html","id":"wahlbeteiligung","chapter":"Kapitel 5 Daten einlesen und visualisieren","heading":"5.8.3 Wahlbeteiligung bei der Bundestagswahl 2017","text":"Bauen Sie die Grafik nach (Abbildung 5.1).\nAbbildung 5.1: Wahlbeteiligung bei den Bundestagswahlen. Quelle: Der Bundeswahlleiter.\nLesen Sie den Datensatz Wahlbeteiligung.csv R ein und ordnen Sie ihn dem Objekt beteiligung zu.Sehen Sie sich den Datensatz und fassen Sie ihn zusammen.Stellen Sie die Wahlbeteiligung als Funktion der Zeit dar, wie Abbildung 5.1 gezeigt.Beschriften Sie die Grafik.Speichern Sie die Grafik als pdf ab.","code":""},{"path":"daten-einlesen-und-visualisieren.html","id":"zweitstimme","chapter":"Kapitel 5 Daten einlesen und visualisieren","heading":"5.8.4 Zweitstimme bei der Bundestagswahl 2017","text":"Bauen Sie die Grafik nach (Abbildung 5.2).\nAbbildung 5.2: Zweitstimme bei der Bundestagswahl 2017. Quelle: Der Bundeswahlleiter.\nLesen Sie den Datensatz Zweitstimme.csv R ein und ordnen Sie ihn dem Objekt zweitstimme zu.Sehen Sie sich den Datensatz und fassen Sie ihn zusammen.Stellen Sie die die Zweitstimmen pro Partei einem S√§ulendiagramm dar. Nutzen Sie das geom geom_col() und lesen Sie den Unterschied zu geom_bar() der Hilfe nach. Tipps:\nDer Variablenname Zweitstimme 2017 enth√§lt ein Leerzeichen. Daher m√ºssen Sie es beim Aufruf zu ggplot unbedingt ‚Äú`‚Äù setzten.\nDamit die Parteien der selben Reihenfolge dargestellt werden, wie im Datensatz angegeben, wandeln Sie die Spalte Partei ein factor um: zweitstimme$Partei <- as_factor(zweitstimme$Partei).\nFarben stellen Sie direkt geom_col() ein mit fill = c('black', 'red', 'magenta', 'darkgreen', 'yellow', 'blue', 'grey')\nDer Variablenname Zweitstimme 2017 enth√§lt ein Leerzeichen. Daher m√ºssen Sie es beim Aufruf zu ggplot unbedingt ‚Äú`‚Äù setzten.Damit die Parteien der selben Reihenfolge dargestellt werden, wie im Datensatz angegeben, wandeln Sie die Spalte Partei ein factor um: zweitstimme$Partei <- as_factor(zweitstimme$Partei).Farben stellen Sie direkt geom_col() ein mit fill = c('black', 'red', 'magenta', 'darkgreen', 'yellow', 'blue', 'grey')Beschriften Sie die Grafik.Speichern Sie die Grafik als pdf ab.","code":""},{"path":"daten-einlesen-und-visualisieren.html","id":"zweigrafiken","chapter":"Kapitel 5 Daten einlesen und visualisieren","heading":"5.8.5 Ergebnisse der Bundestagswahl in einer Grafik","text":"Stellen Sie beide Grafiken untereinander dar wie Abbildung (5.3) gezeigt.\nAbbildung 5.3: Ergebnisse der Bundestagswahl 2017. Quelle: Der Bundeswahlleiter.\n","code":""},{"path":"daten-einlesen-und-visualisieren.html","id":"ihre-arbeit-einreichen-2","chapter":"Kapitel 5 Daten einlesen und visualisieren","heading":"5.9 Ihre Arbeit einreichen","text":"Speichern Sie Ihr Notebook ab und laden Sie nur die .Rmd Datei vom Server.Laden Sie Ihre .Rmd Datei ILIAS hoch. Beachten Sie die Deadline!Sie erhalten die Musterl√∂sung nach dem Hochladen.","code":""},{"path":"tidyverse.html","id":"tidyverse","chapter":"Kapitel 6 Der explorative Workflow mit tidyverse","heading":"Kapitel 6 Der explorative Workflow mit tidyverse","text":"\nKernpakete aus tidyverse benennen\n\nein einfaches Workflow (Daten einlesen, zusammenfassen, darstellen) mit tidyverse durchf√ºhren\n\nFunktionen des Pakets dplyr f√ºr Datentransformation anwenden\ntidyverse ist eine Sammlung von R-Pakete, die explizit f√ºr Datenanalyse entwickelt wurden (https://www.tidyverse.org/). tidyverse versucht durch gemeinsame Philosophie Design, Grammatik und Datenstruktur die Datenanalyse zu erleichtern (https://design.tidyverse.org/). Auch wenn tidyverse auf den ersten Blick etwas fremd erscheint, es ist ein Teil von R, kein eigenes Universum. Es ist also v√∂llig Ordnung, R-Basisfunktionen mit Funktionen aus tidyverse zu mischen.Das wichtigste Einf√ºhrungsbuch zu tidyverse ist sicherlich R4DS: ‚ÄúR Data Science‚Äù (Wickham Grolemund 2021), das Sie kostenlos online lesen k√∂nnen (https://r4ds..co.nz/).","code":""},{"path":"tidyverse.html","id":"grundpakete","chapter":"Kapitel 6 Der explorative Workflow mit tidyverse","heading":"6.1 Grundpakete","text":"tidyverse enth√§lt folgende Grundpakete, die alle installiert werden, wenn Sie install.packages('tidyverse') ausf√ºhren.Jedes dieser Pakete hat ein Cheat Sheet, eine √ºbersichtliche Zusammenstellung der Funktionen des Pakets. Sie bekommen die Cheet Sheats √ºber die tidyverse-Seite (https://www.tidyverse.org/packages/), indem Sie auf das jeweilige Paket klicken und zum Abschnitt ‚ÄòCheatsheet‚Äô scrollen.","code":""},{"path":"tidyverse.html","id":"der-explorative-workflow","chapter":"Kapitel 6 Der explorative Workflow mit tidyverse","heading":"6.2 Der explorative Workflow","text":"","code":""},{"path":"tidyverse.html","id":"daten-einlesen-revisited","chapter":"Kapitel 6 Der explorative Workflow mit tidyverse","heading":"6.2.1 Daten einlesen, revisited","text":"Als erstes laden wir die Bibliothek tidyverse.Sie kennen bereits die Funktion read_delim() zum Einlesen von Textdateien. Die Funktion ist die allgemeinste Funktion der read_* Familie aus readr tidyverse; read_csv() und read_csv2() sind jeweils f√ºr komma- und strichpunkt-getrennte Datens√§tze gedacht. der Basisinstallation von R (also au√üerhalb von tidyverse) gibt die sehr umfangreiche Funktion read.table(), die ebenfalls zum Einlesen von Textdateien verwendet wird. Man k√∂nnte berechtigterweise fragen, warum neue Funktion (read_*) f√ºr etwas erfinden, es schon gibt. Die Autoren von tidyverse versprechen Konsistenz und Geschwindigkeit. Ersteres war schon immer ein Problem von R, da es nicht von Computerspezialisten, sondern von Anwendern erfunden wurde. Daher ist eine Vereinheitlichung durch tidyverse mehr als willkommen. Und Geschwindigkeit ist sp√§testens bei gr√∂√üeren Datens√§tzen ein wichtiger Punkt.Wir sehen uns Daten des Deutschen Wetterdienstes , die ich 24. Mai 2020 herunter geladen habe (https://www.dwd.de/DE/leistungen/klimadatendeutschland/klimadatendeutschland.html). Auch das ist eine tolle Datenquelle f√ºr Berichte üòÑ. Der Datensatz enth√§lt Stundenwerte f√ºr relative Luftfeuchte (%) und Lufttemperatur (¬∞C) von drei Wetterstationen, n√§mlich Hof, Frankfurt und K√∂ln-Bonn. Die Daten sind der Datei Drei_Stationen.csv gespeichert.Beim Einlesen zeigt Ihnen read_delim() bereits, welche Spalten und welche Datentypen es erkennt, mit trim_ws = T werden Leerzeichen aus Spalten entfernt.Eine weitere Kontrolle bietet die Funktion print(), die das eingelesene Ergebnis √ºbersichtlich (und im Notebook interaktiv) darstellt. Sie m√ºssen hier nicht head() verwenden, da grunds√§tzlich nur die ersten 10 Zeilen dargestellt werden.Das gleiche Ergebnis bekommen Sie auch ohne print(), wenn Sie wie gewohnt den Namen des Objekts tippen.diesem Datensatz sind folgende Variablen (Spalten) enthalten (s. Datensatzbeschreibung des DWDs)Das Objekt temp_humid ist ein tibble, ein data.frame mit ‚Äúmodernem‚Äù Verhalten. Z.B. gibt die Funktion print() nur die ersten 10 Zeilen aus, die Datentypen den Spalten werden hellgrau zwischen ‚Äò<>‚Äô mit angegeben etc. Mehr zu Tibbles finden Sie Kapitel 10 ‚ÄúTibbles‚Äù R4DS.","code":"\nlibrary(tidyverse)\ntemp_humid <- read_delim('data/Drei_Stationen.csv', delim = ';',    trim_ws = T)## \n## ‚îÄ‚îÄ Column specification ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n## cols(\n##   STATIONS_ID = col_double(),\n##   MESS_DATUM = col_double(),\n##   QN_9 = col_double(),\n##   TT_TU = col_double(),\n##   RF_TU = col_double(),\n##   eor = col_character()\n## )\nprint(temp_humid)## # A tibble: 39,600 x 6\n##    STATIONS_ID MESS_DATUM  QN_9 TT_TU RF_TU eor  \n##          <dbl>      <dbl> <dbl> <dbl> <dbl> <chr>\n##  1        2261 2018111900     3  -2.8    99 eor  \n##  2        2261 2018111901     3  -2.5   100 eor  \n##  3        2261 2018111902     3  -2.3   100 eor  \n##  4        2261 2018111903     3  -2     100 eor  \n##  5        2261 2018111904     3  -1.9    99 eor  \n##  6        2261 2018111905     3  -2.1    99 eor  \n##  7        2261 2018111906     3  -1.8    99 eor  \n##  8        2261 2018111907     3  -1.5    99 eor  \n##  9        2261 2018111908     3  -1.1    99 eor  \n## 10        2261 2018111909     3  -0.6    97 eor  \n## # ‚Ä¶ with 39,590 more rows\ntemp_humid## # A tibble: 39,600 x 6\n##    STATIONS_ID MESS_DATUM  QN_9 TT_TU RF_TU eor  \n##          <dbl>      <dbl> <dbl> <dbl> <dbl> <chr>\n##  1        2261 2018111900     3  -2.8    99 eor  \n##  2        2261 2018111901     3  -2.5   100 eor  \n##  3        2261 2018111902     3  -2.3   100 eor  \n##  4        2261 2018111903     3  -2     100 eor  \n##  5        2261 2018111904     3  -1.9    99 eor  \n##  6        2261 2018111905     3  -2.1    99 eor  \n##  7        2261 2018111906     3  -1.8    99 eor  \n##  8        2261 2018111907     3  -1.5    99 eor  \n##  9        2261 2018111908     3  -1.1    99 eor  \n## 10        2261 2018111909     3  -0.6    97 eor  \n## # ‚Ä¶ with 39,590 more rows\nclass(temp_humid)## [1] \"spec_tbl_df\" \"tbl_df\"      \"tbl\"         \"data.frame\""},{"path":"tidyverse.html","id":"geschickter-umgang-mit-zeit-und-datum","chapter":"Kapitel 6 Der explorative Workflow mit tidyverse","heading":"6.3 Geschickter Umgang mit Zeit und Datum","text":"Ein weiteres Paket, dass zwar nicht zum Kern von tidyverse geh√∂rt, jedoch trotzdem extrem n√ºtzlich ist, hei√üt lubridate. Es hilft, Text sehr einfach richtige Datums-Objekte zu transformieren (Base-R muss man sich daf√ºr kryptischen Datumsformate merken). Wir transformieren die Spalte temp_humid$MESS_DATUM ein richtiges Datum mit Uhrzeit. Die Funktion ymd_h() kann character ein richtiges Datumsformat transformieren, wenn das Datum als year, month, day, hour codiert ist. Es gibt noch weitere Varianten der Codierung, die Sie bei Bedarf der Hilfe nachschlagen sollten.","code":"\nlibrary(lubridate)\n\ntemp_humid$MESS_DATUM <- ymd_h(temp_humid$MESS_DATUM)\n\ntemp_humid## # A tibble: 39,600 x 6\n##    STATIONS_ID MESS_DATUM           QN_9 TT_TU RF_TU eor  \n##          <dbl> <dttm>              <dbl> <dbl> <dbl> <chr>\n##  1        2261 2018-11-19 00:00:00     3  -2.8    99 eor  \n##  2        2261 2018-11-19 01:00:00     3  -2.5   100 eor  \n##  3        2261 2018-11-19 02:00:00     3  -2.3   100 eor  \n##  4        2261 2018-11-19 03:00:00     3  -2     100 eor  \n##  5        2261 2018-11-19 04:00:00     3  -1.9    99 eor  \n##  6        2261 2018-11-19 05:00:00     3  -2.1    99 eor  \n##  7        2261 2018-11-19 06:00:00     3  -1.8    99 eor  \n##  8        2261 2018-11-19 07:00:00     3  -1.5    99 eor  \n##  9        2261 2018-11-19 08:00:00     3  -1.1    99 eor  \n## 10        2261 2018-11-19 09:00:00     3  -0.6    97 eor  \n## # ‚Ä¶ with 39,590 more rows"},{"path":"tidyverse.html","id":"daten-zusammenfassen","chapter":"Kapitel 6 Der explorative Workflow mit tidyverse","heading":"6.3.1 Daten zusammenfassen","text":"Die drei Wetterstationen haben folgende IDs:Wir z√§hlen nach, wie viele Messpunkte es pro Station gibt. Dazu m√ºssen wir den Datensatz nach der Variablen STATION_ID gruppieren und dann pro Gruppe die Anzahl der Datenpunkte ermitteln:Die Zeichenkombination %>% hei√üt Pipe-Operator (pipe) und wird als ‚Äòund dann‚Äô gelesen (). Der Ausdruck temp_humid %>% group_by(STATIONS_ID) %>% count() hei√üt also: nimm das Objekt temp_humid, gruppiere es nach der Variablen STATION_ID und dann z√§hle die Eintr√§ge pro Gruppe zusammen. Der Pipe-Operator ist die Kernphilosophie von tidyverse und wird Ihnen √ºberall begegnen. Der Operator stammt aus dem Paket magrittr (https://magrittr.tidyverse.org/). Seine Hauptaufgabe ist es, den Code √ºbersichtlicher und besser lesbar zu machen (vielleicht nicht gleich zu Beginn der Lernkurve aber schon sehr bald üòé).","code":"\nstation_ids <-  c('2261' = 'Hof', '1420' = 'Frankfurt', '2667' = 'Koeln')\ntemp_humid %>% \n  group_by(STATIONS_ID) %>% \n  count()## # A tibble: 3 x 2\n## # Groups:   STATIONS_ID [3]\n##   STATIONS_ID     n\n##         <dbl> <int>\n## 1        1420 13200\n## 2        2261 13200\n## 3        2667 13200"},{"path":"tidyverse.html","id":"die-grammatik-der-datenmanipulation-dplyr","chapter":"Kapitel 6 Der explorative Workflow mit tidyverse","heading":"6.4 Die Grammatik der Datenmanipulation ‚Äì dplyr","text":"Die Funktion count() geh√∂rt zum Paket dplyr, das f√ºr Datentransformationen zust√§ndig ist. Es ist mal wieder eine Grammatik. Dieses Paket enth√§lt 5 Grundfunktionen (alle nach Verben benannt, damit man gleich wei√ü, frau tut üòÑ):Wir m√∂chten nur von einer bestimmten Station die Anzahl der Messwerte wissen m√∂chten, dann filtern wir vorher.Beim Filtern l√§uft eine logische Abfrage. D.h. es wird bei jeden Eintrag STATION_ID nachgesehen, ob da der Wert 2667 steht. Wenn da 2667 steht, dann gibt == ein TRUE zur√ºck, wenn da etwas anderes steht, dann gibt == ein FALSE zur√ºck. Und die Funktion filter() beh√§lt nur die Zeilen, bei denen == ein TRUE zur√ºck gegeben hat.Weiter wichtige logische und relationale Operatoren finden Sie hier der Hilfe zu filter(). Hier ein paar einfache BeispieleZudem kann man bei filter() die Anfragen auch kombinieren. Wir wollen z.B. die Stationen K√∂ln und Hof haben. | ist der logische Operator oder. Wenn man also sowohl K√∂ln als auch Hof haben , sagt man: finde alles, entweder gleich K√∂ln oder gleich Hof ist.Das Gleiche erreicht man mit folgendem Code, indem man Frankfurt ausschlie√üt:Alternative kann man auch den Operator %% verwenden. Dieser ist sehr n√ºtzlich, wenn man anhand einer einzelnen Variablen filtert, aber unterschiedliche Eintr√§ge ausw√§hlen m√∂chte (z.B. zwei Messstationen). Es wird bei jeder Zeile der Variablen STATIONS_ID nun √ºberpr√ºft, ob hier entweder 2667 oder 2261 stehen.","code":"\ntemp_humid %>% \n  filter(STATIONS_ID == '2667') %>%\n  count()## # A tibble: 1 x 1\n##       n\n##   <int>\n## 1 13200\ntemp_humid %>% \n  filter(STATIONS_ID == '2667' | STATIONS_ID == '2261') %>%\n  group_by(STATIONS_ID) %>% \n  count()## # A tibble: 2 x 2\n## # Groups:   STATIONS_ID [2]\n##   STATIONS_ID     n\n##         <dbl> <int>\n## 1        2261 13200\n## 2        2667 13200\ntemp_humid %>% \n  filter(STATIONS_ID != '1420') %>%\n  group_by(STATIONS_ID) %>% \n  count()## # A tibble: 2 x 2\n## # Groups:   STATIONS_ID [2]\n##   STATIONS_ID     n\n##         <dbl> <int>\n## 1        2261 13200\n## 2        2667 13200\ntemp_humid %>% \n  filter(STATIONS_ID %in% c('2667', '2261')) %>%\n  group_by(STATIONS_ID) %>% \n  count()## # A tibble: 2 x 2\n## # Groups:   STATIONS_ID [2]\n##   STATIONS_ID     n\n##         <dbl> <int>\n## 1        2261 13200\n## 2        2667 13200"},{"path":"tidyverse.html","id":"daten-plotten","chapter":"Kapitel 6 Der explorative Workflow mit tidyverse","heading":"6.4.1 Daten plotten","text":"Wir sehen uns die Daten erst mal , bevor wir weiter machen. Wir plotten die Temperatur. Weil es sich um Zeitreihen handelt, m√∂chten wir sie eher untereinander als nebeneinander haben. Daher setzen wir bei facet_wrap() den Parameter nrow = 3.","code":"\nggplot(data = temp_humid, aes(x = MESS_DATUM, y = TT_TU)) + \n  geom_line() +\n  facet_wrap(~STATIONS_ID, nrow = 3) +\n  labs(x = 'Zeit', y = 'Temperatur (¬∞C)')"},{"path":"tidyverse.html","id":"neue-variablen-erstellen-mit-mutate","chapter":"Kapitel 6 Der explorative Workflow mit tidyverse","heading":"6.4.2 Neue Variablen erstellen mit mutate()","text":"Wir wollen nun die Monatsmittelwerte und die Standardabweichungen f√ºr die Temperatur berechnen und diese darstellen. Als erstes erstellen wir zwei neue Spalten, die jeweils das Jahr und den Monat beinhalten. Die beiden neuen Spalten werden Ende von temp_humid angeh√§ngt. Um neue Spalten zu erstellen, nutzen wir die Funktion mutate(). Die Funktionen year()und month() geh√∂ren zur Bibliothek lubridate und extrahieren jeweils das Jahr und den Monat aus MESS_DATUM.Jetzt k√∂nnen wir einen neuen Datensatz mit den Mittelwerten erstellen. Daf√ºr gruppieren wir erst einmal die Daten nach STATIONS_ID, year und month. Die Mittelwerte sollen ja je Station, Jahr und Monat berechnet werden. Beim Gruppieren gibt man die Variablen ohne Anf√ºhrungszeichen und ohne einen Vektor zu bilden einfach durch Kommas getrennt .Die Struktur von monthly_means zeigt uns, dass es sich um gruppierte Daten handelt.Da wir aber mit den Daten weiter rechnen wollen, ist es besser, die Gruppierung wieder aufzugeben. Es k√∂nnte sonst sp√§ter Fehlermeldungen geben.Um die Daten als Zeitreihen zu plotten, erstellen wir noch eine ordentliche Zeit-Spalte. Die Funktion parse_date_time() kann aus Character richtige Datums-Zeitobjekte erstellen. Sie ist allgemeiner als die oben verwendete ymd_h() Funktion, da man hier das Format explizit angeben kann. unserem Fall ist das Format ‚Äòym‚Äô f√ºr Jahr und Monat.Der Code paste0(year, month) ‚Äúklebt‚Äù die Daten der Variablen year und month zusammen. Das ist n√∂tig, da die Funktion parse_date_time() einen Charaktervektor als Input erwartet und keine zwei getrennten Spalten. Da das Datum au√üer dem Jahr und dem Monat noch einen Tag braucht, hat parse_date_time() den ersten eines jeden Monats genommen.Alternativ k√∂nnen wir die Mittelwerte mit den Standardabweichungen darstellen.Oder, weil es gerade Spa√ü macht, als halb-transparentes Band. Ich hoffe, Sie haben jetzt Lust, das Kapitel 5 im ggplot2 Buch zu lesen üòé.Ein letzter Trick. Die √úberschriften f√ºr die Teilgrafiken sind ungeschickt, da man die IDs als Mensch einfach nicht zuordnen kann. Weiter oben haben wir einen benannten Vektor definiert, der die Klarnamen enth√§lt.Diesen Vektor nutzen wir als Titel.","code":"\ntemp_humid <- temp_humid %>% \n  mutate(year = year(MESS_DATUM),\n         month = month(MESS_DATUM))\n\ntemp_humid## # A tibble: 39,600 x 8\n##    STATIONS_ID MESS_DATUM           QN_9 TT_TU RF_TU eor    year month\n##          <dbl> <dttm>              <dbl> <dbl> <dbl> <chr> <dbl> <dbl>\n##  1        2261 2018-11-19 00:00:00     3  -2.8    99 eor    2018    11\n##  2        2261 2018-11-19 01:00:00     3  -2.5   100 eor    2018    11\n##  3        2261 2018-11-19 02:00:00     3  -2.3   100 eor    2018    11\n##  4        2261 2018-11-19 03:00:00     3  -2     100 eor    2018    11\n##  5        2261 2018-11-19 04:00:00     3  -1.9    99 eor    2018    11\n##  6        2261 2018-11-19 05:00:00     3  -2.1    99 eor    2018    11\n##  7        2261 2018-11-19 06:00:00     3  -1.8    99 eor    2018    11\n##  8        2261 2018-11-19 07:00:00     3  -1.5    99 eor    2018    11\n##  9        2261 2018-11-19 08:00:00     3  -1.1    99 eor    2018    11\n## 10        2261 2018-11-19 09:00:00     3  -0.6    97 eor    2018    11\n## # ‚Ä¶ with 39,590 more rows\nmonthly_means <- temp_humid %>%\n  group_by(STATIONS_ID, year, month) %>% \n  summarize(mean_T = mean(TT_TU), mean_RH = mean(RF_TU),\n            sd_T = sd(TT_TU), sd_RH = sd(RF_TU))## `summarise()` has grouped output by 'STATIONS_ID', 'year'. You can override using the `.groups` argument.\nmonthly_means## # A tibble: 57 x 7\n## # Groups:   STATIONS_ID, year [9]\n##    STATIONS_ID  year month mean_T mean_RH  sd_T sd_RH\n##          <dbl> <dbl> <dbl>  <dbl>   <dbl> <dbl> <dbl>\n##  1        1420  2018    11   4.00    79.7  1.82  9.96\n##  2        1420  2018    12   4.73    83.7  4.20 11.7 \n##  3        1420  2019     1   2.12    79.3  3.76 10.0 \n##  4        1420  2019     2   4.48    74.1  4.69 17.7 \n##  5        1420  2019     3   8.28    68.5  4.08 16.1 \n##  6        1420  2019     4  11.7     61.0  5.52 21.8 \n##  7        1420  2019     5  12.7     67.5  4.64 20.1 \n##  8        1420  2019     6  21.4     60.6  6.05 21.2 \n##  9        1420  2019     7  21.6     55.6  5.90 21.8 \n## 10        1420  2019     8  20.7     65.6  4.94 20.8 \n## # ‚Ä¶ with 47 more rows\nstr(monthly_means)## grouped_df [57 √ó 7] (S3: grouped_df/tbl_df/tbl/data.frame)\n##  $ STATIONS_ID: num [1:57] 1420 1420 1420 1420 1420 1420 1420 1420 1420 1420 ...\n##  $ year       : num [1:57] 2018 2018 2019 2019 2019 ...\n##  $ month      : num [1:57] 11 12 1 2 3 4 5 6 7 8 ...\n##  $ mean_T     : num [1:57] 4 4.73 2.12 4.48 8.28 ...\n##  $ mean_RH    : num [1:57] 79.7 83.7 79.3 74.1 68.5 ...\n##  $ sd_T       : num [1:57] 1.82 4.2 3.76 4.69 4.08 ...\n##  $ sd_RH      : num [1:57] 9.96 11.68 10.04 17.73 16.1 ...\n##  - attr(*, \"groups\")= tibble [9 √ó 3] (S3: tbl_df/tbl/data.frame)\n##   ..$ STATIONS_ID: num [1:9] 1420 1420 1420 2261 2261 ...\n##   ..$ year       : num [1:9] 2018 2019 2020 2018 2019 ...\n##   ..$ .rows      : list<int> [1:9] \n##   .. ..$ : int [1:2] 1 2\n##   .. ..$ : int [1:12] 3 4 5 6 7 8 9 10 11 12 ...\n##   .. ..$ : int [1:5] 15 16 17 18 19\n##   .. ..$ : int [1:2] 20 21\n##   .. ..$ : int [1:12] 22 23 24 25 26 27 28 29 30 31 ...\n##   .. ..$ : int [1:5] 34 35 36 37 38\n##   .. ..$ : int [1:2] 39 40\n##   .. ..$ : int [1:12] 41 42 43 44 45 46 47 48 49 50 ...\n##   .. ..$ : int [1:5] 53 54 55 56 57\n##   .. ..@ ptype: int(0) \n##   ..- attr(*, \".drop\")= logi TRUE\nmonthly_means <- ungroup(monthly_means)\nmonthly_means <- monthly_means %>%\n  mutate(year_month = parse_date_time(paste0(year, month), orders = 'ym', tz = 'CET'))\n\nmonthly_means## # A tibble: 57 x 8\n##    STATIONS_ID  year month mean_T mean_RH  sd_T sd_RH year_month         \n##          <dbl> <dbl> <dbl>  <dbl>   <dbl> <dbl> <dbl> <dttm>             \n##  1        1420  2018    11   4.00    79.7  1.82  9.96 2018-11-01 00:00:00\n##  2        1420  2018    12   4.73    83.7  4.20 11.7  2018-12-01 00:00:00\n##  3        1420  2019     1   2.12    79.3  3.76 10.0  2019-01-01 00:00:00\n##  4        1420  2019     2   4.48    74.1  4.69 17.7  2019-02-01 00:00:00\n##  5        1420  2019     3   8.28    68.5  4.08 16.1  2019-03-01 00:00:00\n##  6        1420  2019     4  11.7     61.0  5.52 21.8  2019-04-01 00:00:00\n##  7        1420  2019     5  12.7     67.5  4.64 20.1  2019-05-01 00:00:00\n##  8        1420  2019     6  21.4     60.6  6.05 21.2  2019-06-01 00:00:00\n##  9        1420  2019     7  21.6     55.6  5.90 21.8  2019-07-01 00:00:00\n## 10        1420  2019     8  20.7     65.6  4.94 20.8  2019-08-01 00:00:00\n## # ‚Ä¶ with 47 more rows\nggplot(data = monthly_means, aes(x = year_month, y = mean_T, col = factor(STATIONS_ID))) + \n  geom_line() + \n  labs(x = 'Zeit', y = 'Temperatur (¬∞C)', color = 'Messstation')\nggplot(monthly_means, aes(x = year_month, y = mean_T, ymin = mean_T - sd_T, ymax = mean_T + sd_T)) +\n  geom_errorbar() +\n  geom_point() +\n  facet_wrap(~STATIONS_ID, nrow = 3) + \n  labs(x = 'Zeti', y = 'Temperatur (¬∞C)')\nggplot(monthly_means, aes(x = year_month, y = mean_T, ymin = mean_T - sd_T, ymax = mean_T + sd_T)) +\n  geom_ribbon(alpha = 0.5) +\n  geom_line() +\n  facet_wrap(~STATIONS_ID, nrow = 3) + \n  labs(x = 'Zeit', y = 'Temperatur (¬∞C)')\nstation_ids##        2261        1420        2667 \n##       \"Hof\" \"Frankfurt\"     \"Koeln\"\nggplot(monthly_means, aes(x = year_month, y = mean_T, ymin = mean_T - sd_T, ymax = mean_T + sd_T)) +\n  geom_ribbon(alpha = 0.5) +\n  geom_line() +\n  facet_wrap(~STATIONS_ID, nrow = 3, labeller = labeller(STATIONS_ID = station_ids)) + \n  labs(x = 'Zeit', y = 'Temperatur (¬∞C)')"},{"path":"tidyverse.html","id":"lesestoff-4","chapter":"Kapitel 6 Der explorative Workflow mit tidyverse","heading":"6.5 Lesestoff","text":"Kapitel 3 Ismay Kim (2021)","code":""},{"path":"tidyverse.html","id":"weiterf√ºhrende-literatur-und-videos","chapter":"Kapitel 6 Der explorative Workflow mit tidyverse","heading":"6.6 Weiterf√ºhrende Literatur und Videos","text":"R4DS Wickham Grolemund (2021): Kapitel 5 ‚ÄúData transformation‚ÄùR4DS Wickham Grolemund (2021): Kapitel 5 ‚ÄúData transformation‚ÄùEine live Analyse des Hauptautors von tidyverse, Hadley Wickham. Empfehlenswert, auch wenn er viel zu schnell tippt üòÑ.Eine live Analyse des Hauptautors von tidyverse, Hadley Wickham. Empfehlenswert, auch wenn er viel zu schnell tippt üòÑ.","code":""},{"path":"stichproben.html","id":"stichproben","chapter":"Kapitel 7 Stichproben und Variabilit√§t","heading":"Kapitel 7 Stichproben und Variabilit√§t","text":"\nBegriffe Stichprobenverteilung und Standardfehler erk√§ren\n\nZufall bei wiederholter Stichprobenerhebung erkennen\n\nStichprobenverteilung darstellen\n\nEinfluss der Stichprobengr√∂√üe auf Stichprobenverteilung benennen\nMit diesem Kapitel steigen wir die schlie√üende Statistik ein. Wir beginnen damit, wie man der Statistik zu Daten kommt (Stichprobenerhebung) und welche Rolle der Zufall dabei spielt. Dabei konzentrieren wir uns auf die Erhebung von einfachen zuf√§lligen Stichproben (Zufallsstichproben), nicht auf das Designen von komplizierten Erhebungen. Das ist eine Kunst f√ºr sich und geht √ºber die Ziele dieses Kurses hinaus.","code":"\nlibrary(tidyverse)\nlibrary(moderndive)"},{"path":"stichproben.html","id":"stichproben-1","chapter":"Kapitel 7 Stichproben und Variabilit√§t","heading":"7.1 Stichproben","text":"Wir nutzen wieder die selbst erstellten Daten aus der Aufgabe 10.1. Die 12000 Studiere sind unsere Grundgesamtheit. Da wir die Daten selbst erstellt haben, wissen wir alles √ºber sie. Das ist ein gro√üer Vorteil von Computerexperimenten üòÑ. Damit alle dieselben Daten erstellen, ist die Zeile set.seed(123) sehr wichtig. Sie sorgt daf√ºr, dass der Generator f√ºr Zufallszahlen einen zuf√§lligen, aber reproduzierbaren Zustand versetzt wird. DIe Zahl den Klammern ist nicht wichtig. Wichtig ist, dass alle dieselbe benutzen.F√ºr bessere Nachvollziehbarkeit, nummerieren wir unsere Studierenden diesmal durch.Wir wollen nun 50 Studierende befragen. Durch die zuf√§llige Auswahl Befragten erzeugen wir eine zuf√§llige Stichprobe. √úbersetzt unser Computerexperiment bedeutet es, dass wir zuf√§llig 50 Zeilen aus dem Datensatz grundgesamtheit ziehen und zwar , dass sich diese Zeilen nicht wiederholen (d.h. niemand mehrfach befragt wird). Dazu nutzen wir die Funktion rep_sample_n(), die wiederholt (rep) n Zeilen zieht (sample), und zwar mit der Einstellung replace = FALSE, also ohne Zur√ºcklegen. Wir befragen nur einmal, daher reps = 1.Damit alle wieder dieselben Daten bekommen, setzen wir vorher den seed (Zustand des Zufallszahlengenerators). Die Variable befragung_size gibt die Stichprobengr√∂√üe .Die Variable replicate zeigt immer 1. Das bedeutet, dass wir die Befragung einmal wiederholt (repliziert) haben und alle Datenpunkte zu dieser Wiederholung geh√∂ren.Wir wollen nun wissen, wie viele Studierende unter den Befragten der Stadt oder auf dem Land wohnen.Das Ganze m√∂chten wir als Anteile ausdr√ºcken. Die Funktion n() kann innerhalb der Funktion summarise() zum Ausz√§hlen genutzt werden. Wir teilen durch die Stichprobengr√∂√üe.Es wohnen also 42% auf dem Land und 58% der Stadt.passiert, wenn wir die Befragung mehrfach wiederholen, sagen wir 33 Mal? der Realit√§t ist dieses Szenario sehr unwahrscheinlich, aber einem Computerexperiment einfach zu implementieren. Es hilft uns ein Gef√ºhl f√ºr die Variabilit√§t, die durch das zuf√§llige Ausw√§hlen der Studierenden bei der Befragung entsteht, zu entwickeln.Wir setzten erneut den seed, damit alle dieselben Ergebnisse bekommen.Jetzt wird uns angezeigt, dass es dem Datensatz befragung_reps 33 replicates (Wiederholgungen) gibt. Diese sind einfach nacheinander befragung_reps angeordent (bl√§ttern Sie durch den Datensatz). Dementsprechend hat der Datensatz 50 \\(\\times\\) 33 = 1650 Zeilen.Wie sieht es jetzt mit den Anteilen von Stadt- und Landbewohnern aus? Wir m√ºssen nun zus√§tzlich zum wohnort auch noch nach replicate gruppieren.Erwartungsgem√§√ü bringt jede Wiederholung der Befragung, die wir ja als zuf√§lliges Herausgreifen der Studierenden ohne Mehrfachbefragung programmiert haben, etwas andere Ergebnisse. Sehen Sie sich die studnet_id den replicates , es werde unterschiedliche Studierende befragt! einem Histogramm sieht das ganze aus:Die h√§ufigsten Anteile sind um die 40% f√ºr Land und um die 60% f√ºr Stadt. Wir k√∂nnen es sogar etwas genauer ablesen, da wir binwidth = 0.05 gew√§hnt haben, also Schritte von 5%. Es sind 35‚Äì40% f√ºr Land und 55‚Äì60% f√ºr Stadt.","code":"\nset.seed(123)\n\nstudent_id <- 1:12000\n  \nanreise <- c(runif(n = 12000 * 0.8, min = 5, max = 40),\n             runif(n = 12000 * 0.2, min = 60, max = 120))\n\ngeschlecht <- sample(c('m', 'w'), size = 12000, replace = TRUE)\n\nwohnort <- sapply(anreise, function(x) {\n  if(x < 30) 'stadt'\n  else 'land'\n})\n\nverkehrsmittel <- sapply(anreise, function(x) {\n  if(x <= 10) 'zu_fuss'\n  else if(x > 10 & x <= 15) sample(c('zu_fuss', 'fahrrad'), size = 1)\n  else if(x > 15 & x <= 45) sample(c('bus', 'fahrrad', 'auto'), size = 1)\n  else sample(c('bus', 'auto'), size = 1)\n})\n\nzeit_bib <- 5 * 60 - 0.7 * anreise + rnorm(length(anreise), 0, 20)\n\ngrundgesamtheit <- tibble(student_id, geschlecht, wohnort, verkehrsmittel, anreise, zeit_bib)\n\ngrundgesamtheit## # A tibble: 12,000 x 6\n##    student_id geschlecht wohnort verkehrsmittel anreise zeit_bib\n##         <int> <chr>      <chr>   <chr>            <dbl>    <dbl>\n##  1          1 w          stadt   bus              15.1      294.\n##  2          2 w          land    fahrrad          32.6      254.\n##  3          3 w          stadt   fahrrad          19.3      231.\n##  4          4 m          land    auto             35.9      245.\n##  5          5 m          land    bus              37.9      234.\n##  6          6 w          stadt   zu_fuss           6.59     303.\n##  7          7 w          stadt   bus              23.5      284.\n##  8          8 m          land    auto             36.2      274.\n##  9          9 m          stadt   fahrrad          24.3      299.\n## 10         10 w          stadt   bus              21.0      282.\n## # ‚Ä¶ with 11,990 more rows\nset.seed(345)\n\nbefragung_size <- 50\n\nbefragung <- rep_sample_n(grundgesamtheit, size = befragung_size, replace = FALSE, reps = 1)\n\nbefragung## # A tibble: 50 x 7\n## # Groups:   replicate [1]\n##    replicate student_id geschlecht wohnort verkehrsmittel anreise zeit_bib\n##        <int>      <int> <chr>      <chr>   <chr>            <dbl>    <dbl>\n##  1         1       1623 m          stadt   zu_fuss           7.06     299.\n##  2         1       9171 m          stadt   fahrrad          11.3      278.\n##  3         1      10207 w          land    bus             107.       199.\n##  4         1       3506 w          stadt   bus              25.0      326.\n##  5         1       8892 w          stadt   bus              28.1      259.\n##  6         1       5460 m          stadt   bus              23.6      299.\n##  7         1       6120 w          stadt   bus              20.0      268.\n##  8         1        865 w          stadt   fahrrad          26.6      290.\n##  9         1      11586 m          land    bus             114.       207.\n## 10         1       8153 w          stadt   zu_fuss           8.06     297.\n## # ‚Ä¶ with 40 more rows\nbefragung %>% \n  group_by(wohnort) %>% \n  count()## # A tibble: 2 x 2\n## # Groups:   wohnort [2]\n##   wohnort     n\n##   <chr>   <int>\n## 1 land       21\n## 2 stadt      29\nbefragung %>% \n  group_by(wohnort) %>% \n  summarise(prop = n()/befragung_size)## # A tibble: 2 x 2\n##   wohnort  prop\n##   <chr>   <dbl>\n## 1 land     0.42\n## 2 stadt    0.58\nset.seed(234)\n\nbefragung_reps <- rep_sample_n(grundgesamtheit, size = befragung_size, replace = FALSE, reps = 33)\n\nbefragung_reps## # A tibble: 1,650 x 7\n## # Groups:   replicate [33]\n##    replicate student_id geschlecht wohnort verkehrsmittel anreise zeit_bib\n##        <int>      <int> <chr>      <chr>   <chr>            <dbl>    <dbl>\n##  1         1       2079 m          land    auto              38.8     262.\n##  2         1       1314 m          stadt   fahrrad           13.3     301.\n##  3         1       1710 m          stadt   auto              26.5     272.\n##  4         1       4386 w          stadt   bus               23.9     269.\n##  5         1       9490 m          land    auto              34.2     262.\n##  6         1      11757 w          land    bus              102.      227.\n##  7         1      11649 w          land    bus              111.      202.\n##  8         1       2244 m          land    bus               38.9     256.\n##  9         1       3652 w          stadt   fahrrad           10.3     254.\n## 10         1       3127 m          stadt   fahrrad           29.6     271.\n## # ‚Ä¶ with 1,640 more rows\nwohnort_props <- befragung_reps %>% \n  group_by(replicate, wohnort) %>% \n  summarise(prop = n()/befragung_size)\n\nwohnort_props## # A tibble: 66 x 3\n## # Groups:   replicate [33]\n##    replicate wohnort  prop\n##        <int> <chr>   <dbl>\n##  1         1 land     0.42\n##  2         1 stadt    0.58\n##  3         2 land     0.36\n##  4         2 stadt    0.64\n##  5         3 land     0.4 \n##  6         3 stadt    0.6 \n##  7         4 land     0.38\n##  8         4 stadt    0.62\n##  9         5 land     0.4 \n## 10         5 stadt    0.6 \n## # ‚Ä¶ with 56 more rows\nggplot(data = wohnort_props, aes(x = prop)) + \n  geom_histogram(binwidth = 0.05, boundary = 0.4, col = 'white') +\n  facet_wrap(~ wohnort) +\n  labs(x = 'Anteile beim Wohnort', title = 'Verteilung der Wohnorte', y = 'H√§ufigkeit')"},{"path":"stichproben.html","id":"anzahl-der-wiederholungen-und-variabilit√§t","chapter":"Kapitel 7 Stichproben und Variabilit√§t","heading":"7.1.1 Anzahl der Wiederholungen und Variabilit√§t","text":"passiert, wenn wir unsere Umfrage nun 1000 Mal wiederholen? Wir k√∂nnen den ganzen Code recyclen und m√ºssen nur die reps entsprechend ver√§ndern. Wir erstellen daf√ºr eine extra Variable befragung_reps. Beim Histogramm sollten wir die binwidth etwas heruntersetzten, da wir jetzt sehr viel mehr Daten haben und diese detaillierter anzeigen lassen k√∂nnen. Zus√§tzlich wird die x-Achse ‚Äúfrei‚Äù gegeben, .e.¬†die Skalierung wird jetzt auf jeder Achse separat bestimmt scales = 'free_x' facet_wrap(), um die Verteilungen besser zu sehen.Die h√§ufigsten Anteile beim Land liegen bei 40‚Äì42% und bei der Stadt bei 58‚Äì60%.Die Histogramme geben nun sehr gut die Verteilung der Anteile der Stadt- und Landbewohner wieder. Solche Verteilungen nennt man Stichprobenverteilungen. Sie zeigen die Verteilung einer statistischen Kenngr√∂√üe (Statistik), unserem Fall Anteil, die aus zuf√§lligen Stichproben ausgerechnet wurde. Die Stichprobenverteilung beantwrotet die Frage: Wenn ich eine zuf√§llige Menge (Stichprobengr√∂√üe) Daten (Zufallsstichprobe) aus der Grundgesamtheit herausgreife und eine Kenngr√∂√üe (z.B. Anteil) berechne, welchen Wert werde ich im Mittel erhalten und wie stark wird der Wert schwanken.","code":"\nset.seed(345)\n\nbefragung_reps <- 1000\n\nbefragung_reps <- rep_sample_n(grundgesamtheit, size = befragung_size, replace = FALSE, reps = befragung_reps)\n\nwohnort_props <- befragung_reps %>% \n  group_by(replicate, wohnort) %>% \n  summarise(prop = n()/befragung_size)\n\n\nggplot(data = wohnort_props, aes(x = prop)) + \n  geom_histogram(binwidth = 0.02, boundary = 0.4, col = 'white') +\n  facet_wrap(~ wohnort, scales = 'free_x') +\n  labs(x = 'Anteile beim Wohnort', title = 'Verteilung der Wohnorte', y = 'H√§ufigkeit')"},{"path":"stichproben.html","id":"stichprobengr√∂√üe","chapter":"Kapitel 7 Stichproben und Variabilit√§t","heading":"7.1.2 Stichprobengr√∂√üe","text":"passiert, wenn wir die Gr√∂√üe der Stichproben variieren? Das w√ºrde Befragungen mit unterschiedlicher Anzahl von Teilnehmern entsprechen. Wir vergleichen 25, 50 und 100 Befragte und wiederholen jeweils 1000 Mal, um erneut Stichprobenverteilungen plotten zu k√∂nnen. Das ist eine repetitive Aufgabe und ich werde daf√ºr eine Funktion definieren. Wie man das macht, wird einer sp√§teren Stunde erkl√§rt.Nun wenden wir diese selbst definierte Funktion und f√ºren die Befragungen durch.Wir stellen die drei Stichprobenverteilungen dar. Die binwidth ist jeweils eine andere.Wie kann man diese Stichprobenverteilungen charakterisieren? Nun, es sind erster Linie Daten und wie bei jedem Datensatz kann man auch hier einen Mittelwert und eine Stadanrdabweichung angeben. Die Standardabweichung der Stichprobenverteilung hei√üt Standardfehler und fasst den Einfluss der Variabilit√§t (zuf√§lliges Herausgreifen der Studierenden) zusammen.Sie sehen, dass mit steigender Stichprobengr√∂√üe der Standardfehler sinkt. Das ist intuitiv verst√§ndlich, denn je mehr Studierende wir (pro Wiederholung!) befragen, desto repr√§sentativer ist die Stichprobe.Da dieses Kapitel wichtig ist, gibt es ausnahmsweise vorformulierte Take-Home-Messages üòÑ:\nEine zuf√§llige Stichprobe ist (meistens\\(^*\\)) der K√∂nigsweg, um repr√§sentative Informationen √ºber die Grundgesamtheit zu bekommen.\n\nDie Verteilung einer statistischen Kenngr√∂√üe, die aus Zufallsstichproben ausgerechnet wurde, hei√üt Stichprobenverteilung. Um diese Verteilung zu bekommen, muss man wiederholt Stichproben erheben. Je mehr Stichproben man erhebt, desto genauer kann man die Stichprobenverteilung beschreiben.\n\nDie Standardabweichung der Kenngr√∂√üe, die durch die Stichprobenverteilung dargestellt wird, hei√üt Standardfehler.\n\nDer Zufall macht sich durch eine Streuung (erfasst durch den Standardfehler) der Stichprobenverteilung bemerkbar. Je gr√∂√üer die einzelnen Stichproben, desto kleiner der Standardfehler.\n\\(^*\\): Manchmal ist die interessierte Gr√∂√üe unterschiedlichen Untergruppen der Grundgesamtheit unterschiedlich verteilt. Z.B. k√∂nnten bestimmte Haltungen der Bev√∂lkerung gegen√ºber irgendwelchen Sachverhalten von Alter oder Bildungsstand oder Wohnort (Stadt vs.¬†Land) abh√§ngen. Dann sollte man sich √ºberlegen, ob man statt einer zuf√§lligen Stichprobe lieber eine geschichtete Zufallsstichprobe zieht, d.h. innerhalb dieser Kategorien zuf√§llig beprobt.","code":"\ncalculate_props <- function(grund_data = grundgesamtheit, befragung_size, befragung_reps = 1000) {\n  \n  befragung <- rep_sample_n(grund_data, size = befragung_size, replace = FALSE, reps = befragung_reps)\n\nwohnort_props <- befragung %>% \n  group_by(replicate, wohnort) %>% \n  summarise(prop = n()/befragung_size)\n\nwohnort_props\n}\nset.seed(123)\n\n# Stichprobengr√∂√üe 25\nwohnort_props_25 <- calculate_props(grund_data = grundgesamtheit, befragung_size = 25, befragung_reps = 1000)\n  \n# Stichprobengr√∂√üe 50\nwohnort_props_50 <- calculate_props(grund_data = grundgesamtheit, befragung_size = 50, befragung_reps = 1000)\n\n# Stichprobengr√∂√üe 100\nwohnort_props_100 <- calculate_props(grund_data = grundgesamtheit, befragung_size = 100, befragung_reps = 1000)\nggplot(data = wohnort_props_25, aes(x = prop)) + \n  geom_histogram(binwidth = 0.05, boundary = 0.4, col = 'white') +\n  facet_wrap(~ wohnort, scales = 'free_x') +\n  labs(x = 'Anteile beim Wohnort', title = 'Verteilung der Wohnorte, Stichprobengr√∂√üe = 25', y = 'H√§ufigkeit')\nggplot(data = wohnort_props_50, aes(x = prop)) + \n  geom_histogram(binwidth = 0.02, boundary = 0.4, col = 'white') +\n  facet_wrap(~ wohnort, scales = 'free_x') +\n  labs(x = 'Anteile beim Wohnort', title = 'Verteilung der Wohnorte, Stichprobengr√∂√üe = 50', y = 'H√§ufigkeit')\nggplot(data = wohnort_props_100, aes(x = prop)) + \n  geom_histogram(binwidth = 0.02, boundary = 0.4, col = 'white') +\n  facet_wrap(~ wohnort, scales = 'free_x') +\n  labs(x = 'Anteile beim Wohnort', title = 'Verteilung der Wohnorte, Stichprobengr√∂√üe = 100', y = 'H√§ufigkeit')\nwohnort_props_25 %>% \n  group_by(wohnort) %>% \n  summarise(prop_sd = sd(prop))## # A tibble: 2 x 2\n##   wohnort prop_sd\n##   <chr>     <dbl>\n## 1 land      0.102\n## 2 stadt     0.102\nwohnort_props_50 %>% \n  group_by(wohnort) %>% \n  summarise(prop_sd = sd(prop))## # A tibble: 2 x 2\n##   wohnort prop_sd\n##   <chr>     <dbl>\n## 1 land     0.0679\n## 2 stadt    0.0679\nwohnort_props_100 %>% \n  group_by(wohnort) %>% \n  summarise(prop_sd = sd(prop))## # A tibble: 2 x 2\n##   wohnort prop_sd\n##   <chr>     <dbl>\n## 1 land     0.0458\n## 2 stadt    0.0458"},{"path":"stichproben.html","id":"lesestoff-5","chapter":"Kapitel 7 Stichproben und Variabilit√§t","heading":"7.2 Lesestoff","text":"Kapitel 7 Ismay Kim (2021)","code":""},{"path":"stichproben.html","id":"aufgaben-4","chapter":"Kapitel 7 Stichproben und Variabilit√§t","heading":"7.3 Aufgaben","text":"","code":""},{"path":"stichproben.html","id":"wahrer-wert-in-der-grundgesamtheit","chapter":"Kapitel 7 Stichproben und Variabilit√§t","heading":"7.3.1 Wahrer Wert in der Grundgesamtheit","text":"Berechnen Sie die Anteile von Studierenden der Grundgesamtheit, die der Stadt bzw. auf dem Land leben. Wie gut waren die Sch√§tzungen im Vergleich zum wahren Wert der Grundgesamtheit?","code":""},{"path":"stichproben.html","id":"lohnt-eine-station-zum-ausleihen-von-farr√§hdern","chapter":"Kapitel 7 Stichproben und Variabilit√§t","heading":"7.3.2 Lohnt eine Station zum Ausleihen von Farr√§hdern?","text":"unserem fiktiven Beispiel der Uni Werdeschlau geht es eigenlich darum, ob sich eine Station zum Ausleihen von Fahrr√§dern lohnen w√ºrde. Daher ist die Frage interessant, wie viele Studierende mit dem Fahrrad zur Uni kommen. Wiederholen Sie die obige Analyse und ermitteln Sie statt der Anteile von Stadt- und Landbewohnern nun die Anteile der unterschiedlichen Verkehrsmittel. Die selbst definierte Funktion m√ºssen Sie durch die folgende ersetzten.der L√∂sung zu dieser Aufgabe erhalten Sie auch weiter Tipps zur Darstellung von Histogrammen und Dichtefunktionen üòé.","code":"\ncalculate_props_verkehr <- function(grund_data = grundgesamtheit, befragung_size, befragung_reps = 1000) {\n  \n  befragung <- rep_sample_n(grund_data, size = befragung_size, replace = FALSE, reps = befragung_reps)\n\nverkehrsmittel_props <- befragung %>% \n  group_by(replicate, verkehrsmittel) %>% \n  summarise(prop = n()/befragung_size)\n\nverkehrsmittel_props\n}"},{"path":"stichproben.html","id":"ihre-arbeit-einreichen-3","chapter":"Kapitel 7 Stichproben und Variabilit√§t","heading":"7.4 Ihre Arbeit einreichen","text":"Speichern Sie Ihr Notebook ab und laden Sie nur die .Rmd Datei vom Server.Laden Sie Ihre .Rmd Datei ILIAS hoch. Beachten Sie die Deadline!Sie erhalten die Musterl√∂sung nach dem Hochladen.","code":""},{"path":"bootstrapping-und-konfidenzintervalle.html","id":"bootstrapping-und-konfidenzintervalle","chapter":"Kapitel 8 Bootstrapping und Konfidenzintervalle","heading":"Kapitel 8 Bootstrapping und Konfidenzintervalle","text":"\nFunktionsweise von Bootstrap erkl√§ren\n\nBootstrap-Konfidenzintervalle f√ºr Mittelwert berechnen\nIm Kapitel 7 haben Sie gesehen, dass Statistiken aus zuf√§llig gezogenen Stichproben, dem Zufall unterliegen. Sie sind Zufallsvariablen. Diesen Zufall haben wir mit Hilfe der Stichprobenverteilung dieser Statistiken quantifiziert, dem wir den Standardfehler, die Standardabweichung aus der Stichprobenverteilung, berechnet haben.Die Statistik, die wir im Kapitel 7 berechnet haben, war der Anteil von Studierenden, die entweder der Stadt oder auf dem Land wohnen. Mit jeder Stichprobe, aus der wir diesen Anteil berechnet haben, haben wir eigentlich gesch√§tzt, wie gro√ü der wahre Anteil der Stadt- und Landbewohner der Grundgesamtheit (allen 12000 Studierenden von Werdeschlau) ist. Der aus der Stichprobe berechnete Anteil ist also ein Sch√§tzer f√ºr den wahren Anteil der Grundgesamtheit. Dieser Sch√§tzer ist eine Zufallsvariable (s.o.) und wie jede andere Zufallsvariable ist er durch seine Verteilung, n√§mlich die Stichprobenverteilung charakterisiert.Wir k√∂nnen jetzt also eine Menge statistischer Begriffe mit Hilfe unseres Beispiels mit Leben f√ºllen:\nGrundgesamtheit: alle Studierenden der Universit√§t Werdeschlau\n\nzuf√§llige Stichprobe: eine zuf√§llig ausgesuchte Gruppe von Studierenden\n\nParameter der Grundgesamtheit: z.B. der wahre Anteil von Studierenden, die der Stadt oder auf dem Land leben\n\nSch√§tzer f√ºr diesen Parameter der Grundgesamtheit: Anteil der Studierenden, die der Stadt oder auf dem Land leben, berechnet aus der zuf√§lligen Stichprobe. Da die Stichprobe zuf√§llig ist, kann man davon ausgehen, dass sie repr√§sentativ f√ºr die Grundgesamtheit ist und der Sch√§tzer unverzerrt (unbiased, d.h. ohne einen systematischen Fehler).\n\nInferenz: schlie√üen auf die Grundgesamtheit darf man, wenn die Stichprobe zuf√§llig erhoben wurde und repr√§sentative f√ºr die Fragestellung ist.\nDie Begriffe Statistik, Sch√§tzer, Sch√§tzfunktion und Stichprobenfunktion werden als Synonyme verwendet. Die Statistik ist ja auch eine Funktion, da sie mit einer Formel eine Zahl aus Daten (Stichprobe) berechnet. Sie fasst die Stichprobe also zusammen.Im echten Leben werden Sie kaum wiederholt befragen (Stichproben ziehen) k√∂nnen. Das ist vollkommen unrealistisch und nur f√ºr Computerexperimente ein tolles Werkzeug. diesem Kapitel wird es darum gehen, wie man nun im richtigen Leben mit einer Stichprobe einen Parameter der Grundgesamtheit sch√§tzen kann und dabei seine Variabilit√§t quantifiziert.","code":""},{"path":"bootstrapping-und-konfidenzintervalle.html","id":"bootstrapping-die-m√ºnchhausenmethode","chapter":"Kapitel 8 Bootstrapping und Konfidenzintervalle","heading":"8.1 Bootstrapping, die M√ºnchhausenmethode","text":"Wenn wir nur eine Stichprobe haben, werden wir den Parameter der Grundgesamtheit daraus sch√§tzen. Der Sch√§tzer kann der Mittelwert oder eben auch der Anteil sein, wie bei unseren vorherigen Beispielen mit Mittelwert der Anreisezeit oder dem Anteil der Studierenden aus der Stadt bzw. vom Land.Da jede Stichprobe dem Zufall unterliegt und der Sch√§tzer somit eine Zufallsvariable darstellt, w√ºrden wir gerne wissen, wie gut wir sch√§tzen.Gibt es einen plausiblen Bereich f√ºr den Mittelwert der Anreisezeit? Plausibel meint, dass wenn wir sehr oft verschiedene zuf√§llige Stichprobe ziehen, dieser Bereich sagen wir mal 95% der F√§lle den wahren Mittelwert einschlie√üt. Solche Plausibilit√§tsbereiche nennt man Konfidenzintervalle.Es gibt mehrere Methoden, solche Konfidenzintervalle zu berechnen. Wenn man die Verteilung des Sch√§tzers kennt, wie z.B. beim Mittelwert (Normalverteilung), dann kann man daraus den Standardfehler berechnen (nennen wir diesen \\(SE\\)). Ein 95%-Konfidenzintervall w√§re dann \\(\\hat{\\mu} \\pm 1.96 \\cdot SE\\), wobei \\(\\hat{\\mu}\\) der gesch√§tzter Mittelwert ist. Das H√ºtchen steht f√ºr gesch√§tzt. Diese Formel haben Sie bestimmt schon der Grundvorlesung Statistik gesehen.Es gibt aber Sch√§tzer, f√ºr die keine theoretische Verteilung bekannt ist. Da muss man eine andere Methode anwenden. Eine bekannte Methode hei√üt Bootstrapping (Bootstrap-Verfahren), manchmal auch M√ºnchhausenmethode. Sie klingt auf den ersten Blick wie ein Selbstbetrug, als ob man sich selbst den Haaren aus dem Sumpf zieht (Abblildung 8.1), hat aber sehr gut fundierte mathematische Wurzeln. Bootstrap wurde von Efron (1979) Ende der 70er vorgestellt und hat sich seit dem als eine der wichtigsten Resampling-Strategien etabliert.\nAbbildung 8.1: M√ºnchhausen zieht sich aus dem Sumpf (Theodor Hosemann (1807-1875), Public domain, via Wikimedia Commons)\nDas Prinzip beim Bootstrap ist, dass die Stichprobe die Rolle der Grundgesamtheit √ºbernimmt. Abbildung 8.2 zeigt das Vorgehen aus dem Kapitel 7. Wir ziehen mehrere echte Stichproben aus einer Grundgesamtheit, erhalten eine Stichprobenverteilung und k√∂nnen den Parameter der Grundgesamtheit sch√§tzen.\nAbbildung 8.2: Berechnen einer Stichprobenverteilung durch wiederholtes Stichproben ziehen. Abbildung aus (Hesterberg 2015), dort Figure 4. Die Publikation ist open-access und darf f√ºr nicht-kommerzielle Zwecke verwendet werden.\nAbbildung 8.3 haben wir nur eine Stichprobe. Wir gehen davon aus, dass diese Stipchprobe eine Miniatur der Grundgesamtheit ist, also zuf√§llig gezogen wurde und repr√§sentative ist. Mit dieser Grundidee im Kopf, ersetzten wir die Grundgesamtheit durch dies Stichprobe und verfahren (fast) genauso, um die Stichprobenverteilung zu ermitteln. Der einzige Unterschied ist, dass wir aus dieser einen Stichprobe mit Zur√ºcklegen neue Stichproben (Bootstrap-Stichproben) ziehen.\nAbbildung 8.3: Berechnen einer Stichprobenverteilung durch wiederholtes Ziehen aus einer Stichprobe mit Zur√ºcklegen. Abbildung aus (Hesterberg 2015), dort Figure 5. Die Publikation ist open-access und darf f√ºr nicht-kommerzielle Zwecke verwendet werden.\nDie Konfidenzintervalle berechnet man aus der Stichprobenverteilung der Bootstrap-Stichproben, indem man z.B. das 2.5% und das 97.5% Quantil berechnet. Zwischen diesen beiden Quantilen sind 95% der Werte enthalten. Dieses Intervall nennt man das 95%-Konfidenzintervall.","code":""},{"path":"bootstrapping-und-konfidenzintervalle.html","id":"konfidenzintervall-f√ºr-den-mittelwert-der-anreisezeit","chapter":"Kapitel 8 Bootstrapping und Konfidenzintervalle","heading":"8.2 Konfidenzintervall f√ºr den Mittelwert der Anreisezeit","text":"Wir sehen uns das Ganze anhand des Beispiels der Studierenden aus Werdeschlau. Zun√§chst wieder der Code f√ºr die Grundgesamtheit.Nun befragen wir 200 Studierende.Wir berechnen den wahren Mittelwert der Anreisezeit und den Mittelwert aus der Befragung.Wir ziehen nun unsere Bootstrap-Stichproben aus der einen Stichprobe, n√§mlich der befragung. Achten Sie darauf, wie √§hnlich der Code zum Ziehen von echten Stichproben ist. Wir √§ndern nur replace = TRUE.Studierende kommen jetzt mehrfach vor, da wir ja mit Zur√ºcklegen gezogen haben. Wir sehen uns das den erste 50 Bootstrap-Stichproben .Nun berechnen wir die Mittelwerte aus den Bootstrap-Stichproben.Der Standardfehler des Bootstraps und das 95%-Konfidenzintervall basierend auf Quantilen berechnen sich wie folgt:Wir stellen die Stichprobenverteilung mit dem Standardfehler des Bootstraps und dem 95%-Konfidenzintervall dar. Das ist eine umfangreiche Grafik und wir gehen der √úbung Schritt f√ºr Schritt vor. Die Funktion scale_color_manual erlaubt es uns, die Legende anzupassen.Der Standardfehler des Bootstraps stimmt sehr gut mit dem Fehler \\(s/\\sqrt(n)\\) f√ºr den Sch√§tzer des Mittelwerts √ºberein. Da wir normalerweise die wahre Standardabweichung der Grundgesamtheit nicht kennen, wird der Formel \\(s/\\sqrt(n)\\) die Standardabweichung der Stichprobe als Sch√§tzung verwendet.Standardfehler des Bootstraps.Und der wahre Standardfehler, wenn man die Standardabweichung der Grundgesamtheit kennt.","code":"\nlibrary(tidyverse)\nlibrary(infer)\nset.seed(123)\n\nstudent_id <- 1:12000\n  \nanreise <- c(runif(n = 12000 * 0.8, min = 5, max = 40),\n             runif(n = 12000 * 0.2, min = 60, max = 120))\n\ngeschlecht <- sample(c('m', 'w'), size = 12000, replace = TRUE)\n\nwohnort <- sapply(anreise, function(x) {\n  if(x < 30) 'stadt'\n  else 'land'\n})\n\nverkehrsmittel <- sapply(anreise, function(x) {\n  if(x <= 10) 'zu_fuss'\n  else if(x > 10 & x <= 15) sample(c('zu_fuss', 'fahrrad'), size = 1)\n  else if(x > 15 & x <= 45) sample(c('bus', 'fahrrad', 'auto'), size = 1)\n  else sample(c('bus', 'auto'), size = 1)\n})\n\nzeit_bib <- 5 * 60 - 0.7 * anreise + rnorm(length(anreise), 0, 20)\n\ngrundgesamtheit <- tibble(student_id, geschlecht, wohnort, verkehrsmittel, anreise, zeit_bib)\n\ngrundgesamtheit## # A tibble: 12,000 x 6\n##    student_id geschlecht wohnort verkehrsmittel anreise zeit_bib\n##         <int> <chr>      <chr>   <chr>            <dbl>    <dbl>\n##  1          1 w          stadt   bus              15.1      294.\n##  2          2 w          land    fahrrad          32.6      254.\n##  3          3 w          stadt   fahrrad          19.3      231.\n##  4          4 m          land    auto             35.9      245.\n##  5          5 m          land    bus              37.9      234.\n##  6          6 w          stadt   zu_fuss           6.59     303.\n##  7          7 w          stadt   bus              23.5      284.\n##  8          8 m          land    auto             36.2      274.\n##  9          9 m          stadt   fahrrad          24.3      299.\n## 10         10 w          stadt   bus              21.0      282.\n## # ‚Ä¶ with 11,990 more rows\nset.seed(345)\n\nbefragung_size <- 200\n\nbefragung <- rep_sample_n(grundgesamtheit, size = befragung_size, replace = FALSE, reps = 1)\n\nbefragung## # A tibble: 200 x 7\n## # Groups:   replicate [1]\n##    replicate student_id geschlecht wohnort verkehrsmittel anreise zeit_bib\n##        <int>      <int> <chr>      <chr>   <chr>            <dbl>    <dbl>\n##  1         1       1623 m          stadt   zu_fuss           7.06     299.\n##  2         1       9171 m          stadt   fahrrad          11.3      278.\n##  3         1      10207 w          land    bus             107.       199.\n##  4         1       3506 w          stadt   bus              25.0      326.\n##  5         1       8892 w          stadt   bus              28.1      259.\n##  6         1       5460 m          stadt   bus              23.6      299.\n##  7         1       6120 w          stadt   bus              20.0      268.\n##  8         1        865 w          stadt   fahrrad          26.6      290.\n##  9         1      11586 m          land    bus             114.       207.\n## 10         1       8153 w          stadt   zu_fuss           8.06     297.\n## # ‚Ä¶ with 190 more rows\nmean_grundgesamtheit <- grundgesamtheit %>% \n  summarise(Mittelwert = mean(anreise))\n\nmean_grundgesamtheit## # A tibble: 1 x 1\n##   Mittelwert\n##        <dbl>\n## 1       36.0\nmean_befragung <- befragung %>% \n  summarise(Mittelwert = mean(anreise))\n\nmean_befragung## # A tibble: 1 x 2\n##   replicate Mittelwert\n##       <int>      <dbl>\n## 1         1       34.1\nset.seed(345)\n\nbefragung_size <- 200\nnumber_reps <- 10000\n\nbefragung_reps_bootstrap <- rep_sample_n(befragung, size = befragung_size, replace = TRUE, reps = number_reps)\n\nbefragung_reps_bootstrap## # A tibble: 2,000,000 x 7\n## # Groups:   replicate [10,000]\n##    replicate student_id geschlecht wohnort verkehrsmittel anreise zeit_bib\n##        <int>      <int> <chr>      <chr>   <chr>            <dbl>    <dbl>\n##  1         1       7038 m          stadt   bus              29.4      243.\n##  2         1        493 m          stadt   bus              21.1      303.\n##  3         1       3442 m          land    auto             30.3      311.\n##  4         1       4920 w          stadt   bus              21.1      290.\n##  5         1       3178 w          stadt   zu_fuss           8.07     325.\n##  6         1       7694 w          land    auto             31.3      295.\n##  7         1       9479 m          land    bus              39.5      302.\n##  8         1       3367 m          land    auto             36.4      272.\n##  9         1       5985 w          stadt   fahrrad          15.9      303.\n## 10         1        843 m          stadt   fahrrad          26.4      300.\n## # ‚Ä¶ with 1,999,990 more rows\nbefragung_reps_bootstrap %>% \n  filter(replicate %in% (1:50)) %>% \n  group_by(replicate, student_id) %>% \n  tally() %>% \n  filter(n != 1) %>% \n  arrange(desc(n))## # A tibble: 2,657 x 3\n## # Groups:   replicate [50]\n##    replicate student_id     n\n##        <int>      <int> <int>\n##  1        43       4787     8\n##  2        20       5985     6\n##  3        34       7749     6\n##  4        38       5641     6\n##  5        41       8456     6\n##  6         3       7083     5\n##  7         3      10943     5\n##  8         5       8994     5\n##  9         6      10118     5\n## 10         8      11425     5\n## # ‚Ä¶ with 2,647 more rows\nres_means_bootstrap <- befragung_reps_bootstrap %>%\n  group_by(replicate) %>% \n  summarise(Mittelwert = mean(anreise))\n\nres_means_bootstrap## # A tibble: 10,000 x 2\n##    replicate Mittelwert\n##        <int>      <dbl>\n##  1         1       32.6\n##  2         2       31.9\n##  3         3       38.9\n##  4         4       33.5\n##  5         5       35.4\n##  6         6       37.2\n##  7         7       34.4\n##  8         8       33.4\n##  9         9       35.5\n## 10        10       31.0\n## # ‚Ä¶ with 9,990 more rows\nstat_bootstrap <- res_means_bootstrap %>% \n  summarize(mean = mean(Mittelwert), sd = sd(Mittelwert), ci_2.5 = quantile(Mittelwert, probs = 0.025), ci_97.5 = quantile(Mittelwert, probs = 0.975))\nggplot(res_means_bootstrap, aes(Mittelwert)) + \n  geom_histogram(bins = 50 , color=\"white\") +\n  labs(y = 'H√§ufigkeit', x = 'Mittelwerte der Anreise (min)') +\n  geom_vline(aes(xintercept = mean_grundgesamtheit$Mittelwert, col = 'grundgesamtheit'), linetype = \"dashed\", size = 2) + \n  geom_vline(aes(xintercept = stat_bootstrap$mean, col = 'boot')) + \n  geom_vline(aes(xintercept = mean_befragung$Mittelwert, col = 'stichprobe'), linetype = 'dashed', size = 2) +\n  geom_vline(aes(xintercept = stat_bootstrap$mean + stat_bootstrap$sd, col = 'sd')) + \n  geom_vline(xintercept = stat_bootstrap$mean - stat_bootstrap$sd, col = 'orange') + \n  geom_vline(aes(xintercept = stat_bootstrap$ci_2.5, col = 'ci')) +\n  geom_vline(xintercept = stat_bootstrap$ci_97.5, col = 'brown') + \n  scale_color_manual(name = \"Statistik\", values = c(grundgesamtheit = 'black', sd = 'orange', boot = 'red', ci = 'brown', stichprobe = 'gray90'), breaks = c('stichprobe', 'boot', 'sd', 'ci', 'grundgesamtheit'), label = c('Mittelwert Stichprobe', 'Mittelwert Bootstrap', 'Standardfehler Bootstrap', '95% Konfidenzintervall Bootstrap', 'Mittelwert Population'))\nbefragung %>% \n  summarize(sd_error = sd(anreise)/sqrt(length(anreise)))## # A tibble: 1 x 2\n##   replicate sd_error\n##       <int>    <dbl>\n## 1         1     2.04\nres_means_bootstrap %>% \n  summarize(sd_error = sd(Mittelwert))## # A tibble: 1 x 1\n##   sd_error\n##      <dbl>\n## 1     2.06\ngrundgesamtheit %>% \n  summarize(sd_error = sd(anreise)/sqrt(length(befragung$anreise)))## # A tibble: 1 x 1\n##   sd_error\n##      <dbl>\n## 1     2.09"},{"path":"bootstrapping-und-konfidenzintervalle.html","id":"bootstrap-konfidenzintervalle-mit-infer","chapter":"Kapitel 8 Bootstrapping und Konfidenzintervalle","heading":"8.3 Bootstrap-Konfidenzintervalle mit infer","text":"Das Paket infer bietet eine sehr bequeme M√∂glichkeit, Konfidentintervalle mit Bootstrap zu berechnen und zu visualisieren. Das Vorgehen aus dem vorherigen Abschnitt √ºbertragen wir nun den Workflow mit infer.Brechnen der Bootstrap-Stichproben.Visualisieren der Stichprobenverteilung.Berechnen KonfidenzintervalleVisualisieren der Stichprobenverteilung mit den KonfidenzintervallenDie Konfidenzintervalle, die wir als Quantile aus der Bootstrap-Stichprobenverteilung berechnet haben, und die, die man mit der Formel \\(\\hat{\\mu} \\pm 1.96 \\cdot s/\\sqrt(n)\\) berechnen kann, sind sehr √§hnlich. Das werden Sie einer der Aufgaben (s.u.) nachrechnen. Das liegt daran, dass der Zentrale Grenzwertsatz garantiert, dass die Stichprobenverteilung des Sch√§tzers des Mittelwerts eine Normalverteilung ist. Es gibt aber Sch√§tzer, wie z.B. den des Medians, f√ºr den es keine theoretische Verteilung gibt. Daher gilt als Take-Home-Message, dass man Bootstrap zum Berechnen der Konfidenzintervalle gut einsetzten kann, egal ob es eine theoretische Verteilung des Sch√§tzers gibt. Die Quantilmethode zur Berechnung der Bootstrap-Konfidenzintervalle liefert gute Ergebnisse. Wir werden im sp√§teren Kapitel lernen, dass man Bootstrap auch f√ºr die Regressionsanalyse nutzen kann.","code":"\nset.seed(345)\n\nbootstrap_distribution <- befragung %>%\n  specify(response = anreise) %>% \n  generate(reps = 10000, type = 'bootstrap') %>% \n  calculate(stat = 'mean')\nvisualize(bootstrap_distribution)\npercentile_ci <- bootstrap_distribution %>% \n  get_confidence_interval(level = 0.95, type = \"percentile\")\npercentile_ci## # A tibble: 1 x 2\n##   lower_ci upper_ci\n##      <dbl>    <dbl>\n## 1     30.1     38.3\nvisualize(bootstrap_distribution) + \n  shade_confidence_interval(endpoints = percentile_ci, color = \"orange\", fill = \"khaki\") +\n  geom_vline(xintercept = mean_grundgesamtheit$Mittelwert, linetype = 'dashed')"},{"path":"bootstrapping-und-konfidenzintervalle.html","id":"bedeutung-der-konfidenzintervalle","chapter":"Kapitel 8 Bootstrapping und Konfidenzintervalle","heading":"8.4 Bedeutung der Konfidenzintervalle","text":"Ein Konfidenzintervall h√§ngt von der Stichprobe ab, ist also vom Zufall betroffen. Man kann also sagen, dass die Grenzen des Konfidenzintervalls Zufallsvariablen sind. Das Konfidenzintervall wird nicht immer den wahren Parameter der Grundgesamtheit einschlie√üen. Die Definition eines 95%-Konfidenzintervalls kann wie folgt formuliert werden:Wenn wir sehr oft die Stichproben neu ziehen und jedesmal ein 95%-Kofidenzintervall berechnen, dann erwarten wir, dass 95% der F√§lle diese Konfidenzintervalle den wahren Parameter der Grundgesamtheit enthalten.Das Konfidenzintervall ist unsere Absch√§tzung der Lage des wahren Parameters der Grundgesamtheit. Eine andere Absch√§tzung haben wir nicht (es sei denn, es gibt wiederum eine theoretische Verteilung). Die Interpretation wird oft abgek√ºrzt, dass man sagt, man sei zu 95% sicher, dass das 95%-Konfidenzintervall den wahren Parameter enth√§lt. Das ist nicht richtig (s. Definition oben). Es ist besser zu sagen, dass 95% der F√§lle, das Konfidenzintervall den wahren Parameter der Grundgesamtheit enth√§lt. mit 95% der F√§lle gemeint ist, wissen Sie ja, wenn Sie sich die genaue Definition erinnern üòÑ.","code":""},{"path":"bootstrapping-und-konfidenzintervalle.html","id":"lesestoff-6","chapter":"Kapitel 8 Bootstrapping und Konfidenzintervalle","heading":"8.5 Lesestoff","text":"Kapitel 8 Ismay Kim (2021)","code":""},{"path":"bootstrapping-und-konfidenzintervalle.html","id":"aufgaben-5","chapter":"Kapitel 8 Bootstrapping und Konfidenzintervalle","heading":"8.6 Aufgaben","text":"","code":""},{"path":"bootstrapping-und-konfidenzintervalle.html","id":"konfidenzintervall-aus-dem-zentralen-grenzwertsatz","chapter":"Kapitel 8 Bootstrapping und Konfidenzintervalle","heading":"8.6.1 Konfidenzintervall aus dem Zentralen Grenzwertsatz","text":"Der Zentrale Grenzwertsatz besagt, dass die Stichprobenverteilung des Sch√§tzers des Mittelwerts sich asymptotisch (also bei vielen Stichproben) der Normalverteilung n√§hert. Daher kann man f√ºr die Konfidenzintervalle auch die folgende Formel nutzen: \\(\\hat{\\mu} \\pm 1.96 \\cdot SE\\), wobei \\(\\hat{\\mu}\\) der gesch√§tzter Mittelwert ist. Das H√ºtchen steht f√ºr gesch√§tzt.Berechnen Sie die Konfidenzintervalle mit dieser Formel f√ºr die Stichprobenverteilung aus dem Bootstrap f√ºr den Mittelwert der Anreisezeit. Dazu passen Sie der Funktion get_confidence_interval den Typ des Konfidenzintervalls type = \"se\" und geben Sie den Mittelwert der Befragung : get_confidence_interval(type = \"se\", point_estimate = mean_befragung$Mittelwert).Stellen Sie die Stichprobenverteilung mit diesem Konfidenzintervall dar und vergleichen Sie mit dem Konfidenzintervall, das wir mit der Quantil-Methode berechnet haben.","code":""},{"path":"bootstrapping-und-konfidenzintervalle.html","id":"anteile-an-stadt--und-landbewohnern","chapter":"Kapitel 8 Bootstrapping und Konfidenzintervalle","heading":"8.6.2 Anteile an Stadt- und Landbewohnern","text":"Wiederholen Sie die Analyse, die wir mit dem Paket infer f√ºr die Sch√§tzung des Mittelwerts der Anreisezeit gemacht haben, nun f√ºr die Anteile Stadt- und Landbewohnern. Tip: specify(response = wohnort, success = 'stadt').","code":""},{"path":"bootstrapping-und-konfidenzintervalle.html","id":"wie-h√§ngt-das-konfidenzintervall-von-der-stichprobengr√∂√üe-ab","chapter":"Kapitel 8 Bootstrapping und Konfidenzintervalle","heading":"8.6.3 Wie h√§ngt das Konfidenzintervall von der Stichprobengr√∂√üe ab?","text":"Wiederholen Sie die Analyse f√ºr den Mittelwert der Anreisezeit f√ºr eine Stichprobe von 30 Studierenden. Wie ver√§ndert sich das Konfidenzintervall?","code":""},{"path":"bootstrapping-und-konfidenzintervalle.html","id":"ihre-arbeit-einreichen-4","chapter":"Kapitel 8 Bootstrapping und Konfidenzintervalle","heading":"8.7 Ihre Arbeit einreichen","text":"Speichern Sie Ihr Notebook ab und laden Sie nur die .Rmd Datei vom Server.Laden Sie Ihre .Rmd Datei ILIAS hoch. Beachten Sie die Deadline!Sie erhalten die Musterl√∂sung nach dem Hochladen.","code":""},{"path":"bootstrapping-und-konfidenzintervalle.html","id":"weiterf√ºhrende-literatur-1","chapter":"Kapitel 8 Bootstrapping und Konfidenzintervalle","heading":"8.8 Weiterf√ºhrende Literatur","text":"Kapitel 17.3 Sauer (2019)","code":""},{"path":"hypothesentests-mit-dem-paket-infer.html","id":"hypothesentests-mit-dem-paket-infer","chapter":"Kapitel 9 Hypothesentests mit dem Paket infer","heading":"Kapitel 9 Hypothesentests mit dem Paket infer","text":"\nIdee hinter simulationsbasierten Tests erkl√§ren\n\nTests mit dem Paket infer durchf√ºhren\n","code":""},{"path":"hypothesentests-mit-dem-paket-infer.html","id":"es-gibt-nur-einen-test","chapter":"Kapitel 9 Hypothesentests mit dem Paket infer","heading":"9.1 Es gibt nur einen Test","text":"Ich wei√ü nicht, wie es Ihnen ergangen ist, aber ich habe meiner Grundausbildung Statistik verschiedene Tests kennen gelernt: \\(t\\)-Test f√ºr gepaarte und ungepaarte Stichproben, \\(F\\)-Test f√ºr die Varianz, \\(z\\)-Test etc. Ende war ich verwirrt und wusste nicht mehr, welchen ich wann nehmen soll. Ende des Tages musste ich, wenn ich einen neuen Datensatz hatte und einen Test brauchte, lange nachdenken, welchen ich nutzen soll.Diese vielen Tests stammen noch aus der Urzeit der Statistik, als Rechenzeit, wenn √ºberhaupt vorhanden, unbezahlbar war. Daher haben die V√§ter der Statistik (war damals √ºberwiegend eine reine M√§nnerclique üò†) viele N√§herungsverfahren entwickelt. Diese N√§herungsverfahren leiten eine theoretische Verteilung f√ºr verschiedene Teststatistiken ab. Tests, die auf solchen N√§herungen basieren, haben h√§ufig starke Annahmen √ºber die Daten, wie z.B. dass die Daten normalverteilt sein m√ºssen, oder dass der Datensatz gro√ü sein muss, damit die N√§herung stimmt.Heute ist f√ºr die meisten unserer Analysen ausreichen Rechenkapazit√§t vorhanden. Daher m√ºssen wir nicht mehr auf solche N√§herungen zur√ºck greifen, sondern k√∂nnen Computersimulationen benutzen. Diese Computersimulationen setzt man ein, um bei Hypothesentests Daten unter der Normalverteilung zu generieren. Abbildung 9.1 zeigt das allgemeine Vorgehen, wie es f√ºr jeden beliebigen Test g√ºltig ist. Dieses Vorgehen kann man auf folgende Schritte ‚Äúrunterkochen‚Äù:Teststatistik aus Stichprobe berechnen\nWir haben eine Stichprobe (data der Abbildung 9.1), die wir mit Hilfe einer Teststatistik zusammen fassen. Wir nennen diese Teststatistik \\(\\sigma^*\\). Sie kann z.B. der Mittelwert der Differenzen zwischen einer Behandlung und einer Kontrolle einem Experiment sein.Nullhypothese formulieren\nWir denken gut √ºber unsere Forschungsfrage nach und √ºberlegen uns, welches Modell besten die Nullhypothese \\(H_0\\), also eine Situation ohne jeglichen Effekt, wiedergibt. Im Falle des Mittelwerts eben eine Welt, der der besagte Mittelwert null ist, es also keinen Behandlungseffekt unserem Experiment gibt. Das Modell f√ºr \\(H_0\\) kann eine Permutation der Daten sein (Permutationstests) oder aus einer theoretischen Verteilung stammen (z.B. Normalverteilung). Es kann auch ein richtig kompliziertes Modell sein. Letzteres ist nicht Bestandteil diese Kurses.Simulation der Daten unter der Nullhypothese\nWir simulieren Daten aus diesem Modell ohne Effekt, d.h. Daten unter der Nullhypothese und berechnen aus jedem simulierten Datensatz dieselbe Teststatistik wie aus der echten Stichprobe.Berechnen der Stichprobenverteilung\nDie vielen simulierten Teststatistiken ergeben eine Stichprobenverteilung.Vergleich der beobachteten Teststatistik mit der Stichprobenverteilung ‚Äì Entscheidung\nNun k√∂nnen wir die Teststatistik \\(\\sigma^*\\) mit der Stichprobenverteilung der simulieren Teststatistiken vergleichen. Wir entscheiden, ob wir \\(\\sigma^*\\) der Welt ohne Effekt, also unter der Nullhypothese h√§ufig oder eher selten vorkommt. Wenn \\(\\sigma^*\\) selten vorkommt, verwerfen wir die Nullhypothese und sagen, dass es einen Effekt gibt. Mit anderen Worte, es ist dann unwahrscheinlich, dass das beobachtete \\(\\sigma^*\\) auf den Zufall zur√ºck zu f√ºhren ist. Als Entscheidungshilfe nutzen wir das Signifikanzniveau \\(\\alpha\\), das h√§ufig auf 5% gesetzt wird.Diese Schritte gelten wirklich f√ºr jeden beliebigen Test. Daher kann man verallgemeinert sagen, dass es nur einen Test (ein Testframework) gibt.\nAbbildung 9.1: Logik hinter den Hypothesentests aus der Sicht der modernen Datenanlyse (Quelle: http://allendowney.blogspot.com/2016/06/--still--one-test.html).\n","code":""},{"path":"hypothesentests-mit-dem-paket-infer.html","id":"workflow-in-infer","chapter":"Kapitel 9 Hypothesentests mit dem Paket infer","heading":"9.2 Workflow in infer","text":"Das Paket infer bietet ein einheitliches Framework f√ºr Hypothesentests (Abbildung 9.2). Es hat 4 Verben, die den oben beschriebenen Prozess der Hypothesentests vereinheitlichen:specify() Variablen festlegenhypothesize() Nullhypothese definierengenerate() Daten unter der Nullhypothese generierencalculate() Stichprobenverteilung (d.g. Verteilung der Teststatistik) berechnenvisualize() Stichprobenverteilung darstellenMit get_p_value kann man den \\(p\\)-Wert berechnen und mit shade_p_value diesen darstellen lassen.\nAbbildung 9.2: Verallgemeinertes Vorgehen bei Hypothesentests (Quelle: https://infer.netlify.app/).\n","code":""},{"path":"hypothesentests-mit-dem-paket-infer.html","id":"stadt--und-landbewohner-in-werdeschlau","chapter":"Kapitel 9 Hypothesentests mit dem Paket infer","heading":"9.2.1 Stadt- und Landbewohner in Werdeschlau","text":"Wir m√∂chten gerne wissen, ob sich unter den Studierenden Werdeschlau genauso viele Stadt- und Landbewohner gibt.Wir simulieren erneut unsere Grundgesamtheit.Nun befragen wir 200 Studierende.Wir berechnen den Anteil der Stadtbewohner der Befragung.Die Nullhypothese und die Alternativhypothese lauten:\\(H_0\\): es gibt keinen Unterschied der Anzahl der Stadt- und Landbewohner, d.h. Anteil der Stadtbewohner \\(p = 0.5\\).\\(H_A\\): Anteil der Stadtbewohner \\(p \\neq 0.5\\)Wir setzten das Ganz nun mit infer um.Das Paket infer setzt generate() die Art der Simulation automatisch (bootstrap, simulate oder permute). F√ºr sogen. Punkthypothesen null = \"point\" bei kategoriellen Variablen, z.B. \\(H_0\\): Anteil der Stadtbewohner = 0.5, simuliert generate() neue Daten mit Hilfe der Funktion sample() und nutzt die hypothesize() definierten Anteil p als Wahrscheinlichket f√ºr success. D.h. unserem Fall simuliert generate() 10000 neue Stichproben mit der Wahrscheinlichkeit von 0.5 f√ºr Stadtbewohner (success = 'stadt'), wie von \\(H_0\\) verlangt üòÑ.Wir sehen uns die Stichprobenverteilung .Ende berechnen wir den \\(p\\)-Wert.Der \\(p\\)-Wert ist sehr klein und kleiner als das Standard-Signifikanzniveau von 5%. Daher schlie√üen wir, dass es sehr unwahrscheinlich ist, dieses Verh√§ltnis von Stadt- und Landbewohnern unter den Studierenden zu beobachten, wenn es wirklich gleich viele Stad- und Landbewohner sind. Ergo, das Verh√§ltnis von Stadt- zu Landbewohnern ist nicht eins zu eins.","code":"\nlibrary(tidyverse)\nlibrary(infer)\nset.seed(123)\n\nstudent_id <- 1:12000\n  \nanreise <- c(runif(n = 12000 * 0.8, min = 5, max = 40),\n             runif(n = 12000 * 0.2, min = 60, max = 120))\n\ngeschlecht <- sample(c('m', 'w'), size = 12000, replace = TRUE)\n\nwohnort <- sapply(anreise, function(x) {\n  if(x < 30) 'stadt'\n  else 'land'\n})\n\nverkehrsmittel <- sapply(anreise, function(x) {\n  if(x <= 10) 'zu_fuss'\n  else if(x > 10 & x <= 15) sample(c('zu_fuss', 'fahrrad'), size = 1)\n  else if(x > 15 & x <= 45) sample(c('bus', 'fahrrad', 'auto'), size = 1)\n  else sample(c('bus', 'auto'), size = 1)\n})\n\nzeit_bib <- 5 * 60 - 0.7 * anreise + rnorm(length(anreise), 0, 20)\n\ngrundgesamtheit <- tibble(student_id, geschlecht, wohnort, verkehrsmittel, anreise, zeit_bib)\n\ngrundgesamtheit## # A tibble: 12,000 x 6\n##    student_id geschlecht wohnort verkehrsmittel anreise zeit_bib\n##         <int> <chr>      <chr>   <chr>            <dbl>    <dbl>\n##  1          1 w          stadt   bus              15.1      294.\n##  2          2 w          land    fahrrad          32.6      254.\n##  3          3 w          stadt   fahrrad          19.3      231.\n##  4          4 m          land    auto             35.9      245.\n##  5          5 m          land    bus              37.9      234.\n##  6          6 w          stadt   zu_fuss           6.59     303.\n##  7          7 w          stadt   bus              23.5      284.\n##  8          8 m          land    auto             36.2      274.\n##  9          9 m          stadt   fahrrad          24.3      299.\n## 10         10 w          stadt   bus              21.0      282.\n## # ‚Ä¶ with 11,990 more rows\nset.seed(345)\n\nbefragung_size <- 200\n\nbefragung <- rep_sample_n(grundgesamtheit, size = befragung_size, replace = FALSE, reps = 1)\n\nbefragung## # A tibble: 200 x 7\n## # Groups:   replicate [1]\n##    replicate student_id geschlecht wohnort verkehrsmittel anreise zeit_bib\n##        <int>      <int> <chr>      <chr>   <chr>            <dbl>    <dbl>\n##  1         1       1623 m          stadt   zu_fuss           7.06     299.\n##  2         1       9171 m          stadt   fahrrad          11.3      278.\n##  3         1      10207 w          land    bus             107.       199.\n##  4         1       3506 w          stadt   bus              25.0      326.\n##  5         1       8892 w          stadt   bus              28.1      259.\n##  6         1       5460 m          stadt   bus              23.6      299.\n##  7         1       6120 w          stadt   bus              20.0      268.\n##  8         1        865 w          stadt   fahrrad          26.6      290.\n##  9         1      11586 m          land    bus             114.       207.\n## 10         1       8153 w          stadt   zu_fuss           8.06     297.\n## # ‚Ä¶ with 190 more rows\nprop_hat <- befragung %>% \n  specify(response = wohnort, success = \"stadt\") %>%\n  calculate(stat = \"prop\")\n\nprop_hat## # A tibble: 1 x 1\n##    stat\n##   <dbl>\n## 1  0.62\nset.seed(123)\n\nnull_distn <- befragung %>%\n  specify(response = wohnort, success = \"stadt\") %>%\n  hypothesize(null = \"point\", p = .5) %>%\n  generate(reps = 10000) %>%\n  calculate(stat = \"prop\")## Setting `type = \"simulate\"` in `generate()`.\nvisualize(null_distn) +\n  shade_p_value(obs_stat = prop_hat, direction = \"two-sided\")\nnull_distn %>%\n  get_p_value(obs_stat = prop_hat, direction = \"two-sided\")## # A tibble: 1 x 1\n##   p_value\n##     <dbl>\n## 1  0.0008"},{"path":"hypothesentests-mit-dem-paket-infer.html","id":"pr√§ferenzen-f√ºr-den-wohnort","chapter":"Kapitel 9 Hypothesentests mit dem Paket infer","heading":"9.2.2 Pr√§ferenzen f√ºr den Wohnort","text":"Haben weibliche und m√§nnliche Studierende unterschiedliche Pr√§ferenzen f√ºr den Wohnort? Das ist ein √§hnlicher Fall wie der Einf√ºhrung zu Hypothesentests, als wir uns mit den Bef√∂rderungschancen von Fraune und M√§nnern den 70ern befasst haben. Wir haben hier zwei kategoriale Variablen, n√§mlich wohnort und geschlecht und wollen wissen, ob die beiden miteinander zusammenh√§ngen. Daher lauten unsere Nullhypothese und Alternativhypothese:\\(H_0\\): wohnort und geschlecht sind unabh√§ngig.\\(H_A\\): wohnort und geschlecht h√§ngen zusammen.Wir berechnen zun√§chst den Unterschied zwischen Stadtbewohnern nach Geschlecht.Wir basieren unseren Test auf Permutation, d.h. wir permutieren mehrfach eine der Variablen und berechnen die Differenzen den Anteilen der Stadtbewohner je nach Geschlecht f√ºr jede Permutation. Die Permutation wird von generate() automatisch richtig gew√§hlt.Nun Plotten wir die Stichprobenverteilung, die auf Permutation basiert, und f√§rben den \\(p\\)-Wert ein.Der \\(p\\)-Wert betr√§gtDer \\(p\\)-Wert ist gr√∂√üer als das Standard-Signifikanzniveau von 5%, daher k√∂nnen wir die Nullhypothese nicht ablehnen und behalten sie bei. dieser Stelle ist es wichtig, nicht Signifikanzniveau zu drehen, es etwas auf 10% zu setzten, oder irgendwie Datenpunkte heraus zu filtern. Das w√§re \\(p\\)-Hacking. nennt man das k√ºnstliche Dr√ºcken des \\(p\\)-Werts unter die 5%-Schranke, um statistische Signifikanz zu erzeugen. Viel besser ist es, zu berichten, dass die beobachteten Differenzen der Pr√§ferenz von Frauen und M√§nnern f√ºr den Wohnort zuf√§llig sein k√∂nnen, und den \\(p\\)-Wert mit anzugeben. BTW, der wahre Unterschied aus der Grundgesamtheit ist extrem klein.\\(p\\)-Werte werden h√§ufig miss- oder √ºberinterpretiert. Es geht soweit, dass nur wissenschaftliche Ergebnisse mit signifikanten Hypothesentests als wertvoll und publizierbar angesehen werden. Davor kann man nur dringend warnen. Diese Einstellung f√ºhrt zur Verzerrung der wissenschaftlichen Ergebnissen. Ich lade Sie ein, mehr dazu bei Wasserstein Lazar (2016) und im Kapitel 9.6 Ismay Kim (2021) nachzulesen.","code":"\nd_hat <- befragung %>% \n  specify(wohnort ~ geschlecht, success = \"stadt\") %>%\n  calculate(stat = \"diff in props\", order = c(\"w\", \"m\"))\n\nd_hat## # A tibble: 1 x 1\n##    stat\n##   <dbl>\n## 1 0.142\nset.seed(123)\n\nnull_distn <- befragung %>%\n  specify(wohnort ~ geschlecht, success = \"stadt\") %>%\n  hypothesize(null = \"independence\") %>% \n  generate(reps = 10000) %>% \n  calculate(stat = \"diff in props\", order = c(\"w\", \"m\"))## Setting `type = \"permute\"` in `generate()`.\nnull_distn## # A tibble: 10,000 x 2\n##    replicate     stat\n##        <int>    <dbl>\n##  1         1 -0.0381 \n##  2         2 -0.0180 \n##  3         3  0.0221 \n##  4         4  0.00201\n##  5         5 -0.0982 \n##  6         6  0.0221 \n##  7         7  0.0622 \n##  8         8  0.0421 \n##  9         9  0.00201\n## 10        10 -0.0581 \n## # ‚Ä¶ with 9,990 more rows\nvisualize(null_distn) +\n  shade_p_value(obs_stat = d_hat, direction = \"two-sided\")\nnull_distn %>%\n  get_p_value(obs_stat = d_hat, direction = \"two-sided\")## # A tibble: 1 x 1\n##   p_value\n##     <dbl>\n## 1  0.0542\ngrundgesamtheit %>% \n  specify(wohnort ~ geschlecht, success = \"stadt\") %>%\n  calculate(stat = \"diff in props\", order = c(\"w\", \"m\"))## # A tibble: 1 x 1\n##       stat\n##      <dbl>\n## 1 -0.00930"},{"path":"hypothesentests-mit-dem-paket-infer.html","id":"lesestoff-7","chapter":"Kapitel 9 Hypothesentests mit dem Paket infer","heading":"9.3 Lesestoff","text":"Kapitel 9.3 bis 9.6 Ismay Kim (2021)","code":""},{"path":"hypothesentests-mit-dem-paket-infer.html","id":"aufgaben-6","chapter":"Kapitel 9 Hypothesentests mit dem Paket infer","heading":"9.4 Aufgaben","text":"","code":""},{"path":"hypothesentests-mit-dem-paket-infer.html","id":"sind-anreisezeit-und-zeit-in-der-bibliothek-correliert","chapter":"Kapitel 9 Hypothesentests mit dem Paket infer","heading":"9.4.1 Sind Anreisezeit und Zeit in der Bibliothek correliert?","text":"F√ºhren Sie einen Hypothesentest durch, ob die Anreisezeit und die Zeit der Bibliothek (zeit_bib) korreliert sind. Formulieren Sie die Null- und die Alternativhypothese mit Ihren eigenen Worten, bevor Sie den Test durchf√ºhren.Tipps: specify(anreise ~ zeit_bib) und calculate(stat = \"correlation\"). Sehr hilfreich dazu ist auch die Webseite von infer (s.u.).","code":""},{"path":"hypothesentests-mit-dem-paket-infer.html","id":"h√§ngt-die-wahl-des-verkehrsmittels-vom-wohnort-ab","chapter":"Kapitel 9 Hypothesentests mit dem Paket infer","heading":"9.4.2 H√§ngt die Wahl des Verkehrsmittels vom Wohnort ab?","text":"Vielleicht k√∂nnen Sie sich noch erinnern, dass wir einer der fr√ºheren Stunden die Kontingenztabelle durchgenommen haben (s. Vorlesung Zusammenhangsma√üe). einer solchen Tabelle fasst man die H√§ufigkeiten von zwei kategoriellen Variablen zusammen. Anhand von einer Tabelle kann man entscheiden, ob es einen Zusammenhang zwischen diesen beiden Variablen gibt. Die Statistik, die man f√ºr eine Tabelle ausrechnet, hei√üt Kontingenzkoeffizient. einem Hypothesentest, genannt \\(\\chi^2\\)-Test, kann man √ºberpr√ºfen, ob dieser Zusammenhang signifikant ist.√úberpr√ºfen Sie nun, ob es einen Zusamenhang gibt zwischen der Wahl des Verkehrsmittels und dem Wohnort der befragten Studierenden. Tipps: specify(formula = wohnort ~ verkehrsmittel) und calculate(stat = \"Chisq\"). Auch hier lohnt ein Blick auf die Webseite von infer (s.u.)\n.\n## Ihre Arbeit einreichen\n- Speichern Sie Ihr Notebook ab und laden Sie nur die .Rmd Datei vom Server.\n- Laden Sie Ihre .Rmd Datei ILIAS hoch. Beachten Sie die Deadline!\n- Sie erhalten die Musterl√∂sung nach dem Hochladen.","code":""},{"path":"hypothesentests-mit-dem-paket-infer.html","id":"weiterf√ºhrende-literatur-und-videos-1","chapter":"Kapitel 9 Hypothesentests mit dem Paket infer","heading":"9.5 Weiterf√ºhrende Literatur und Videos","text":"Webseite von infer: https://infer.netlify.app/Vortrag des Autors von infer.\n\n\ninfer: package tidy statistical inference - RStudio\n","code":""},{"path":"aufgabensammlung.html","id":"aufgabensammlung","chapter":"Kapitel 10 Aufgabensammlung","heading":"Kapitel 10 Aufgabensammlung","text":"Diese Aufgabensammlung enth√§lt zus√§tzlich Aufgaben, die z.B. im Seminar bearbeitet werden. Aufgaben zu den einzelnen Kapiteln finden Sie Ende des jeweiligen Kapitels.","code":""},{"path":"aufgabensammlung.html","id":"werdeschlau","chapter":"Kapitel 10 Aufgabensammlung","heading":"10.1 Tutorial Zusammenhangsma√üe","text":"Begleitend zu diesem Tutorial sind die Kapitel 2 und 3 Mittag (2017) ‚ÄúStatistik‚Äù zu lesen.","code":""},{"path":"aufgabensammlung.html","id":"befragung-der-studierenden-der-uni-werdeschlau","chapter":"Kapitel 10 Aufgabensammlung","heading":"Befragung der Studierenden der Uni Werdeschlau","text":"Wir besch√§ftigen uns mit einem fiktiven Beispiel.der (kleinen) Universit√§t Werdeschlau m√∂chte die Studierendenvertretung wissen, ob sich eine Station zum Ausleihen von Fahrr√§dern lohnen w√ºrde. Dazu befragen sie die Studierenden, wie lange sie zur Uni fahren. Zudem wollen Sie wissen, ob die Anreisezeit und die Zeit, die die Studierenden pro Woche der Bibliothek verbringen, zusammen h√§ngen.","code":""},{"path":"aufgabensammlung.html","id":"grundgesamtheit-generieren","chapter":"Kapitel 10 Aufgabensammlung","heading":"10.1.1 Grundgesamtheit generieren","text":"Unsere Grundgesamtheit sind alle 12000 Studierende von der Uni Werdeschlau. Wir erstellen uns diesem Beispiel selbst unsere Grundgesamtheit aus der Gleichverteilung. Die Regeln dazu sind absolut frei erfunden. Die meisten Studierenden sind zwischen 5 und 40 Minuten unterwegs; 20% jedoch haben eine l√§ngere Anreise zwischen 60 und 120 Minuten.Lassen Sie den Code laufen.Wir setzen geschlecht, wohnort, verkehrsmittel, anreise und zeit_bib zu einer Datenmatrix (tibble) zusammen und nennen das Objekt grundgesamtheit.Lassen Sie den folgenden Code laufen.","code":"\nlibrary(tidyverse)\nset.seed(123)\nanreise <- c(runif(n = 12000 * 0.8, min = 5, max = 40),\n                     runif(n = 12000 * 0.2, min = 60, max = 120))\n\ngeschlecht <- sample(c('m', 'w'), size = 12000, replace = TRUE)\nwohnort <- sapply(anreise, function(x) {\n  if(x < 30) 'stadt'\n  else 'land'\n})\nverkehrsmittel <- sapply(anreise, function(x) {\n  if(x <= 10) 'zu_fuss'\n  else if(x > 10 & x <= 15) sample(c('zu_fuss', 'fahrrad'), size = 1)\n  else if(x > 15 & x <= 45) sample(c('bus', 'fahrrad', 'auto'), size = 1)\n  else sample(c('bus', 'auto'), size = 1)\n})\n\nzeit_bib <- 5 * 60 - 0.7 * anreise + rnorm(length(anreise), 0, 20)\ngrundgesamtheit <- tibble(geschlecht, wohnort, verkehrsmittel, anreise, zeit_bib)"},{"path":"aufgabensammlung.html","id":"befragung-simulieren","chapter":"Kapitel 10 Aufgabensammlung","heading":"10.1.2 Befragung simulieren","text":"der Realit√§t werden nat√ºrlich nicht alle 12000 Studierende befragt (wer hat schon viele Kapazit√§ten?), sondern eine zuf√§llige Stichprobe erhoben, also eine Teilmenge der Grundgesamtheit.Frage: Wie nennt man die StudierendenMerkmalstr√§gerBefragte oderModalwerte?Falls Sie nicht sicher sind: Lesen Sie Kapitel 2 Mittag (2017) ‚ÄúStatistik!‚ÄùUm unsere Stichprobe zu erstellen, ziehen wir ohne Zur√ºcklegen aus unserer Grundgesamtheit. Sagen wir mal, die Kapazit√§ten der Befragenden reichen f√ºr 200 Befragungen.Lassen Sie den folgenden Code laufen.","code":"\nbefragung <- grundgesamtheit[sample(1:dim(grundgesamtheit)[1], size = 200, replace = FALSE), ]"},{"path":"aufgabensammlung.html","id":"kurze-explorative-datenanalyse","chapter":"Kapitel 10 Aufgabensammlung","heading":"10.1.3 Kurze explorative Datenanalyse","text":"Von hier arbeiten wir mit unserer Stichprobe befragung. Sehen wir uns mal die empirische Verteilung, d.h. die Verteilung der Stichprobe .Plotten Sie ein Histogramm der Anreisezeiten unserer Stichprobe. Lassen Sie den Code laufen und passen Sie die bins sinnvoll .","code":"\nggplot(data = befragung, aes(x = anreise)) +\n  geom_histogram(bins = 5) +\n  xlab('Tagliche Anreise (min)') +\n  ylab('H√§ufigkeit')"},{"path":"aufgabensammlung.html","id":"lage--und-streuungsma√üe","chapter":"Kapitel 10 Aufgabensammlung","heading":"10.1.4 Lage- und Streuungsma√üe","text":"Erstellen Sie die F√ºnf-Punkte-Zusammenfassung der Stichprobe. Lassen Sie den Code laufen.Wie Sie sehen k√∂nnen, behandelt R die kategorischen Daten anders als numerische. Kategorische Variablen werden als absolute H√§ufigkeiten pro Kategorie dargestellt (d.h. ausgez√§hlt).Wir vergleichen nun gew√∂hnliche und robuste Lage- und Streuungsma√üe. Zu gew√∂hnlichen geh√∂ren der Mittelwert (genauer arithmetisches Mittel) und die Standardabwechung.Berechnen Sie den Mittelwert und die Standardabweichung der Anreise.Zu den robusten Ma√üen geh√∂ren der Median, der Interquartilabstand und die mittlere absolute Abweichung vom Median (MAD). MAD beschreibt die durchschnittlich Abweichung der Stichprobe von ihrem Median.Berechnen Sie den Median der Stichprobe.Den Interquartilabstand bekommt man mit Hilfe der Funtion quantile, die die Quantile berechnet.Lassen Sie den folgenden Code laufen.Der Interquartilabstand kann auch direkt mit der Funktion IQR() berechnet werden und MAD mit mad().Berechnen Sie den Interquartilabstand und MAD der Stichprobe.Vergleichen Sie die gew√∂hnlichen und die robusten Ma√üe. Es gilt: je gr√∂√üer die au√üergew√∂hnlichen Datenpunkte, d.h. je h√∂her die h√∂chsten Anfahrtszeiten, desto st√§rker reagieren der Mittelwert und die Standardabweichung. Die robusten Ma√üe bleiben (solange der Anteil der hohen Anfahrtszeiten nicht zu gro√ü ist) relativ konstant.Abgesehen vom Aspekt der Robustheit, ist das arithmetische Mittel nicht immer ein geeigneter Durchschnittswert. F√ºr Wachstumsfaktoren (Preissteigerung, Zinsen) ist das geometrische Mittel die korrekte Mittelung und f√ºr die Berechnung von Durchschnittsgeschwindigkeiten das harmonische Mittel (Details z.B. bei Fahrmeir et al.¬†(2016). Statistik. Der Weg zur Datenanalyse).","code":"\nsummary(befragung)\nquantile(x = befragung$anreise, probs = 0.75) - quantile(x = befragung$anreise, probs = 0.25)"},{"path":"aufgabensammlung.html","id":"zufall-in-der-befragung","chapter":"Kapitel 10 Aufgabensammlung","heading":"10.1.5 Zufall in der Befragung","text":"Wir haben unsere Befragten rein zuf√§llig ausgew√§hlt. D.h. die Kenngr√∂√üen h√§ngen von dieser zuf√§lligen Auswahl ab. Wie w√ºrden sie sich ver√§ndern, wenn wir eine andere Stichprobe ausgesucht h√§tten?Wir simulieren eine wiederholte Befragung und sehen uns , wie sich der Mittelwert und der Median entwickeln. Lassen Sie den Code laufen.Stellen Sie die Mittelwerte mean_all als Histogramm dar. Lassen Sie den Code laufen und passen Sie die bins sinnvoll .Stellen Sie die Mediane median_all als Histogramm dar. Lassen Sie den Code laufen und passen Sie die bins sinnvoll .","code":"\nanzahl_der_befragungen <- 100\n\n# Leere Vektoren erstellen, in die sp√§ter die Ergebnisse geschrieben werden.\nmean_all <- vector()\nmedian_all <- vector()\n\n\nfor (i in 1:anzahl_der_befragungen){\n  dat <- grundgesamtheit[sample(1:dim(grundgesamtheit)[1], size = 200, replace = FALSE), ]\n  mean_all[i] <- mean(dat$anreise)\n  median_all[i] <- median(dat$anreise)\n}\n\nkennzahlen <- tibble(mean_all, median_all)\nggplot(data = kennzahlen, aes(x = mean_all)) +\n  geom_histogram(bins = 5) +\n  xlab('Mittelwerte der taglichen Anreise (min)') +\n  ylab('H√§ufigkeit')\nggplot(data = kennzahlen, aes(x = median_all)) +\n  geom_histogram(bins = 5) +\n  xlab('Mediane der taglichen Anreise (min)') +\n  ylab('H√§ufigkeit')"},{"path":"aufgabensammlung.html","id":"zusammenhangsma√üe-f√ºr-nominalskalierte-merkmale","chapter":"Kapitel 10 Aufgabensammlung","heading":"10.1.6 Zusammenhangsma√üe f√ºr nominalskalierte Merkmale","text":"Gibt es Pr√§ferenzen f√ºr bestimmte Verkehrsmittel je nach Geschlecht?\nWir sehen uns die Kontingenztabelle dazu .Lassen Sie den folgenden Code laufen.Nun berechnen wir die Zusammenhangsma√üe auf dieser Tabelle. Dazu nutzen wir die Bibliothek vcd (Visualizing Categorical Data), sehr empfehlenswert, wenn Sie kategorische Daten analysieren wollen.Lassen Sie den folgenden Code laufen.Der Phi-Koeffizient ist NA, weil er nur auf \\(2 \\times 2\\)-Tabellen definiert ist. Die beiden anderen, Contingency Coeff. (Pearson Koeffizient K) und Cramer‚Äôs V zeigen unterschiedliche Werte , je nachdem, wie unsere zuf√§llige Stichprobe ausf√§llt. Aber der Zusammenhang sollte eher klein sein.Allgemein gil: Contingency Coeff. (Pearson Koeffizient K) und Cramer‚Äôs V schwanken zwischen 0 (kein Zusammenhang) und 1 (perfekter Zusammenhang). Wichtig: Sie zeigen keine Richtung . D.h. wir wissen nicht, ob der Zusammenhang positiv - ‚Äúje mehr desto mehr‚Äù oder negativ ‚Äúje mehr desto weniger‚Äù ist.Die ersten beiden Zeilen, die assocstats liefert, geh√∂ren zum Thema Hypothsentests. Das besprechen wir sp√§ter.Gibt es einen Zusammenhang zwischen dem Wohnort und dem ausgesuchten Verkehrsmittel?Berechnen Sie die Kontingenztabelle. Nutzen Sie die Funktion table() auf den Spalten wohnort und verkehrsmittel im Datensatz befragung.Berechnen Sie die Zusammenhangsma√üe. Lassen Sie den Code laufen.Gibt es eine Pr√§ferenz f√ºr den Wohnort je Geschlecht? Lassen Sie den Code laufen.Da Sie ja genau wissen, wie die Daten erstellt wurden, sollten Ihnen die Antworten nicht zu schwer fallen.","code":"\ntable(befragung$geschlecht, befragung$verkehrsmittel)\nlibrary(vcd)\nassocstats(table(befragung$geschlecht, befragung$verkehrsmittel))\nassocstats(table(befragung$wohnort, befragung$verkehrsmittel))\nassocstats(table(befragung$wohnort, befragung$geschlecht))"},{"path":"aufgabensammlung.html","id":"zusammenhangsma√üe-f√ºr-metrische-merkmale","chapter":"Kapitel 10 Aufgabensammlung","heading":"10.1.7 Zusammenhangsma√üe f√ºr metrische Merkmale","text":"Zum Schluss wenden wir uns den beiden numerischen Variablen, anreise und zeit_bib. Besteht hier eine Korrelation?Zuerst stellen wir die Daten dar.Lassen Sie den folgenden Code laufen.Der Zusammenhang zwischen den beiden Variablen ist (ziemlich) linear und negativ.Wir berechnen beide Korrelationsma√üe, den Pearson Korrelationskoeffizienten f√ºr lineare Zusammenh√§nge und den Spearman Korrelationskoeffizient f√ºr monotone Zusammenh√§nge.Lassen Sie den Code laufen.Beide Koeffizienten sind nah dran dem Faktor 0.7, den wir zum Simulieren unserer Daten verwendet haben. Man darf hier beide verwenden. Wichtig ist es zu berichten, welchen Sie verwenden. D.h. es ist nicht genug, zu schreiben, dass Sie eine Korrelation berechnet haben.Gut gemacht! Lassen Sie den Code laufen.","code":"\nggplot(data = befragung, aes(x = anreise, y = zeit_bib)) +\n  geom_point() +\n  xlab('T√§gliche Anreise (min)') +\n  ylab('Zeit in der Bibliothek pro Woche (min)')\n# Pearson Korrelationskoeffizient\ncor(befragung$anreise, befragung$zeit_bib, method = 'pearson')\n\n# Spearman Korrelationskoeffizient\ncor(befragung$anreise, befragung$zeit_bib, method = 'spearman')\nlibrary(ggplot2)\nlibrary(emojifont)\nggplot() + geom_fontawesome(\"fa-coffee\", color='lightblue', size = 80) + theme_void() + ggtitle(\"It's time for coffee\")"},{"path":"aufgabensammlung.html","id":"aufgabe-einreichen","chapter":"Kapitel 10 Aufgabensammlung","heading":"10.1.8 Aufgabe einreichen","text":"Speichern Sie Ihr Notebook und laden Sie es vom Server herunter.Laden Sie Ihr Notebook ILIAS hoch. Sie bekommen eine Musterl√∂sungVergleichen Sie Ihre L√∂sung mit der Musterl√∂sung.Fertig!","code":""},{"path":"aufgabensammlung.html","id":"der-explorative-workflow-mit-tidyverse","chapter":"Kapitel 10 Aufgabensammlung","heading":"10.2 Der explorative Workflow mit tidyverse","text":"","code":""},{"path":"aufgabensammlung.html","id":"r-hausaufgaben","chapter":"Kapitel 10 Aufgabensammlung","heading":"10.2.1 R-Hausaufgaben","text":"dem Kurs ‚ÄúEinf√ºhrung R‚Äù nehmen 49 Studierende teil. Der Leistungsnachweis besteht aus Hausaufgaben, die insgesamt mit 100 Punkten bewertet werden. Ab 50 Punkten gilt der Kurs als bestanden.Lesen Sie den Datensatz R-.txt, der die Endpunkte enth√§lt, ein.Ermitteln Sie, wie viele Teilnehmer bestanden und wie viele nicht bestanden haben. Nutzen Sie dazu die Funktion mutate() und die Funktion ifelse().","code":""},{"path":"aufgabensammlung.html","id":"klausur","chapter":"Kapitel 10 Aufgabensammlung","heading":"10.2.2 Unfaire Klausur?","text":"Ar belegt im 4. Semester die Veranstaltung ‚ÄúSpa√ü mit R.‚Äù Bei der Klausur gibt es 2 Aufgabengruppen mit jeweils 60 Punkten. Aufgabengruppe 1 wird Studierende auf ungeraden Sitzpl√§tzen und Aufgabengruppe 2 Studierende auf geraden Sitzpl√§tzen ausgegeben.Lesen Sie den Datensatz Klausurpunkte.txt ein.√úberpr√ºfen Sie Ars Vermutung, dass die Aufgabengruppe 1 im Schnitt leichter war als Aufgabengruppe 2 (d.h. der Gruppe 1 im Schnitt mehr Punkte erzielt wurden). Nutzen Sie die Funktionen mutate(), um eine Spalte mit der Gruppenzugeh√∂rigkeit zu ermitteln und summarize(), um den Mittelwert zu berechnen. Tipp: mit dem Operator %% k√∂nnen Sie √ºberpr√ºfen, ob eine Zahl z.B. durch 2 teilbar ist.","code":""},{"path":"aufgabensammlung.html","id":"flederm√§use","chapter":"Kapitel 10 Aufgabensammlung","heading":"10.2.3 Flederm√§use","text":"Ar Stat untersucht im Rahmen eines √∂kologischen Praktikums Flederm√§use Ecuador. Er vermisst die gr√∂√üe der Tiere und notiert ihr Geschlecht.Laden Sie den Datensatz Fledermaus.txt. Dieser enth√§lt die Gr√∂√üe der Tiere cm.Die ersten 20 untersuchten Tiere sind M√§nnchen. Erstellen Sie einen factor ‚Äúgeschlecht,‚Äù der das Geschlecht der Tiere enth√§lt. Benutzen Sie dazu die Funktionen rep().F√ºgen Sie die Informationen √ºber die Gr√∂√üe und das Geschlecht einem tibble zusammen und bennen Sie die Spalten entsprechend.Bei dem 3. Individuum hat sich Ar vertippt. Die Gr√∂√üe des Tieres lautet Wirklichkeit 5,37 cm. Korrigieren Sie den Fehler.Speichern Sie den korrigierten Datensatz ab.Berechnen Sie die Mittelwerte und die Standardabweichungen der Gr√∂√üen der Tiere je Geschlecht.Plotten Sie die Gr√∂√üen je Geschlecht einem Boxplot und speichern Sie diesen ab.","code":""},{"path":"aufgabensammlung.html","id":"flederm√§use-revisited","chapter":"Kapitel 10 Aufgabensammlung","heading":"10.2.4 Flederm√§use, revisited","text":"Wir gehen davon aus, dass das Alter der Flederm√§use mit ihrer Gr√∂√üe zusammenh√§ngt. Pauschal legen wir fest, dass ein Tier, das kleiner als 5 cm gro√ü ist, ein Jungtier ist.Klassifizieren Sie die Tiere J (Jungtier) und E (Erwachsen). Erstellen Sie dazu mit mutate() ein eigene Spalte.Wie viele Jungtiere gibt es im Datensatz?Sind die Jungtiere weiblich oder m√§nnlich?","code":""},{"path":"aufgabensammlung.html","id":"zeitreihen-aus-der-langen-bramke-harz","chapter":"Kapitel 10 Aufgabensammlung","heading":"10.2.5 Zeitreihen aus der Langen Bramke (Harz)","text":"Im Harz wurden √ºber eine l√§ngere Zeit Niederschlag, Abfluss und Temperatur gemessen. DIe Messeinheiten sind f√ºr Temperatur ¬∞C, f√ºr Niederschlag und Abfluss mm.Laden Sie den Datensatz Data.dat.Wandeln Sie die Spalte Date ein richtiges Datum um.Plotten Sie die Temperatur, den Niederschlag und den Abfluss (verschiedene Grafiken) untereinander. Beschriften Sie alles korrekt und f√ºgen Sie Titel hinzu. √úberlegen Sie, welche Darstellungsart (geom) f√ºr den Niederschlag besten ist.Speichern Sie die Grafik als pdf ab.","code":""},{"path":"aufgabensammlung.html","id":"umweltdaten-entlang-der-d√§nischen-k√ºste","chapter":"Kapitel 10 Aufgabensammlung","heading":"10.2.6 Umweltdaten entlang der d√§nischen K√ºste","text":"Die Datei Temperatur.csv aus Zuur, Ieno, Meesters (2009) enth√§lt Messungen von Temperatur, Salinit√§t und Chlorophyl 31 Orten entlang der d√§nischen K√ºste. Die Daten stammen vom d√§nischen Institut RIKZ (Monitoringprogramm MWTL: Monitoring Waterstaatkundige Toestand des Lands). Die Messungen wurden zwischen 1990 und 2005 durchgef√ºhrt mit einer H√§ufigkeit von 0‚Äì4 mal pro Monat je nach Jahreszeit.Lesen Sie den Datensatz Temperatur.csv ein.Konvertieren Sie die Spalte Date ein richtiges Datumsformat und plotten Sie die Temperaturen pro Station (facet_wrap()) als Zeitreihen.Berechnen Sie die Anzahl der Messwerte, Monatsmittelwerte der Temperatur f√ºr alle Stationen, sowie die Standardabweichungen.Stellen Sie die Monatsmittel der Temperatur als Linien dar.Beschriften Sie die Grafik sinnvoll.F√ºgen Sie die Standardabweichungen als Band hinzu.Speichern Sie die Grafik als pdf ab.","code":""},{"path":"aufgabensammlung.html","id":"umweltdaten-entlang-der-d√§nischen-k√ºste-revisited","chapter":"Kapitel 10 Aufgabensammlung","heading":"10.2.7 Umweltdaten entlang der d√§nischen K√ºste, revisited","text":"Berechnen Sie die Monatsmittelwerte und Standardabweichungen je Station. Tipp: group_by(Station, Month).Stellen Sie die Daten mit einem Fehlerband dar (verschiedenen Plots mit facet_wrap()) und speichern Sie sie ab.","code":""},{"path":"literatur.html","id":"literatur","chapter":"Literatur","heading":"Literatur","text":"","code":""}]
